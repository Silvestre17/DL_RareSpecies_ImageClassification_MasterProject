{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Churn Prediction: Data preprocessing\"\"\"\n",
    "\n",
    "# Data Preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('./Churn.csv')\n",
    "\n",
    "# Extract features (X) and target (Y)\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "Y = dataset.iloc[:, 13].values\n",
    "\n",
    "# Convert categorical data to numerical data\n",
    "\n",
    "# Encode the 'Geography' column\n",
    "labelencoder1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder1.fit_transform(X[:, 1])\n",
    "\n",
    "# Encode the 'Gender' column\n",
    "labelencoder2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder2.fit_transform(X[:, 2])\n",
    "\n",
    "\n",
    "# Apply One-Hot Encoding to the 'Geography' column\n",
    "ct = ColumnTransformer([(\"Geography\", OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = ct.fit_transform(X)\n",
    "\n",
    "# Remove dummy variable trap (optional, but recommended)\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Churn Prediction: Training/Test data creation\"\"\"\n",
    "\n",
    "# Creation of training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and test sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "# Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"# Churn Prediction: Model construction\"\"\"\n",
    "\n",
    "# Creation of the model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "# Initialize the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units=6, kernel_initializer='uniform',\n",
    "                     activation='relu', input_dim=11))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units=6, kernel_initializer='uniform',\n",
    "                     activation='relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units=1, kernel_initializer='uniform',\n",
    "                     activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7869 - loss: 0.6563\n",
      "Epoch 2/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8063 - loss: 0.4429\n",
      "Epoch 3/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8030 - loss: 0.4264\n",
      "Epoch 4/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8174 - loss: 0.4193\n",
      "Epoch 5/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8284 - loss: 0.4161\n",
      "Epoch 6/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8308 - loss: 0.4174\n",
      "Epoch 7/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8375 - loss: 0.3978\n",
      "Epoch 8/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8319 - loss: 0.4107\n",
      "Epoch 9/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8375 - loss: 0.4036\n",
      "Epoch 10/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8353 - loss: 0.4033\n",
      "Epoch 11/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8294 - loss: 0.4135\n",
      "Epoch 12/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8369 - loss: 0.4001  \n",
      "Epoch 13/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8353 - loss: 0.4076\n",
      "Epoch 14/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8376 - loss: 0.3980\n",
      "Epoch 15/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8375 - loss: 0.4000\n",
      "Epoch 16/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8345 - loss: 0.4023\n",
      "Epoch 17/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8372 - loss: 0.4032\n",
      "Epoch 18/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8290 - loss: 0.4136\n",
      "Epoch 19/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8413 - loss: 0.3992\n",
      "Epoch 20/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8365 - loss: 0.3983\n",
      "Epoch 21/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8496 - loss: 0.3738\n",
      "Epoch 22/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8373 - loss: 0.4078\n",
      "Epoch 23/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8340 - loss: 0.4030\n",
      "Epoch 24/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8433 - loss: 0.3881\n",
      "Epoch 25/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8377 - loss: 0.3956\n",
      "Epoch 26/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8387 - loss: 0.3963\n",
      "Epoch 27/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8332 - loss: 0.4019\n",
      "Epoch 28/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8370 - loss: 0.3969\n",
      "Epoch 29/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8373 - loss: 0.3929\n",
      "Epoch 30/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8376 - loss: 0.3957\n",
      "Epoch 31/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8403 - loss: 0.3886\n",
      "Epoch 32/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8392 - loss: 0.3869\n",
      "Epoch 33/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8397 - loss: 0.3943\n",
      "Epoch 34/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8331 - loss: 0.3956\n",
      "Epoch 35/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8374 - loss: 0.3949\n",
      "Epoch 36/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8447 - loss: 0.3856\n",
      "Epoch 37/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8378 - loss: 0.3897\n",
      "Epoch 38/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8480 - loss: 0.3773\n",
      "Epoch 39/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8383 - loss: 0.3880\n",
      "Epoch 40/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8456 - loss: 0.3731  \n",
      "Epoch 41/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8532 - loss: 0.3665\n",
      "Epoch 42/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8479 - loss: 0.3746\n",
      "Epoch 43/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8476 - loss: 0.3664\n",
      "Epoch 44/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8614 - loss: 0.3497\n",
      "Epoch 45/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8539 - loss: 0.3574  \n",
      "Epoch 46/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8598 - loss: 0.3484  \n",
      "Epoch 47/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8565 - loss: 0.3509  \n",
      "Epoch 48/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8464 - loss: 0.3702\n",
      "Epoch 49/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8570 - loss: 0.3475  \n",
      "Epoch 50/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8490 - loss: 0.3636\n",
      "Epoch 51/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8557 - loss: 0.3511\n",
      "Epoch 52/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8582 - loss: 0.3529\n",
      "Epoch 53/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8561 - loss: 0.3517  \n",
      "Epoch 54/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8492 - loss: 0.3643  \n",
      "Epoch 55/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8517 - loss: 0.3494\n",
      "Epoch 56/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8633 - loss: 0.3374  \n",
      "Epoch 57/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8561 - loss: 0.3502\n",
      "Epoch 58/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8571 - loss: 0.3431\n",
      "Epoch 59/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8552 - loss: 0.3485  \n",
      "Epoch 60/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8551 - loss: 0.3526\n",
      "Epoch 61/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8568 - loss: 0.3480\n",
      "Epoch 62/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8572 - loss: 0.3399  \n",
      "Epoch 63/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8586 - loss: 0.3487\n",
      "Epoch 64/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8526 - loss: 0.3618\n",
      "Epoch 65/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8586 - loss: 0.3417\n",
      "Epoch 66/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8465 - loss: 0.3508\n",
      "Epoch 67/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8540 - loss: 0.3507\n",
      "Epoch 68/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8559 - loss: 0.3454\n",
      "Epoch 69/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8617 - loss: 0.3433\n",
      "Epoch 70/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8566 - loss: 0.3470\n",
      "Epoch 71/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8545 - loss: 0.3489\n",
      "Epoch 72/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8618 - loss: 0.3420\n",
      "Epoch 73/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8590 - loss: 0.3462\n",
      "Epoch 74/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8573 - loss: 0.3428\n",
      "Epoch 75/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8576 - loss: 0.3526\n",
      "Epoch 76/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8672 - loss: 0.3298\n",
      "Epoch 77/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8546 - loss: 0.3474\n",
      "Epoch 78/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8646 - loss: 0.3303\n",
      "Epoch 79/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8637 - loss: 0.3371\n",
      "Epoch 80/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8573 - loss: 0.3430\n",
      "Epoch 81/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8589 - loss: 0.3354\n",
      "Epoch 82/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8599 - loss: 0.3423\n",
      "Epoch 83/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8548 - loss: 0.3456\n",
      "Epoch 84/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8571 - loss: 0.3438\n",
      "Epoch 85/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8608 - loss: 0.3324\n",
      "Epoch 86/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8549 - loss: 0.3436\n",
      "Epoch 87/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8640 - loss: 0.3353\n",
      "Epoch 88/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8623 - loss: 0.3367\n",
      "Epoch 89/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8681 - loss: 0.3304\n",
      "Epoch 90/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8615 - loss: 0.3412\n",
      "Epoch 91/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8642 - loss: 0.3316\n",
      "Epoch 92/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8651 - loss: 0.3333\n",
      "Epoch 93/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8603 - loss: 0.3371\n",
      "Epoch 94/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8641 - loss: 0.3347\n",
      "Epoch 95/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8614 - loss: 0.3356\n",
      "Epoch 96/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8647 - loss: 0.3251\n",
      "Epoch 97/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8558 - loss: 0.3397\n",
      "Epoch 98/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8620 - loss: 0.3373\n",
      "Epoch 99/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8666 - loss: 0.3312 \n",
      "Epoch 100/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8568 - loss: 0.3356\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Confusion Matrix:\n",
      " [[1507   70]\n",
      " [ 213  210]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Stay       0.88      0.96      0.91      1577\n",
      "       Leave       0.75      0.50      0.60       423\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.81      0.73      0.76      2000\n",
      "weighted avg       0.85      0.86      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"# Churn Prediction: Model fitting and Evaluation on the Test observations\"\"\"\n",
    "\n",
    "# Training the network\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "# Train the classifier\n",
    "classifier.fit(X_train, y_train, epochs=100)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Print Statistics from Confusion Matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Print the classification report\n",
    "target_names = ['Stay', 'Leave']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"# Adding Dropout to the Neural Network\"\"\"\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform',\n",
    "                     activation = 'relu', input_dim = 11))\n",
    "classifier.add(Dropout(0.1))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform',\n",
    "                     activation = 'relu'))\n",
    "classifier.add(Dropout(0.1))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform',\n",
    "                     activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n",
    "metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding dropout is simple: it is a layer that you add after a hidden dense layer. The 'p' parameter is the dropout probability (i.e., the probability of «silencing» the neurons in the previous layer).\n",
    "- Nothing will change in the remaining parts of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall -y scikit-learn\n",
    "# !pip install scikit-learn==1.3.1\n",
    "\n",
    "# https://stackoverflow.com/questions/79290968/super-object-has-no-attribute-sklearn-tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n"
     ]
    }
   ],
   "source": [
    "# Print version of scikit-learn\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  3.3min finished\n"
     ]
    }
   ],
   "source": [
    "\"\"\"# Cross Validation\"\"\"\n",
    "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier      - deprecated\n",
    "\n",
    "# %pip install scikeras[tensorflow]\n",
    "# %pip install -U scikit-learn\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform',\n",
    "                         activation = 'relu', input_dim = 11))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform',\n",
    "                         activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform',\n",
    "                         activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return classifier\n",
    "\n",
    "classifier = KerasClassifier(model=build_classifier, batch_size = 10, epochs = 100)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10, n_jobs = -1, verbose = 1)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7801 - loss: 0.6538\n",
      "Epoch 2/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7950 - loss: 0.4428\n",
      "Epoch 3/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8109 - loss: 0.4173\n",
      "Epoch 4/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8151 - loss: 0.4023\n",
      "Epoch 5/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8251 - loss: 0.3843\n",
      "Epoch 6/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8415 - loss: 0.3849\n",
      "Epoch 7/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8529 - loss: 0.3657\n",
      "Epoch 8/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8520 - loss: 0.3668\n",
      "Epoch 9/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8626 - loss: 0.3461\n",
      "Epoch 10/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8621 - loss: 0.3363\n",
      "Epoch 11/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8548 - loss: 0.3533\n",
      "Epoch 12/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8570 - loss: 0.3525\n",
      "Epoch 13/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8624 - loss: 0.3430\n",
      "Epoch 14/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8534 - loss: 0.3494\n",
      "Epoch 15/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8568 - loss: 0.3536\n",
      "Epoch 16/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8578 - loss: 0.3491\n",
      "Epoch 17/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8629 - loss: 0.3369\n",
      "Epoch 18/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8605 - loss: 0.3457\n",
      "Epoch 19/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8608 - loss: 0.3503\n",
      "Epoch 20/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8635 - loss: 0.3340\n",
      "Epoch 21/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8592 - loss: 0.3425\n",
      "Epoch 22/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8613 - loss: 0.3434\n",
      "Epoch 23/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8585 - loss: 0.3446\n",
      "Epoch 24/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8585 - loss: 0.3470\n",
      "Epoch 25/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8637 - loss: 0.3351\n",
      "Epoch 26/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8599 - loss: 0.3422\n",
      "Epoch 27/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8667 - loss: 0.3331\n",
      "Epoch 28/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8615 - loss: 0.3434\n",
      "Epoch 29/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8650 - loss: 0.3408  \n",
      "Epoch 30/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8611 - loss: 0.3402\n",
      "Epoch 31/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8574 - loss: 0.3432\n",
      "Epoch 32/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8646 - loss: 0.3344\n",
      "Epoch 33/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8667 - loss: 0.3353\n",
      "Epoch 34/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8607 - loss: 0.3381\n",
      "Epoch 35/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8614 - loss: 0.3412\n",
      "Epoch 36/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8675 - loss: 0.3282\n",
      "Epoch 37/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8636 - loss: 0.3340\n",
      "Epoch 38/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8570 - loss: 0.3430\n",
      "Epoch 39/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8702 - loss: 0.3314\n",
      "Epoch 40/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8638 - loss: 0.3440\n",
      "Epoch 41/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8635 - loss: 0.3351\n",
      "Epoch 42/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8643 - loss: 0.3310\n",
      "Epoch 43/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8614 - loss: 0.3351\n",
      "Epoch 44/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8630 - loss: 0.3307\n",
      "Epoch 45/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8691 - loss: 0.3285\n",
      "Epoch 46/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8589 - loss: 0.3493\n",
      "Epoch 47/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8638 - loss: 0.3414\n",
      "Epoch 48/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8616 - loss: 0.3414  \n",
      "Epoch 49/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8638 - loss: 0.3294\n",
      "Epoch 50/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8649 - loss: 0.3328\n",
      "Epoch 51/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8632 - loss: 0.3352\n",
      "Epoch 52/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8610 - loss: 0.3400\n",
      "Epoch 53/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8672 - loss: 0.3293\n",
      "Epoch 54/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8625 - loss: 0.3382  \n",
      "Epoch 55/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8518 - loss: 0.3523\n",
      "Epoch 56/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8589 - loss: 0.3428\n",
      "Epoch 57/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8592 - loss: 0.3353  \n",
      "Epoch 58/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8636 - loss: 0.3368\n",
      "Epoch 59/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8581 - loss: 0.3449  \n",
      "Epoch 60/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8631 - loss: 0.3427\n",
      "Epoch 61/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8573 - loss: 0.3425\n",
      "Epoch 62/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8627 - loss: 0.3360\n",
      "Epoch 63/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8625 - loss: 0.3361\n",
      "Epoch 64/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8670 - loss: 0.3358\n",
      "Epoch 65/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8654 - loss: 0.3336\n",
      "Epoch 66/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8624 - loss: 0.3323\n",
      "Epoch 67/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8581 - loss: 0.3416\n",
      "Epoch 68/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8637 - loss: 0.3280\n",
      "Epoch 69/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8626 - loss: 0.3382\n",
      "Epoch 70/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8562 - loss: 0.3405\n",
      "Epoch 71/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8629 - loss: 0.3385\n",
      "Epoch 72/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8637 - loss: 0.3324\n",
      "Epoch 73/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8676 - loss: 0.3325\n",
      "Epoch 74/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8724 - loss: 0.3253\n",
      "Epoch 75/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8637 - loss: 0.3323\n",
      "Epoch 76/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8530 - loss: 0.3503\n",
      "Epoch 77/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8578 - loss: 0.3400\n",
      "Epoch 78/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8650 - loss: 0.3313\n",
      "Epoch 79/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8710 - loss: 0.3259\n",
      "Epoch 80/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8606 - loss: 0.3359\n",
      "Epoch 81/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8613 - loss: 0.3435\n",
      "Epoch 82/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8672 - loss: 0.3291\n",
      "Epoch 83/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8643 - loss: 0.3332\n",
      "Epoch 84/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8688 - loss: 0.3254\n",
      "Epoch 85/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8608 - loss: 0.3337\n",
      "Epoch 86/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8621 - loss: 0.3377\n",
      "Epoch 87/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8659 - loss: 0.3321\n",
      "Epoch 88/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8597 - loss: 0.3345\n",
      "Epoch 89/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8645 - loss: 0.3344\n",
      "Epoch 90/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8586 - loss: 0.3436\n",
      "Epoch 91/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8664 - loss: 0.3363\n",
      "Epoch 92/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8629 - loss: 0.3372\n",
      "Epoch 93/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8674 - loss: 0.3324\n",
      "Epoch 94/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8655 - loss: 0.3314\n",
      "Epoch 95/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8719 - loss: 0.3212\n",
      "Epoch 96/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8629 - loss: 0.3364\n",
      "Epoch 97/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8598 - loss: 0.3391\n",
      "Epoch 98/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8648 - loss: 0.3262\n",
      "Epoch 99/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8676 - loss: 0.3267\n",
      "Epoch 100/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8667 - loss: 0.3261\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7774 - loss: 0.6457\n",
      "Epoch 2/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7894 - loss: 0.4520\n",
      "Epoch 3/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7923 - loss: 0.4370\n",
      "Epoch 4/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7966 - loss: 0.4297\n",
      "Epoch 5/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7971 - loss: 0.4257\n",
      "Epoch 6/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7882 - loss: 0.4394\n",
      "Epoch 7/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7918 - loss: 0.4268\n",
      "Epoch 8/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8052 - loss: 0.4252\n",
      "Epoch 9/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8208 - loss: 0.4213\n",
      "Epoch 10/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8231 - loss: 0.4182\n",
      "Epoch 11/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8370 - loss: 0.4075\n",
      "Epoch 12/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8318 - loss: 0.4152\n",
      "Epoch 13/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8395 - loss: 0.4049\n",
      "Epoch 14/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8389 - loss: 0.4051\n",
      "Epoch 15/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8300 - loss: 0.4195\n",
      "Epoch 16/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8286 - loss: 0.4215\n",
      "Epoch 17/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8327 - loss: 0.4181\n",
      "Epoch 18/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8356 - loss: 0.4093\n",
      "Epoch 19/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8309 - loss: 0.4206\n",
      "Epoch 20/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8423 - loss: 0.3998\n",
      "Epoch 21/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8387 - loss: 0.4095\n",
      "Epoch 22/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8395 - loss: 0.4040\n",
      "Epoch 23/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8370 - loss: 0.4039\n",
      "Epoch 24/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8422 - loss: 0.3952\n",
      "Epoch 25/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8351 - loss: 0.4102\n",
      "Epoch 26/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8391 - loss: 0.4009\n",
      "Epoch 27/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8382 - loss: 0.4026\n",
      "Epoch 28/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8360 - loss: 0.4062\n",
      "Epoch 29/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8390 - loss: 0.4126\n",
      "Epoch 30/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8417 - loss: 0.3992\n",
      "Epoch 31/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8373 - loss: 0.4111\n",
      "Epoch 32/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8388 - loss: 0.3989\n",
      "Epoch 33/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8465 - loss: 0.3929\n",
      "Epoch 34/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8334 - loss: 0.4093\n",
      "Epoch 35/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8389 - loss: 0.4009\n",
      "Epoch 36/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8392 - loss: 0.4010\n",
      "Epoch 37/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8393 - loss: 0.3991\n",
      "Epoch 38/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8373 - loss: 0.3989\n",
      "Epoch 39/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8370 - loss: 0.4093\n",
      "Epoch 40/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8343 - loss: 0.4040\n",
      "Epoch 41/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8439 - loss: 0.4022\n",
      "Epoch 42/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8394 - loss: 0.4028\n",
      "Epoch 43/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8360 - loss: 0.4028\n",
      "Epoch 44/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8388 - loss: 0.4006\n",
      "Epoch 45/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8334 - loss: 0.4089\n",
      "Epoch 46/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8432 - loss: 0.4009\n",
      "Epoch 47/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8451 - loss: 0.3882\n",
      "Epoch 48/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8402 - loss: 0.4010\n",
      "Epoch 49/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8406 - loss: 0.3933\n",
      "Epoch 50/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8391 - loss: 0.4019\n",
      "Epoch 51/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8339 - loss: 0.4165\n",
      "Epoch 52/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8296 - loss: 0.4148\n",
      "Epoch 53/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8368 - loss: 0.4050\n",
      "Epoch 54/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8345 - loss: 0.4000\n",
      "Epoch 55/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8437 - loss: 0.3903\n",
      "Epoch 56/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.4009\n",
      "Epoch 57/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8340 - loss: 0.4086\n",
      "Epoch 58/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8394 - loss: 0.3954\n",
      "Epoch 59/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8389 - loss: 0.3967\n",
      "Epoch 60/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8390 - loss: 0.3942\n",
      "Epoch 61/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8373 - loss: 0.4059\n",
      "Epoch 62/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8455 - loss: 0.3886\n",
      "Epoch 63/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8366 - loss: 0.4074\n",
      "Epoch 64/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8391 - loss: 0.4036\n",
      "Epoch 65/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8300 - loss: 0.4140\n",
      "Epoch 66/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8465 - loss: 0.3897\n",
      "Epoch 67/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8412 - loss: 0.3956\n",
      "Epoch 68/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8345 - loss: 0.4095\n",
      "Epoch 69/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8410 - loss: 0.3994\n",
      "Epoch 70/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8416 - loss: 0.3994\n",
      "Epoch 71/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8454 - loss: 0.3886\n",
      "Epoch 72/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8365 - loss: 0.4022\n",
      "Epoch 73/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8378 - loss: 0.4006\n",
      "Epoch 74/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8337 - loss: 0.4032\n",
      "Epoch 75/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8352 - loss: 0.4075\n",
      "Epoch 76/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8385 - loss: 0.4030\n",
      "Epoch 77/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8389 - loss: 0.3958\n",
      "Epoch 78/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8358 - loss: 0.3926\n",
      "Epoch 79/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8397 - loss: 0.4053\n",
      "Epoch 80/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8418 - loss: 0.3923\n",
      "Epoch 81/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8403 - loss: 0.4008\n",
      "Epoch 82/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8338 - loss: 0.4114\n",
      "Epoch 83/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8348 - loss: 0.4033\n",
      "Epoch 84/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8390 - loss: 0.4016\n",
      "Epoch 85/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8407 - loss: 0.3920\n",
      "Epoch 86/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8370 - loss: 0.3977\n",
      "Epoch 87/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8418 - loss: 0.3959\n",
      "Epoch 88/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8415 - loss: 0.4006\n",
      "Epoch 89/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8394 - loss: 0.4032\n",
      "Epoch 90/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8479 - loss: 0.3886\n",
      "Epoch 91/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8428 - loss: 0.3927\n",
      "Epoch 92/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8323 - loss: 0.4073\n",
      "Epoch 93/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8429 - loss: 0.3927\n",
      "Epoch 94/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8370 - loss: 0.4047\n",
      "Epoch 95/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8382 - loss: 0.3966\n",
      "Epoch 96/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8387 - loss: 0.4026\n",
      "Epoch 97/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8448 - loss: 0.3874\n",
      "Epoch 98/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8428 - loss: 0.3935\n",
      "Epoch 99/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8384 - loss: 0.4005\n",
      "Epoch 100/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8407 - loss: 0.3972\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7894 - loss: 0.6478  \n",
      "Epoch 2/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8008 - loss: 0.4366  \n",
      "Epoch 3/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7994 - loss: 0.4283  \n",
      "Epoch 4/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7929 - loss: 0.4417\n",
      "Epoch 5/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7887 - loss: 0.4380\n",
      "Epoch 6/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7979 - loss: 0.4284\n",
      "Epoch 7/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8053 - loss: 0.4093\n",
      "Epoch 8/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8199 - loss: 0.4166\n",
      "Epoch 9/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8221 - loss: 0.4202\n",
      "Epoch 10/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8183 - loss: 0.4161  \n",
      "Epoch 11/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8257 - loss: 0.4109  \n",
      "Epoch 12/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8267 - loss: 0.4175  \n",
      "Epoch 13/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8287 - loss: 0.4085\n",
      "Epoch 14/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8318 - loss: 0.4047\n",
      "Epoch 15/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8217 - loss: 0.4205\n",
      "Epoch 16/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8281 - loss: 0.4180  \n",
      "Epoch 17/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8343 - loss: 0.4048\n",
      "Epoch 18/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8297 - loss: 0.4172  \n",
      "Epoch 19/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 0.8377 - loss: 0.4051\n",
      "Epoch 20/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8340 - loss: 0.4094\n",
      "Epoch 21/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8409 - loss: 0.3979\n",
      "Epoch 22/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8355 - loss: 0.4125\n",
      "Epoch 23/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8320 - loss: 0.4155\n",
      "Epoch 24/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8357 - loss: 0.4074\n",
      "Epoch 25/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8348 - loss: 0.4166\n",
      "Epoch 26/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8371 - loss: 0.3970\n",
      "Epoch 27/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8466 - loss: 0.3879\n",
      "Epoch 28/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8363 - loss: 0.4082\n",
      "Epoch 29/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8247 - loss: 0.4247\n",
      "Epoch 30/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8414 - loss: 0.3947  \n",
      "Epoch 31/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8351 - loss: 0.4026\n",
      "Epoch 32/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8351 - loss: 0.4017\n",
      "Epoch 33/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8291 - loss: 0.4167\n",
      "Epoch 34/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8326 - loss: 0.4008\n",
      "Epoch 35/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8336 - loss: 0.4097\n",
      "Epoch 36/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8241 - loss: 0.4183\n",
      "Epoch 37/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8432 - loss: 0.3923\n",
      "Epoch 38/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8327 - loss: 0.4095\n",
      "Epoch 39/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8287 - loss: 0.4099\n",
      "Epoch 40/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8427 - loss: 0.3948\n",
      "Epoch 41/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8384 - loss: 0.3955\n",
      "Epoch 42/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8330 - loss: 0.4095\n",
      "Epoch 43/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8381 - loss: 0.4006\n",
      "Epoch 44/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8361 - loss: 0.4011\n",
      "Epoch 45/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8306 - loss: 0.4093\n",
      "Epoch 46/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8336 - loss: 0.4086\n",
      "Epoch 47/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8334 - loss: 0.4084\n",
      "Epoch 48/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8343 - loss: 0.4029\n",
      "Epoch 49/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8315 - loss: 0.4090\n",
      "Epoch 50/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8346 - loss: 0.3936\n",
      "Epoch 51/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8365 - loss: 0.4049\n",
      "Epoch 52/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8392 - loss: 0.3970\n",
      "Epoch 53/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8342 - loss: 0.3954\n",
      "Epoch 54/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8366 - loss: 0.4003\n",
      "Epoch 55/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8406 - loss: 0.3846\n",
      "Epoch 56/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8363 - loss: 0.3975\n",
      "Epoch 57/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8358 - loss: 0.3959\n",
      "Epoch 58/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8436 - loss: 0.3925\n",
      "Epoch 59/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8354 - loss: 0.4018\n",
      "Epoch 60/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8347 - loss: 0.4012\n",
      "Epoch 61/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8348 - loss: 0.4103\n",
      "Epoch 62/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8375 - loss: 0.3982  \n",
      "Epoch 63/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8394 - loss: 0.3976\n",
      "Epoch 64/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8365 - loss: 0.3985\n",
      "Epoch 65/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8317 - loss: 0.4032\n",
      "Epoch 66/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8360 - loss: 0.3960\n",
      "Epoch 67/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8347 - loss: 0.4074\n",
      "Epoch 68/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8380 - loss: 0.3904\n",
      "Epoch 69/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8427 - loss: 0.3890\n",
      "Epoch 70/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8374 - loss: 0.3941\n",
      "Epoch 71/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8401 - loss: 0.3986\n",
      "Epoch 72/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8334 - loss: 0.4007\n",
      "Epoch 73/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8437 - loss: 0.3884\n",
      "Epoch 74/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8363 - loss: 0.3983\n",
      "Epoch 75/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8390 - loss: 0.4009\n",
      "Epoch 76/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8327 - loss: 0.4058\n",
      "Epoch 77/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8352 - loss: 0.4001\n",
      "Epoch 78/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8415 - loss: 0.3862\n",
      "Epoch 79/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8367 - loss: 0.4002\n",
      "Epoch 80/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8400 - loss: 0.3932\n",
      "Epoch 81/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8334 - loss: 0.4064\n",
      "Epoch 82/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8396 - loss: 0.3903\n",
      "Epoch 83/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8327 - loss: 0.4003\n",
      "Epoch 84/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8382 - loss: 0.3896\n",
      "Epoch 85/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8327 - loss: 0.4073\n",
      "Epoch 86/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8438 - loss: 0.3839  \n",
      "Epoch 87/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8303 - loss: 0.4048\n",
      "Epoch 88/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8335 - loss: 0.4026\n",
      "Epoch 89/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8288 - loss: 0.4040\n",
      "Epoch 90/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8337 - loss: 0.4067\n",
      "Epoch 91/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8427 - loss: 0.3933\n",
      "Epoch 92/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8329 - loss: 0.4036\n",
      "Epoch 93/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8414 - loss: 0.3902\n",
      "Epoch 94/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8388 - loss: 0.3900\n",
      "Epoch 95/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8352 - loss: 0.3955\n",
      "Epoch 96/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8471 - loss: 0.3781\n",
      "Epoch 97/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8340 - loss: 0.4034\n",
      "Epoch 98/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8308 - loss: 0.4046\n",
      "Epoch 99/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8401 - loss: 0.3868\n",
      "Epoch 100/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8406 - loss: 0.3950\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7831 - loss: 0.6460\n",
      "Epoch 2/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8037 - loss: 0.4346\n",
      "Epoch 3/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8037 - loss: 0.4228\n",
      "Epoch 4/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7870 - loss: 0.4445\n",
      "Epoch 5/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7920 - loss: 0.4294\n",
      "Epoch 6/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8081 - loss: 0.4258\n",
      "Epoch 7/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8256 - loss: 0.4179\n",
      "Epoch 8/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8389 - loss: 0.4077\n",
      "Epoch 9/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8340 - loss: 0.4082\n",
      "Epoch 10/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8418 - loss: 0.3979\n",
      "Epoch 11/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8353 - loss: 0.4120\n",
      "Epoch 12/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8366 - loss: 0.4042\n",
      "Epoch 13/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8395 - loss: 0.4034\n",
      "Epoch 14/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8419 - loss: 0.3966\n",
      "Epoch 15/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8402 - loss: 0.3932\n",
      "Epoch 16/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8351 - loss: 0.4059\n",
      "Epoch 17/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8300 - loss: 0.4070\n",
      "Epoch 18/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8328 - loss: 0.4085\n",
      "Epoch 19/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8363 - loss: 0.3955\n",
      "Epoch 20/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8394 - loss: 0.3972\n",
      "Epoch 21/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8464 - loss: 0.3843\n",
      "Epoch 22/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8359 - loss: 0.4010\n",
      "Epoch 23/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8416 - loss: 0.3901\n",
      "Epoch 24/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8396 - loss: 0.3968\n",
      "Epoch 25/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8349 - loss: 0.3981\n",
      "Epoch 26/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8391 - loss: 0.3953\n",
      "Epoch 27/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8411 - loss: 0.3920\n",
      "Epoch 28/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8428 - loss: 0.3870\n",
      "Epoch 29/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8453 - loss: 0.3894\n",
      "Epoch 30/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8377 - loss: 0.3963\n",
      "Epoch 31/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8411 - loss: 0.3956\n",
      "Epoch 32/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8404 - loss: 0.3898\n",
      "Epoch 33/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8408 - loss: 0.3908\n",
      "Epoch 34/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8367 - loss: 0.3948\n",
      "Epoch 35/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8377 - loss: 0.3901\n",
      "Epoch 36/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8378 - loss: 0.3946\n",
      "Epoch 37/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8371 - loss: 0.4021\n",
      "Epoch 38/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8375 - loss: 0.4017\n",
      "Epoch 39/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8363 - loss: 0.3984\n",
      "Epoch 40/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8386 - loss: 0.3911\n",
      "Epoch 41/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8384 - loss: 0.3924\n",
      "Epoch 42/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8383 - loss: 0.3913  \n",
      "Epoch 43/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 0.8407 - loss: 0.3938\n",
      "Epoch 44/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8340 - loss: 0.4018\n",
      "Epoch 45/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8427 - loss: 0.3885  \n",
      "Epoch 46/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8425 - loss: 0.3830\n",
      "Epoch 47/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - accuracy: 0.8277 - loss: 0.4030\n",
      "Epoch 48/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8436 - loss: 0.3876\n",
      "Epoch 49/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8381 - loss: 0.3917  \n",
      "Epoch 50/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8395 - loss: 0.3858  \n",
      "Epoch 51/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8327 - loss: 0.4070  \n",
      "Epoch 52/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8384 - loss: 0.3895\n",
      "Epoch 53/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8367 - loss: 0.3953\n",
      "Epoch 54/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8376 - loss: 0.3990\n",
      "Epoch 55/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8418 - loss: 0.3901\n",
      "Epoch 56/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8376 - loss: 0.3938\n",
      "Epoch 57/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8410 - loss: 0.3924\n",
      "Epoch 58/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8306 - loss: 0.3994\n",
      "Epoch 59/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8392 - loss: 0.3973\n",
      "Epoch 60/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8361 - loss: 0.4012  \n",
      "Epoch 61/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8413 - loss: 0.3882\n",
      "Epoch 62/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8451 - loss: 0.3891\n",
      "Epoch 63/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8402 - loss: 0.3917\n",
      "Epoch 64/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8384 - loss: 0.3922\n",
      "Epoch 65/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8421 - loss: 0.3868\n",
      "Epoch 66/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8378 - loss: 0.3949\n",
      "Epoch 67/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8423 - loss: 0.3945\n",
      "Epoch 68/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8475 - loss: 0.3796\n",
      "Epoch 69/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8402 - loss: 0.3934\n",
      "Epoch 70/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8418 - loss: 0.3944\n",
      "Epoch 71/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8428 - loss: 0.3886\n",
      "Epoch 72/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8398 - loss: 0.3938\n",
      "Epoch 73/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8473 - loss: 0.3755\n",
      "Epoch 74/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8428 - loss: 0.3880\n",
      "Epoch 75/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8474 - loss: 0.3782\n",
      "Epoch 76/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8455 - loss: 0.3861\n",
      "Epoch 77/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8490 - loss: 0.3723\n",
      "Epoch 78/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8433 - loss: 0.3790\n",
      "Epoch 79/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8481 - loss: 0.3729\n",
      "Epoch 80/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8489 - loss: 0.3777\n",
      "Epoch 81/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8435 - loss: 0.3701\n",
      "Epoch 82/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8510 - loss: 0.3636\n",
      "Epoch 83/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8500 - loss: 0.3641\n",
      "Epoch 84/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8571 - loss: 0.3567\n",
      "Epoch 85/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8566 - loss: 0.3523\n",
      "Epoch 86/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8614 - loss: 0.3433\n",
      "Epoch 87/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8536 - loss: 0.3597\n",
      "Epoch 88/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8606 - loss: 0.3426\n",
      "Epoch 89/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8552 - loss: 0.3509\n",
      "Epoch 90/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8558 - loss: 0.3557\n",
      "Epoch 91/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8604 - loss: 0.3586\n",
      "Epoch 92/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8559 - loss: 0.3475\n",
      "Epoch 93/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8597 - loss: 0.3438\n",
      "Epoch 94/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8587 - loss: 0.3503\n",
      "Epoch 95/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8582 - loss: 0.3476\n",
      "Epoch 96/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8577 - loss: 0.3563\n",
      "Epoch 97/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8601 - loss: 0.3423\n",
      "Epoch 98/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8549 - loss: 0.3505\n",
      "Epoch 99/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8593 - loss: 0.3435\n",
      "Epoch 100/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8686 - loss: 0.3343\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7882 - loss: 0.6502\n",
      "Epoch 2/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7949 - loss: 0.4430\n",
      "Epoch 3/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8028 - loss: 0.4262\n",
      "Epoch 4/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8144 - loss: 0.4014\n",
      "Epoch 5/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8267 - loss: 0.3845\n",
      "Epoch 6/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8533 - loss: 0.3637\n",
      "Epoch 7/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8614 - loss: 0.3566\n",
      "Epoch 8/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8632 - loss: 0.3475\n",
      "Epoch 9/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8618 - loss: 0.3442\n",
      "Epoch 10/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8672 - loss: 0.3406\n",
      "Epoch 11/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8594 - loss: 0.3414\n",
      "Epoch 12/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8612 - loss: 0.3486\n",
      "Epoch 13/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8513 - loss: 0.3638\n",
      "Epoch 14/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8506 - loss: 0.3542\n",
      "Epoch 15/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8524 - loss: 0.3526\n",
      "Epoch 16/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8530 - loss: 0.3518\n",
      "Epoch 17/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8572 - loss: 0.3559\n",
      "Epoch 18/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8551 - loss: 0.3575\n",
      "Epoch 19/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8597 - loss: 0.3453\n",
      "Epoch 20/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8687 - loss: 0.3305\n",
      "Epoch 21/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8574 - loss: 0.3443\n",
      "Epoch 22/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8579 - loss: 0.3462\n",
      "Epoch 23/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8627 - loss: 0.3443\n",
      "Epoch 24/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8607 - loss: 0.3413\n",
      "Epoch 25/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8576 - loss: 0.3478\n",
      "Epoch 26/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8607 - loss: 0.3371\n",
      "Epoch 27/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8612 - loss: 0.3323\n",
      "Epoch 28/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8601 - loss: 0.3429\n",
      "Epoch 29/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8641 - loss: 0.3398\n",
      "Epoch 30/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8559 - loss: 0.3436\n",
      "Epoch 31/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8611 - loss: 0.3418\n",
      "Epoch 32/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8574 - loss: 0.3410\n",
      "Epoch 33/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8706 - loss: 0.3276\n",
      "Epoch 34/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8605 - loss: 0.3460\n",
      "Epoch 35/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8607 - loss: 0.3404\n",
      "Epoch 36/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8632 - loss: 0.3388\n",
      "Epoch 37/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8595 - loss: 0.3353\n",
      "Epoch 38/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8594 - loss: 0.3474\n",
      "Epoch 39/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8561 - loss: 0.3400\n",
      "Epoch 40/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8565 - loss: 0.3376\n",
      "Epoch 41/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8681 - loss: 0.3318\n",
      "Epoch 42/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8634 - loss: 0.3332\n",
      "Epoch 43/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8610 - loss: 0.3366\n",
      "Epoch 44/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8533 - loss: 0.3439\n",
      "Epoch 45/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8559 - loss: 0.3481\n",
      "Epoch 46/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8656 - loss: 0.3288\n",
      "Epoch 47/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8559 - loss: 0.3487\n",
      "Epoch 48/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8679 - loss: 0.3318\n",
      "Epoch 49/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8642 - loss: 0.3325\n",
      "Epoch 50/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8598 - loss: 0.3441\n",
      "Epoch 51/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8572 - loss: 0.3503\n",
      "Epoch 52/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8630 - loss: 0.3352\n",
      "Epoch 53/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8650 - loss: 0.3292\n",
      "Epoch 54/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8628 - loss: 0.3342\n",
      "Epoch 55/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8584 - loss: 0.3389\n",
      "Epoch 56/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8632 - loss: 0.3303\n",
      "Epoch 57/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8683 - loss: 0.3268\n",
      "Epoch 58/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8659 - loss: 0.3322\n",
      "Epoch 59/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8676 - loss: 0.3372\n",
      "Epoch 60/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8630 - loss: 0.3314\n",
      "Epoch 61/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8549 - loss: 0.3441\n",
      "Epoch 62/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8575 - loss: 0.3485\n",
      "Epoch 63/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8672 - loss: 0.3352\n",
      "Epoch 64/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8661 - loss: 0.3378\n",
      "Epoch 65/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8650 - loss: 0.3326\n",
      "Epoch 66/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8660 - loss: 0.3315\n",
      "Epoch 67/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8598 - loss: 0.3361\n",
      "Epoch 68/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8614 - loss: 0.3440\n",
      "Epoch 69/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8623 - loss: 0.3351\n",
      "Epoch 70/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8606 - loss: 0.3295\n",
      "Epoch 71/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8598 - loss: 0.3398\n",
      "Epoch 72/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8706 - loss: 0.3160\n",
      "Epoch 73/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8594 - loss: 0.3406\n",
      "Epoch 74/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8673 - loss: 0.3365\n",
      "Epoch 75/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8751 - loss: 0.3255\n",
      "Epoch 76/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8712 - loss: 0.3207\n",
      "Epoch 77/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8571 - loss: 0.3476\n",
      "Epoch 78/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8593 - loss: 0.3492\n",
      "Epoch 79/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8643 - loss: 0.3391\n",
      "Epoch 80/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8724 - loss: 0.3236\n",
      "Epoch 81/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8664 - loss: 0.3221\n",
      "Epoch 82/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8596 - loss: 0.3418\n",
      "Epoch 83/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8654 - loss: 0.3339\n",
      "Epoch 84/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8653 - loss: 0.3328\n",
      "Epoch 85/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8684 - loss: 0.3289\n",
      "Epoch 86/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8585 - loss: 0.3402\n",
      "Epoch 87/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8612 - loss: 0.3420\n",
      "Epoch 88/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8601 - loss: 0.3371\n",
      "Epoch 89/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8647 - loss: 0.3333\n",
      "Epoch 90/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8661 - loss: 0.3358\n",
      "Epoch 91/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8649 - loss: 0.3377\n",
      "Epoch 92/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8657 - loss: 0.3303\n",
      "Epoch 93/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8639 - loss: 0.3363\n",
      "Epoch 94/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8617 - loss: 0.3356\n",
      "Epoch 95/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8676 - loss: 0.3231\n",
      "Epoch 96/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8651 - loss: 0.3276\n",
      "Epoch 97/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8600 - loss: 0.3370\n",
      "Epoch 98/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8644 - loss: 0.3346\n",
      "Epoch 99/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8728 - loss: 0.3203\n",
      "Epoch 100/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8610 - loss: 0.3369\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7852 - loss: 0.6441\n",
      "Epoch 2/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7952 - loss: 0.4426\n",
      "Epoch 3/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7948 - loss: 0.4351\n",
      "Epoch 4/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7942 - loss: 0.4336\n",
      "Epoch 5/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8016 - loss: 0.4283\n",
      "Epoch 6/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7988 - loss: 0.4252\n",
      "Epoch 7/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8079 - loss: 0.4345\n",
      "Epoch 8/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8235 - loss: 0.4217\n",
      "Epoch 9/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8341 - loss: 0.4011\n",
      "Epoch 10/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8290 - loss: 0.4155\n",
      "Epoch 11/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8395 - loss: 0.3955\n",
      "Epoch 12/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8276 - loss: 0.4086\n",
      "Epoch 13/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8365 - loss: 0.4001\n",
      "Epoch 14/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8377 - loss: 0.3991\n",
      "Epoch 15/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8362 - loss: 0.3961\n",
      "Epoch 16/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8427 - loss: 0.3915\n",
      "Epoch 17/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8439 - loss: 0.3906\n",
      "Epoch 18/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8383 - loss: 0.4049\n",
      "Epoch 19/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8348 - loss: 0.4045\n",
      "Epoch 20/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8477 - loss: 0.3844\n",
      "Epoch 21/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8345 - loss: 0.3975\n",
      "Epoch 22/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8356 - loss: 0.4011\n",
      "Epoch 23/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8406 - loss: 0.3998\n",
      "Epoch 24/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8335 - loss: 0.4047\n",
      "Epoch 25/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8399 - loss: 0.3919\n",
      "Epoch 26/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8374 - loss: 0.3984\n",
      "Epoch 27/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8295 - loss: 0.4096\n",
      "Epoch 28/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8434 - loss: 0.3868\n",
      "Epoch 29/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8334 - loss: 0.4020\n",
      "Epoch 30/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8385 - loss: 0.3994\n",
      "Epoch 31/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8415 - loss: 0.3878\n",
      "Epoch 32/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8444 - loss: 0.3921\n",
      "Epoch 33/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8433 - loss: 0.3841\n",
      "Epoch 34/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8369 - loss: 0.3999\n",
      "Epoch 35/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8431 - loss: 0.3876\n",
      "Epoch 36/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8403 - loss: 0.3893\n",
      "Epoch 37/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8435 - loss: 0.3838\n",
      "Epoch 38/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8381 - loss: 0.3943\n",
      "Epoch 39/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8372 - loss: 0.3989\n",
      "Epoch 40/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8361 - loss: 0.3972\n",
      "Epoch 41/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8390 - loss: 0.3922\n",
      "Epoch 42/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8402 - loss: 0.3897\n",
      "Epoch 43/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8345 - loss: 0.4015\n",
      "Epoch 44/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8479 - loss: 0.3835\n",
      "Epoch 45/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8365 - loss: 0.3999\n",
      "Epoch 46/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8331 - loss: 0.4079\n",
      "Epoch 47/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8417 - loss: 0.3926\n",
      "Epoch 48/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8435 - loss: 0.3907\n",
      "Epoch 49/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8323 - loss: 0.3999\n",
      "Epoch 50/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8354 - loss: 0.3935\n",
      "Epoch 51/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8379 - loss: 0.3977\n",
      "Epoch 52/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8390 - loss: 0.3954\n",
      "Epoch 53/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8432 - loss: 0.3818\n",
      "Epoch 54/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8431 - loss: 0.3848\n",
      "Epoch 55/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8394 - loss: 0.3915\n",
      "Epoch 56/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8380 - loss: 0.3923\n",
      "Epoch 57/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8349 - loss: 0.3985\n",
      "Epoch 58/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8381 - loss: 0.3914\n",
      "Epoch 59/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8409 - loss: 0.3865\n",
      "Epoch 60/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8463 - loss: 0.3830\n",
      "Epoch 61/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8405 - loss: 0.3936\n",
      "Epoch 62/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8430 - loss: 0.3875\n",
      "Epoch 63/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8416 - loss: 0.3874\n",
      "Epoch 64/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8344 - loss: 0.3985\n",
      "Epoch 65/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8350 - loss: 0.3954\n",
      "Epoch 66/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8346 - loss: 0.3992\n",
      "Epoch 67/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8375 - loss: 0.3989\n",
      "Epoch 68/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8425 - loss: 0.3895\n",
      "Epoch 69/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8454 - loss: 0.3824\n",
      "Epoch 70/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8330 - loss: 0.4057\n",
      "Epoch 71/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8405 - loss: 0.3908\n",
      "Epoch 72/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8429 - loss: 0.3879\n",
      "Epoch 73/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8486 - loss: 0.3808\n",
      "Epoch 74/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8491 - loss: 0.3825\n",
      "Epoch 75/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8412 - loss: 0.3869\n",
      "Epoch 76/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8420 - loss: 0.3782\n",
      "Epoch 77/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8383 - loss: 0.3931\n",
      "Epoch 78/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8352 - loss: 0.3978\n",
      "Epoch 79/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8476 - loss: 0.3764\n",
      "Epoch 80/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8437 - loss: 0.3800\n",
      "Epoch 81/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8473 - loss: 0.3733\n",
      "Epoch 82/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8498 - loss: 0.3659\n",
      "Epoch 83/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8374 - loss: 0.3843\n",
      "Epoch 84/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8443 - loss: 0.3800\n",
      "Epoch 85/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8421 - loss: 0.3764\n",
      "Epoch 86/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8377 - loss: 0.3833\n",
      "Epoch 87/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8323 - loss: 0.3866\n",
      "Epoch 88/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8416 - loss: 0.3684\n",
      "Epoch 89/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8475 - loss: 0.3664\n",
      "Epoch 90/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8389 - loss: 0.3773\n",
      "Epoch 91/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8501 - loss: 0.3623\n",
      "Epoch 92/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8417 - loss: 0.3763\n",
      "Epoch 93/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8509 - loss: 0.3593\n",
      "Epoch 94/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8433 - loss: 0.3634\n",
      "Epoch 95/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8467 - loss: 0.3661\n",
      "Epoch 96/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8518 - loss: 0.3587\n",
      "Epoch 97/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8491 - loss: 0.3713\n",
      "Epoch 98/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8399 - loss: 0.3656\n",
      "Epoch 99/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8472 - loss: 0.3581\n",
      "Epoch 100/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8453 - loss: 0.3679\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8018 - loss: 0.6279\n",
      "Epoch 2/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7993 - loss: 0.4399\n",
      "Epoch 3/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7964 - loss: 0.4383\n",
      "Epoch 4/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7990 - loss: 0.4217\n",
      "Epoch 5/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8003 - loss: 0.4195\n",
      "Epoch 6/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8070 - loss: 0.4179\n",
      "Epoch 7/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8230 - loss: 0.4175\n",
      "Epoch 8/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8201 - loss: 0.4198\n",
      "Epoch 9/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8253 - loss: 0.4166\n",
      "Epoch 10/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8237 - loss: 0.4247\n",
      "Epoch 11/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8281 - loss: 0.4199\n",
      "Epoch 12/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8294 - loss: 0.4118\n",
      "Epoch 13/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8275 - loss: 0.4184\n",
      "Epoch 14/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8298 - loss: 0.4134\n",
      "Epoch 15/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8345 - loss: 0.4061\n",
      "Epoch 16/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8305 - loss: 0.4153\n",
      "Epoch 17/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8322 - loss: 0.4190\n",
      "Epoch 18/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8307 - loss: 0.4101\n",
      "Epoch 19/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8314 - loss: 0.4116\n",
      "Epoch 20/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8373 - loss: 0.4072\n",
      "Epoch 21/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8306 - loss: 0.4188\n",
      "Epoch 22/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8375 - loss: 0.4108\n",
      "Epoch 23/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8372 - loss: 0.4099\n",
      "Epoch 24/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8407 - loss: 0.4039\n",
      "Epoch 25/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8305 - loss: 0.4130\n",
      "Epoch 26/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8420 - loss: 0.3942\n",
      "Epoch 27/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8365 - loss: 0.4051\n",
      "Epoch 28/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8302 - loss: 0.4124\n",
      "Epoch 29/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8259 - loss: 0.4178\n",
      "Epoch 30/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8324 - loss: 0.4077\n",
      "Epoch 31/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8308 - loss: 0.4083\n",
      "Epoch 32/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8367 - loss: 0.4069\n",
      "Epoch 33/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8372 - loss: 0.3927\n",
      "Epoch 34/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8327 - loss: 0.4019\n",
      "Epoch 35/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8319 - loss: 0.4127\n",
      "Epoch 36/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8329 - loss: 0.4107\n",
      "Epoch 37/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8396 - loss: 0.3951\n",
      "Epoch 38/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8330 - loss: 0.4021\n",
      "Epoch 39/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8350 - loss: 0.4008\n",
      "Epoch 40/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8314 - loss: 0.4051\n",
      "Epoch 41/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8462 - loss: 0.3925\n",
      "Epoch 42/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8375 - loss: 0.3980\n",
      "Epoch 43/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8359 - loss: 0.4040\n",
      "Epoch 44/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8312 - loss: 0.4115\n",
      "Epoch 45/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8350 - loss: 0.4013\n",
      "Epoch 46/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8389 - loss: 0.4005\n",
      "Epoch 47/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8417 - loss: 0.3975\n",
      "Epoch 48/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8370 - loss: 0.4039\n",
      "Epoch 49/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8401 - loss: 0.3927\n",
      "Epoch 50/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8299 - loss: 0.4093\n",
      "Epoch 51/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8390 - loss: 0.3915\n",
      "Epoch 52/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8450 - loss: 0.3962\n",
      "Epoch 53/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8332 - loss: 0.3995\n",
      "Epoch 54/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8324 - loss: 0.4108\n",
      "Epoch 55/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8340 - loss: 0.3929\n",
      "Epoch 56/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8360 - loss: 0.4037\n",
      "Epoch 57/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8366 - loss: 0.3991\n",
      "Epoch 58/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8367 - loss: 0.4020\n",
      "Epoch 59/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8331 - loss: 0.4048\n",
      "Epoch 60/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8428 - loss: 0.3966\n",
      "Epoch 61/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8317 - loss: 0.4071\n",
      "Epoch 62/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8428 - loss: 0.3909\n",
      "Epoch 63/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8394 - loss: 0.3979\n",
      "Epoch 64/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8428 - loss: 0.3903\n",
      "Epoch 65/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8389 - loss: 0.3933\n",
      "Epoch 66/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8349 - loss: 0.4005\n",
      "Epoch 67/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8312 - loss: 0.4106\n",
      "Epoch 68/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8433 - loss: 0.3929\n",
      "Epoch 69/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8400 - loss: 0.3968\n",
      "Epoch 70/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8299 - loss: 0.4028\n",
      "Epoch 71/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8361 - loss: 0.3977\n",
      "Epoch 72/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8375 - loss: 0.4002\n",
      "Epoch 73/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8380 - loss: 0.4011\n",
      "Epoch 74/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8407 - loss: 0.3876\n",
      "Epoch 75/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8412 - loss: 0.3941\n",
      "Epoch 76/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8405 - loss: 0.3941\n",
      "Epoch 77/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8426 - loss: 0.3916\n",
      "Epoch 78/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8447 - loss: 0.3851\n",
      "Epoch 79/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8358 - loss: 0.3980\n",
      "Epoch 80/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8350 - loss: 0.4006\n",
      "Epoch 81/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8312 - loss: 0.4116\n",
      "Epoch 82/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8372 - loss: 0.3965\n",
      "Epoch 83/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8257 - loss: 0.4171  \n",
      "Epoch 84/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8430 - loss: 0.3886\n",
      "Epoch 85/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8370 - loss: 0.3980\n",
      "Epoch 86/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8383 - loss: 0.4008\n",
      "Epoch 87/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8412 - loss: 0.3977\n",
      "Epoch 88/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8309 - loss: 0.4119\n",
      "Epoch 89/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8349 - loss: 0.4024\n",
      "Epoch 90/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8363 - loss: 0.4036\n",
      "Epoch 91/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8363 - loss: 0.3994\n",
      "Epoch 92/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8357 - loss: 0.4052\n",
      "Epoch 93/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8350 - loss: 0.4060\n",
      "Epoch 94/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8411 - loss: 0.4006\n",
      "Epoch 95/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8466 - loss: 0.3855  \n",
      "Epoch 96/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8346 - loss: 0.4028\n",
      "Epoch 97/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8288 - loss: 0.4082\n",
      "Epoch 98/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8406 - loss: 0.3960  \n",
      "Epoch 99/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8420 - loss: 0.3934  \n",
      "Epoch 100/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8406 - loss: 0.4040\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7923 - loss: 0.6370  \n",
      "Epoch 2/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7916 - loss: 0.4468  \n",
      "Epoch 3/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.7917 - loss: 0.4389\n",
      "Epoch 4/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7993 - loss: 0.4294\n",
      "Epoch 5/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7909 - loss: 0.4424  \n",
      "Epoch 6/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8136 - loss: 0.4068  \n",
      "Epoch 7/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.8033 - loss: 0.4189\n",
      "Epoch 8/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8214 - loss: 0.4198\n",
      "Epoch 9/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8258 - loss: 0.4235\n",
      "Epoch 10/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 0.8321 - loss: 0.4057\n",
      "Epoch 11/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8270 - loss: 0.4157  \n",
      "Epoch 12/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - accuracy: 0.8314 - loss: 0.4161\n",
      "Epoch 13/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8282 - loss: 0.4135  \n",
      "Epoch 14/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8344 - loss: 0.4106  \n",
      "Epoch 15/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8362 - loss: 0.4036  \n",
      "Epoch 16/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8327 - loss: 0.4168  \n",
      "Epoch 17/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8381 - loss: 0.4004\n",
      "Epoch 18/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8346 - loss: 0.4093\n",
      "Epoch 19/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8300 - loss: 0.4196  \n",
      "Epoch 20/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8396 - loss: 0.4055\n",
      "Epoch 21/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8273 - loss: 0.4201\n",
      "Epoch 22/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8359 - loss: 0.4094\n",
      "Epoch 23/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8229 - loss: 0.4271\n",
      "Epoch 24/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8347 - loss: 0.4071\n",
      "Epoch 25/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8332 - loss: 0.4117\n",
      "Epoch 26/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8371 - loss: 0.4082\n",
      "Epoch 27/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8350 - loss: 0.4090\n",
      "Epoch 28/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8331 - loss: 0.4087\n",
      "Epoch 29/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8355 - loss: 0.4085\n",
      "Epoch 30/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8371 - loss: 0.4012\n",
      "Epoch 31/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8384 - loss: 0.4025  \n",
      "Epoch 32/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8444 - loss: 0.3919\n",
      "Epoch 33/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8360 - loss: 0.3972\n",
      "Epoch 34/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8370 - loss: 0.4092\n",
      "Epoch 35/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8444 - loss: 0.3974\n",
      "Epoch 36/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8333 - loss: 0.4036\n",
      "Epoch 37/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8369 - loss: 0.4029\n",
      "Epoch 38/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8376 - loss: 0.3972\n",
      "Epoch 39/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8391 - loss: 0.3980\n",
      "Epoch 40/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8366 - loss: 0.4109\n",
      "Epoch 41/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8264 - loss: 0.4154\n",
      "Epoch 42/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8398 - loss: 0.4071\n",
      "Epoch 43/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8430 - loss: 0.3955\n",
      "Epoch 44/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8324 - loss: 0.4074\n",
      "Epoch 45/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8432 - loss: 0.3961\n",
      "Epoch 46/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8351 - loss: 0.4057\n",
      "Epoch 47/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8317 - loss: 0.4105\n",
      "Epoch 48/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8402 - loss: 0.3979\n",
      "Epoch 49/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8352 - loss: 0.4041\n",
      "Epoch 50/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8434 - loss: 0.3906\n",
      "Epoch 51/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8408 - loss: 0.3922\n",
      "Epoch 52/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8366 - loss: 0.3927\n",
      "Epoch 53/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8366 - loss: 0.4034\n",
      "Epoch 54/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8379 - loss: 0.3983\n",
      "Epoch 55/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8333 - loss: 0.4102\n",
      "Epoch 56/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8333 - loss: 0.4103  \n",
      "Epoch 57/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8335 - loss: 0.4028\n",
      "Epoch 58/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8433 - loss: 0.3984\n",
      "Epoch 59/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8361 - loss: 0.4035\n",
      "Epoch 60/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8325 - loss: 0.4028\n",
      "Epoch 61/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8399 - loss: 0.3994\n",
      "Epoch 62/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8377 - loss: 0.4029\n",
      "Epoch 63/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8446 - loss: 0.3918\n",
      "Epoch 64/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8407 - loss: 0.4016\n",
      "Epoch 65/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.4015\n",
      "Epoch 66/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8388 - loss: 0.4010\n",
      "Epoch 67/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8376 - loss: 0.4005\n",
      "Epoch 68/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8380 - loss: 0.3985\n",
      "Epoch 69/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8320 - loss: 0.4055\n",
      "Epoch 70/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8302 - loss: 0.4122\n",
      "Epoch 71/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8364 - loss: 0.4088\n",
      "Epoch 72/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8399 - loss: 0.4037\n",
      "Epoch 73/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8421 - loss: 0.3988\n",
      "Epoch 74/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8343 - loss: 0.4041\n",
      "Epoch 75/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8364 - loss: 0.4096\n",
      "Epoch 76/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8463 - loss: 0.3856\n",
      "Epoch 77/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8449 - loss: 0.3865\n",
      "Epoch 78/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8306 - loss: 0.4034\n",
      "Epoch 79/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8352 - loss: 0.4054\n",
      "Epoch 80/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8392 - loss: 0.3954\n",
      "Epoch 81/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8409 - loss: 0.3989\n",
      "Epoch 82/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8422 - loss: 0.3918\n",
      "Epoch 83/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8364 - loss: 0.4073\n",
      "Epoch 84/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8393 - loss: 0.3964\n",
      "Epoch 85/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8359 - loss: 0.3952\n",
      "Epoch 86/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8389 - loss: 0.3948\n",
      "Epoch 87/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8354 - loss: 0.4071\n",
      "Epoch 88/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8290 - loss: 0.4150\n",
      "Epoch 89/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8331 - loss: 0.4048\n",
      "Epoch 90/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8349 - loss: 0.4049\n",
      "Epoch 91/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8327 - loss: 0.4127\n",
      "Epoch 92/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8384 - loss: 0.4007\n",
      "Epoch 93/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8395 - loss: 0.3983\n",
      "Epoch 94/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8394 - loss: 0.3888\n",
      "Epoch 95/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8362 - loss: 0.3997\n",
      "Epoch 96/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8365 - loss: 0.3995\n",
      "Epoch 97/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8323 - loss: 0.4113\n",
      "Epoch 98/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8339 - loss: 0.4020\n",
      "Epoch 99/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8391 - loss: 0.4019\n",
      "Epoch 100/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8401 - loss: 0.3949\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7874 - loss: 0.6402\n",
      "Epoch 2/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7988 - loss: 0.4427\n",
      "Epoch 3/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7973 - loss: 0.4293\n",
      "Epoch 4/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8033 - loss: 0.4168\n",
      "Epoch 5/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8041 - loss: 0.4266\n",
      "Epoch 6/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7964 - loss: 0.4253\n",
      "Epoch 7/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7962 - loss: 0.4218\n",
      "Epoch 8/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8097 - loss: 0.4299\n",
      "Epoch 9/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8254 - loss: 0.4198\n",
      "Epoch 10/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8324 - loss: 0.4059\n",
      "Epoch 11/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8261 - loss: 0.4205\n",
      "Epoch 12/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8282 - loss: 0.4136\n",
      "Epoch 13/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8344 - loss: 0.4029  \n",
      "Epoch 14/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8235 - loss: 0.4149\n",
      "Epoch 15/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8354 - loss: 0.4072\n",
      "Epoch 16/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8305 - loss: 0.4200\n",
      "Epoch 17/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8455 - loss: 0.3933\n",
      "Epoch 18/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8373 - loss: 0.4048  \n",
      "Epoch 19/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8342 - loss: 0.4173\n",
      "Epoch 20/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8366 - loss: 0.4038\n",
      "Epoch 21/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8394 - loss: 0.4041\n",
      "Epoch 22/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8351 - loss: 0.4081\n",
      "Epoch 23/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8360 - loss: 0.4081\n",
      "Epoch 24/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8230 - loss: 0.4248\n",
      "Epoch 25/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8410 - loss: 0.3966\n",
      "Epoch 26/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.8384 - loss: 0.4119\n",
      "Epoch 27/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8327 - loss: 0.4132\n",
      "Epoch 28/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8379 - loss: 0.4073\n",
      "Epoch 29/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8357 - loss: 0.4071\n",
      "Epoch 30/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8376 - loss: 0.3998\n",
      "Epoch 31/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8329 - loss: 0.4076\n",
      "Epoch 32/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8347 - loss: 0.4050\n",
      "Epoch 33/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8289 - loss: 0.4200\n",
      "Epoch 34/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8374 - loss: 0.3987  \n",
      "Epoch 35/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8301 - loss: 0.4153\n",
      "Epoch 36/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8342 - loss: 0.4124\n",
      "Epoch 37/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8430 - loss: 0.3982\n",
      "Epoch 38/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8351 - loss: 0.4059\n",
      "Epoch 39/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8320 - loss: 0.4112\n",
      "Epoch 40/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8379 - loss: 0.4003\n",
      "Epoch 41/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8315 - loss: 0.4055  \n",
      "Epoch 42/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8332 - loss: 0.4037\n",
      "Epoch 43/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8349 - loss: 0.3995\n",
      "Epoch 44/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8382 - loss: 0.3972\n",
      "Epoch 45/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8314 - loss: 0.4074\n",
      "Epoch 46/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8282 - loss: 0.4164\n",
      "Epoch 47/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8398 - loss: 0.3950\n",
      "Epoch 48/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8348 - loss: 0.4085\n",
      "Epoch 49/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8387 - loss: 0.3974\n",
      "Epoch 50/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8388 - loss: 0.4019\n",
      "Epoch 51/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8369 - loss: 0.4035\n",
      "Epoch 52/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8464 - loss: 0.3869\n",
      "Epoch 53/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8358 - loss: 0.4079\n",
      "Epoch 54/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8447 - loss: 0.3895\n",
      "Epoch 55/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8368 - loss: 0.4084\n",
      "Epoch 56/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8397 - loss: 0.3949\n",
      "Epoch 57/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8346 - loss: 0.4038\n",
      "Epoch 58/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8425 - loss: 0.3858\n",
      "Epoch 59/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8437 - loss: 0.3947\n",
      "Epoch 60/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8309 - loss: 0.4116\n",
      "Epoch 61/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8319 - loss: 0.4053\n",
      "Epoch 62/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8363 - loss: 0.4012\n",
      "Epoch 63/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8348 - loss: 0.4024\n",
      "Epoch 64/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8237 - loss: 0.4112\n",
      "Epoch 65/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8363 - loss: 0.4079\n",
      "Epoch 66/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8347 - loss: 0.4031\n",
      "Epoch 67/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8326 - loss: 0.4029\n",
      "Epoch 68/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8395 - loss: 0.3946\n",
      "Epoch 69/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8268 - loss: 0.4075\n",
      "Epoch 70/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8402 - loss: 0.3984\n",
      "Epoch 71/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8367 - loss: 0.3950\n",
      "Epoch 72/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8399 - loss: 0.3914\n",
      "Epoch 73/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8479 - loss: 0.3890\n",
      "Epoch 74/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8400 - loss: 0.3929\n",
      "Epoch 75/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8332 - loss: 0.4058\n",
      "Epoch 76/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8345 - loss: 0.4043\n",
      "Epoch 77/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8422 - loss: 0.4037\n",
      "Epoch 78/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8332 - loss: 0.4123\n",
      "Epoch 79/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8355 - loss: 0.4070  \n",
      "Epoch 80/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8349 - loss: 0.4018\n",
      "Epoch 81/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8468 - loss: 0.3859\n",
      "Epoch 82/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8360 - loss: 0.4051\n",
      "Epoch 83/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8374 - loss: 0.3946\n",
      "Epoch 84/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8418 - loss: 0.3926\n",
      "Epoch 85/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8408 - loss: 0.3963\n",
      "Epoch 86/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8380 - loss: 0.3937\n",
      "Epoch 87/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8325 - loss: 0.4035\n",
      "Epoch 88/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8410 - loss: 0.3985\n",
      "Epoch 89/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8361 - loss: 0.4048\n",
      "Epoch 90/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8389 - loss: 0.3963\n",
      "Epoch 91/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8321 - loss: 0.4059\n",
      "Epoch 92/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8365 - loss: 0.4046\n",
      "Epoch 93/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8320 - loss: 0.4086\n",
      "Epoch 94/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8407 - loss: 0.3924\n",
      "Epoch 95/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8358 - loss: 0.3956\n",
      "Epoch 96/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8348 - loss: 0.4038\n",
      "Epoch 97/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8350 - loss: 0.4018\n",
      "Epoch 98/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8376 - loss: 0.3999\n",
      "Epoch 99/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8346 - loss: 0.4033\n",
      "Epoch 100/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8378 - loss: 0.3970\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7855 - loss: 0.6491\n",
      "Epoch 2/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7919 - loss: 0.4374\n",
      "Epoch 3/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8051 - loss: 0.4121\n",
      "Epoch 4/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8144 - loss: 0.4237\n",
      "Epoch 5/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8233 - loss: 0.4194\n",
      "Epoch 6/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8290 - loss: 0.3990\n",
      "Epoch 7/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8292 - loss: 0.3926\n",
      "Epoch 8/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8349 - loss: 0.3769\n",
      "Epoch 9/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8294 - loss: 0.3838\n",
      "Epoch 10/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8312 - loss: 0.3808\n",
      "Epoch 11/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8367 - loss: 0.3778  \n",
      "Epoch 12/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8445 - loss: 0.3716\n",
      "Epoch 13/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8492 - loss: 0.3657\n",
      "Epoch 14/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8432 - loss: 0.3739\n",
      "Epoch 15/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8485 - loss: 0.3657\n",
      "Epoch 16/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8410 - loss: 0.3759\n",
      "Epoch 17/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8568 - loss: 0.3548\n",
      "Epoch 18/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8515 - loss: 0.3634\n",
      "Epoch 19/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8550 - loss: 0.3586\n",
      "Epoch 20/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8541 - loss: 0.3627\n",
      "Epoch 21/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8566 - loss: 0.3526\n",
      "Epoch 22/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8538 - loss: 0.3530\n",
      "Epoch 23/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8550 - loss: 0.3574\n",
      "Epoch 24/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8541 - loss: 0.3602\n",
      "Epoch 25/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8497 - loss: 0.3636\n",
      "Epoch 26/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8563 - loss: 0.3462\n",
      "Epoch 27/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8556 - loss: 0.3544\n",
      "Epoch 28/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8485 - loss: 0.3677\n",
      "Epoch 29/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8525 - loss: 0.3556\n",
      "Epoch 30/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8526 - loss: 0.3610\n",
      "Epoch 31/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8598 - loss: 0.3588\n",
      "Epoch 32/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8504 - loss: 0.3609\n",
      "Epoch 33/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8514 - loss: 0.3609\n",
      "Epoch 34/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8546 - loss: 0.3577\n",
      "Epoch 35/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8575 - loss: 0.3575\n",
      "Epoch 36/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8591 - loss: 0.3438\n",
      "Epoch 37/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8618 - loss: 0.3457\n",
      "Epoch 38/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8628 - loss: 0.3419\n",
      "Epoch 39/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8537 - loss: 0.3581\n",
      "Epoch 40/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8587 - loss: 0.3468\n",
      "Epoch 41/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8558 - loss: 0.3544\n",
      "Epoch 42/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8622 - loss: 0.3447\n",
      "Epoch 43/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8628 - loss: 0.3452\n",
      "Epoch 44/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8594 - loss: 0.3486\n",
      "Epoch 45/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8530 - loss: 0.3550\n",
      "Epoch 46/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8613 - loss: 0.3405\n",
      "Epoch 47/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8587 - loss: 0.3459\n",
      "Epoch 48/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8622 - loss: 0.3468\n",
      "Epoch 49/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8595 - loss: 0.3533\n",
      "Epoch 50/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8636 - loss: 0.3428\n",
      "Epoch 51/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8634 - loss: 0.3366\n",
      "Epoch 52/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8666 - loss: 0.3370\n",
      "Epoch 53/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8668 - loss: 0.3369\n",
      "Epoch 54/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8572 - loss: 0.3495\n",
      "Epoch 55/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8583 - loss: 0.3524\n",
      "Epoch 56/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8636 - loss: 0.3395\n",
      "Epoch 57/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8619 - loss: 0.3469\n",
      "Epoch 58/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8613 - loss: 0.3397\n",
      "Epoch 59/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8555 - loss: 0.3510\n",
      "Epoch 60/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8617 - loss: 0.3457\n",
      "Epoch 61/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8618 - loss: 0.3511\n",
      "Epoch 62/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8519 - loss: 0.3545\n",
      "Epoch 63/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8647 - loss: 0.3330\n",
      "Epoch 64/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8658 - loss: 0.3400\n",
      "Epoch 65/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8610 - loss: 0.3445\n",
      "Epoch 66/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8655 - loss: 0.3375\n",
      "Epoch 67/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8648 - loss: 0.3375\n",
      "Epoch 68/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8658 - loss: 0.3367\n",
      "Epoch 69/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8601 - loss: 0.3437\n",
      "Epoch 70/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8661 - loss: 0.3365\n",
      "Epoch 71/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8663 - loss: 0.3343\n",
      "Epoch 72/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8610 - loss: 0.3369\n",
      "Epoch 73/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8616 - loss: 0.3369\n",
      "Epoch 74/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8636 - loss: 0.3395\n",
      "Epoch 75/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8466 - loss: 0.3613\n",
      "Epoch 76/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8663 - loss: 0.3300\n",
      "Epoch 77/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8579 - loss: 0.3458\n",
      "Epoch 78/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8605 - loss: 0.3357\n",
      "Epoch 79/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8620 - loss: 0.3454\n",
      "Epoch 80/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8606 - loss: 0.3398\n",
      "Epoch 81/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8596 - loss: 0.3437\n",
      "Epoch 82/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8613 - loss: 0.3498\n",
      "Epoch 83/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8597 - loss: 0.3466\n",
      "Epoch 84/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8604 - loss: 0.3358\n",
      "Epoch 85/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8586 - loss: 0.3466\n",
      "Epoch 86/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8600 - loss: 0.3505\n",
      "Epoch 87/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8551 - loss: 0.3419\n",
      "Epoch 88/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8624 - loss: 0.3393\n",
      "Epoch 89/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8563 - loss: 0.3525\n",
      "Epoch 90/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8564 - loss: 0.3412\n",
      "Epoch 91/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8588 - loss: 0.3447\n",
      "Epoch 92/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8608 - loss: 0.3436\n",
      "Epoch 93/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8623 - loss: 0.3387\n",
      "Epoch 94/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8593 - loss: 0.3514\n",
      "Epoch 95/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8627 - loss: 0.3379\n",
      "Epoch 96/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8606 - loss: 0.3412\n",
      "Epoch 97/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8594 - loss: 0.3376\n",
      "Epoch 98/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8607 - loss: 0.3400\n",
      "Epoch 99/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8610 - loss: 0.3336\n",
      "Epoch 100/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8624 - loss: 0.3341\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7943 - loss: 0.6445\n",
      "Epoch 2/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7919 - loss: 0.4419\n",
      "Epoch 3/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7946 - loss: 0.4353\n",
      "Epoch 4/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7905 - loss: 0.4340\n",
      "Epoch 5/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7996 - loss: 0.4230\n",
      "Epoch 6/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8247 - loss: 0.4147\n",
      "Epoch 7/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8324 - loss: 0.4122\n",
      "Epoch 8/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8335 - loss: 0.4135\n",
      "Epoch 9/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8330 - loss: 0.4094\n",
      "Epoch 10/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8337 - loss: 0.4054\n",
      "Epoch 11/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8337 - loss: 0.4029  \n",
      "Epoch 12/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8374 - loss: 0.3973\n",
      "Epoch 13/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8404 - loss: 0.3943\n",
      "Epoch 14/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8370 - loss: 0.4034  \n",
      "Epoch 15/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8440 - loss: 0.3845\n",
      "Epoch 16/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8361 - loss: 0.3955  \n",
      "Epoch 17/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8422 - loss: 0.3879\n",
      "Epoch 18/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8315 - loss: 0.4027\n",
      "Epoch 19/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 0.8391 - loss: 0.3926\n",
      "Epoch 20/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8369 - loss: 0.3984  \n",
      "Epoch 21/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8369 - loss: 0.3929  \n",
      "Epoch 22/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8366 - loss: 0.3922\n",
      "Epoch 23/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8366 - loss: 0.3997\n",
      "Epoch 24/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8422 - loss: 0.3907  \n",
      "Epoch 25/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8363 - loss: 0.3932\n",
      "Epoch 26/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8424 - loss: 0.3908\n",
      "Epoch 27/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8380 - loss: 0.3898\n",
      "Epoch 28/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8459 - loss: 0.3880  \n",
      "Epoch 29/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8406 - loss: 0.3929  \n",
      "Epoch 30/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 0.8405 - loss: 0.3934\n",
      "Epoch 31/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8454 - loss: 0.3780\n",
      "Epoch 32/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8357 - loss: 0.3968\n",
      "Epoch 33/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8420 - loss: 0.3829  \n",
      "Epoch 34/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8391 - loss: 0.3918  \n",
      "Epoch 35/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8447 - loss: 0.3896  \n",
      "Epoch 36/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8405 - loss: 0.3936  \n",
      "Epoch 37/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8376 - loss: 0.4000  \n",
      "Epoch 38/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8422 - loss: 0.3838  \n",
      "Epoch 39/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8382 - loss: 0.3920  \n",
      "Epoch 40/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.8367 - loss: 0.3904\n",
      "Epoch 41/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8356 - loss: 0.3976\n",
      "Epoch 42/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8392 - loss: 0.3936\n",
      "Epoch 43/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8303 - loss: 0.4045\n",
      "Epoch 44/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8369 - loss: 0.3976  \n",
      "Epoch 45/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8437 - loss: 0.3831\n",
      "Epoch 46/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8358 - loss: 0.3971\n",
      "Epoch 47/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8400 - loss: 0.3963\n",
      "Epoch 48/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8369 - loss: 0.3917  \n",
      "Epoch 49/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8345 - loss: 0.4020\n",
      "Epoch 50/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.8395 - loss: 0.3921\n",
      "Epoch 51/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8402 - loss: 0.3922\n",
      "Epoch 52/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8367 - loss: 0.3927\n",
      "Epoch 53/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8348 - loss: 0.3975\n",
      "Epoch 54/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8456 - loss: 0.3818\n",
      "Epoch 55/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8395 - loss: 0.3955\n",
      "Epoch 56/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8321 - loss: 0.4024\n",
      "Epoch 57/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8458 - loss: 0.3843\n",
      "Epoch 58/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8401 - loss: 0.3931  \n",
      "Epoch 59/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8410 - loss: 0.3908\n",
      "Epoch 60/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8459 - loss: 0.3887\n",
      "Epoch 61/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8448 - loss: 0.3826\n",
      "Epoch 62/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8370 - loss: 0.4003\n",
      "Epoch 63/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8408 - loss: 0.4007  \n",
      "Epoch 64/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8380 - loss: 0.4019\n",
      "Epoch 65/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.8399 - loss: 0.3899\n",
      "Epoch 66/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8432 - loss: 0.3965  \n",
      "Epoch 67/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8406 - loss: 0.3919  \n",
      "Epoch 68/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8390 - loss: 0.3923  \n",
      "Epoch 69/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8375 - loss: 0.3983  \n",
      "Epoch 70/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8424 - loss: 0.3914  \n",
      "Epoch 71/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8397 - loss: 0.3962  \n",
      "Epoch 72/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8429 - loss: 0.3817  \n",
      "Epoch 73/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8404 - loss: 0.3901  \n",
      "Epoch 74/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8432 - loss: 0.3853  \n",
      "Epoch 75/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8475 - loss: 0.3747  \n",
      "Epoch 76/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8324 - loss: 0.4071  \n",
      "Epoch 77/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8323 - loss: 0.4034  \n",
      "Epoch 78/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8470 - loss: 0.3830  \n",
      "Epoch 79/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8510 - loss: 0.3747\n",
      "Epoch 80/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.8440 - loss: 0.3916\n",
      "Epoch 81/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8373 - loss: 0.3991\n",
      "Epoch 82/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8441 - loss: 0.3824  \n",
      "Epoch 83/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8458 - loss: 0.3866  \n",
      "Epoch 84/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8467 - loss: 0.3828\n",
      "Epoch 85/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8377 - loss: 0.4008\n",
      "Epoch 86/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8390 - loss: 0.3934\n",
      "Epoch 87/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - accuracy: 0.8479 - loss: 0.3854\n",
      "Epoch 88/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8399 - loss: 0.3889  \n",
      "Epoch 89/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8414 - loss: 0.3937\n",
      "Epoch 90/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8465 - loss: 0.3792  \n",
      "Epoch 91/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8486 - loss: 0.3824\n",
      "Epoch 92/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8445 - loss: 0.3849   \n",
      "Epoch 93/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8417 - loss: 0.3888  \n",
      "Epoch 94/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8471 - loss: 0.3789\n",
      "Epoch 95/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8510 - loss: 0.3753  \n",
      "Epoch 96/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8438 - loss: 0.3838\n",
      "Epoch 97/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.8443 - loss: 0.3836\n",
      "Epoch 98/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8391 - loss: 0.3942\n",
      "Epoch 99/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8423 - loss: 0.3877  \n",
      "Epoch 100/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8425 - loss: 0.3850\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7824 - loss: 0.6317  \n",
      "Epoch 2/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7864 - loss: 0.4506\n",
      "Epoch 3/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7904 - loss: 0.4453\n",
      "Epoch 4/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 0.8057 - loss: 0.4120\n",
      "Epoch 5/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7919 - loss: 0.4251\n",
      "Epoch 6/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.7963 - loss: 0.4266\n",
      "Epoch 7/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8101 - loss: 0.4294  \n",
      "Epoch 8/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8190 - loss: 0.4157\n",
      "Epoch 9/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8181 - loss: 0.4266  \n",
      "Epoch 10/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.8226 - loss: 0.4221\n",
      "Epoch 11/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8308 - loss: 0.4182  \n",
      "Epoch 12/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 0.8267 - loss: 0.4200\n",
      "Epoch 13/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8278 - loss: 0.4188  \n",
      "Epoch 14/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8294 - loss: 0.4227  \n",
      "Epoch 15/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8341 - loss: 0.4187\n",
      "Epoch 16/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8330 - loss: 0.4123\n",
      "Epoch 17/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8360 - loss: 0.4067\n",
      "Epoch 18/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8273 - loss: 0.4272  \n",
      "Epoch 19/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8370 - loss: 0.4075\n",
      "Epoch 20/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8336 - loss: 0.4130  \n",
      "Epoch 21/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.8370 - loss: 0.4046\n",
      "Epoch 22/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8395 - loss: 0.4064  \n",
      "Epoch 23/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8340 - loss: 0.4087\n",
      "Epoch 24/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8430 - loss: 0.3970  \n",
      "Epoch 25/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8399 - loss: 0.3991\n",
      "Epoch 26/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8305 - loss: 0.4209  \n",
      "Epoch 27/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8335 - loss: 0.4164  \n",
      "Epoch 28/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8399 - loss: 0.3977\n",
      "Epoch 29/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8328 - loss: 0.4120  \n",
      "Epoch 30/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8390 - loss: 0.4023  \n",
      "Epoch 31/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8412 - loss: 0.3964  \n",
      "Epoch 32/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8431 - loss: 0.4003\n",
      "Epoch 33/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 0.8468 - loss: 0.3908\n",
      "Epoch 34/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8330 - loss: 0.4082\n",
      "Epoch 35/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8359 - loss: 0.4046  \n",
      "Epoch 36/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8389 - loss: 0.4033\n",
      "Epoch 37/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8363 - loss: 0.3981  \n",
      "Epoch 38/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.8434 - loss: 0.3905\n",
      "Epoch 39/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8399 - loss: 0.4014  \n",
      "Epoch 40/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8397 - loss: 0.4048\n",
      "Epoch 41/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8409 - loss: 0.3961\n",
      "Epoch 42/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8386 - loss: 0.4000\n",
      "Epoch 43/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8390 - loss: 0.3933\n",
      "Epoch 44/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8286 - loss: 0.4095\n",
      "Epoch 45/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8360 - loss: 0.4041\n",
      "Epoch 46/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8407 - loss: 0.3968\n",
      "Epoch 47/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8387 - loss: 0.4006\n",
      "Epoch 48/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8352 - loss: 0.3984\n",
      "Epoch 49/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8353 - loss: 0.4007\n",
      "Epoch 50/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8362 - loss: 0.4040\n",
      "Epoch 51/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8344 - loss: 0.4009\n",
      "Epoch 52/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8334 - loss: 0.4038\n",
      "Epoch 53/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8392 - loss: 0.3913\n",
      "Epoch 54/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8390 - loss: 0.4048\n",
      "Epoch 55/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8350 - loss: 0.4038\n",
      "Epoch 56/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8468 - loss: 0.3881\n",
      "Epoch 57/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8413 - loss: 0.3958\n",
      "Epoch 58/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8439 - loss: 0.3928\n",
      "Epoch 59/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8368 - loss: 0.3992\n",
      "Epoch 60/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8436 - loss: 0.3946\n",
      "Epoch 61/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8345 - loss: 0.4083\n",
      "Epoch 62/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8408 - loss: 0.4023\n",
      "Epoch 63/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8364 - loss: 0.4048\n",
      "Epoch 64/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8385 - loss: 0.4064\n",
      "Epoch 65/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3894\n",
      "Epoch 66/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8341 - loss: 0.4022\n",
      "Epoch 67/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8396 - loss: 0.3975\n",
      "Epoch 68/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8497 - loss: 0.3836\n",
      "Epoch 69/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8382 - loss: 0.4034\n",
      "Epoch 70/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8374 - loss: 0.3986\n",
      "Epoch 71/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8313 - loss: 0.4112\n",
      "Epoch 72/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8380 - loss: 0.3976\n",
      "Epoch 73/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8383 - loss: 0.4030\n",
      "Epoch 74/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8349 - loss: 0.4012\n",
      "Epoch 75/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8360 - loss: 0.4011\n",
      "Epoch 76/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8430 - loss: 0.3948\n",
      "Epoch 77/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8372 - loss: 0.4035\n",
      "Epoch 78/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8350 - loss: 0.3989\n",
      "Epoch 79/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8385 - loss: 0.3961\n",
      "Epoch 80/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8418 - loss: 0.3969\n",
      "Epoch 81/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8316 - loss: 0.4100\n",
      "Epoch 82/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8373 - loss: 0.4074\n",
      "Epoch 83/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8363 - loss: 0.4035\n",
      "Epoch 84/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8368 - loss: 0.4034\n",
      "Epoch 85/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8377 - loss: 0.4068\n",
      "Epoch 86/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8325 - loss: 0.4101\n",
      "Epoch 87/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8441 - loss: 0.3954\n",
      "Epoch 88/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8335 - loss: 0.3997\n",
      "Epoch 89/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8390 - loss: 0.4077\n",
      "Epoch 90/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8402 - loss: 0.3990\n",
      "Epoch 91/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8337 - loss: 0.4014\n",
      "Epoch 92/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8336 - loss: 0.4067\n",
      "Epoch 93/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8387 - loss: 0.3988\n",
      "Epoch 94/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8435 - loss: 0.3895\n",
      "Epoch 95/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8374 - loss: 0.4096\n",
      "Epoch 96/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8458 - loss: 0.3901\n",
      "Epoch 97/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8371 - loss: 0.4008\n",
      "Epoch 98/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8311 - loss: 0.4126\n",
      "Epoch 99/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8419 - loss: 0.3960\n",
      "Epoch 100/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8424 - loss: 0.3988\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7939 - loss: 0.6291  \n",
      "Epoch 2/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8005 - loss: 0.4403  \n",
      "Epoch 3/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7992 - loss: 0.4299  \n",
      "Epoch 4/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7976 - loss: 0.4215  \n",
      "Epoch 5/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8016 - loss: 0.4242\n",
      "Epoch 6/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 0.7960 - loss: 0.4231\n",
      "Epoch 7/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8090 - loss: 0.4167  \n",
      "Epoch 8/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8210 - loss: 0.4164  \n",
      "Epoch 9/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8239 - loss: 0.4216  \n",
      "Epoch 10/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8302 - loss: 0.4054  \n",
      "Epoch 11/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8243 - loss: 0.4192  \n",
      "Epoch 12/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.8331 - loss: 0.4103\n",
      "Epoch 13/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8255 - loss: 0.4148  \n",
      "Epoch 14/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8337 - loss: 0.4186\n",
      "Epoch 15/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8318 - loss: 0.4077\n",
      "Epoch 16/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8400 - loss: 0.4001\n",
      "Epoch 17/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8306 - loss: 0.4078\n",
      "Epoch 18/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8298 - loss: 0.4121  \n",
      "Epoch 19/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8395 - loss: 0.4030\n",
      "Epoch 20/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8353 - loss: 0.4102  \n",
      "Epoch 21/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8300 - loss: 0.4134\n",
      "Epoch 22/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8369 - loss: 0.4042  \n",
      "Epoch 23/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8278 - loss: 0.4143  \n",
      "Epoch 24/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8363 - loss: 0.4105\n",
      "Epoch 25/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8298 - loss: 0.4145\n",
      "Epoch 26/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8266 - loss: 0.4205\n",
      "Epoch 27/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8267 - loss: 0.4250\n",
      "Epoch 28/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8439 - loss: 0.3944\n",
      "Epoch 29/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8358 - loss: 0.4106\n",
      "Epoch 30/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8345 - loss: 0.4032\n",
      "Epoch 31/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8372 - loss: 0.4030\n",
      "Epoch 32/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8345 - loss: 0.4065\n",
      "Epoch 33/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8430 - loss: 0.4006\n",
      "Epoch 34/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8423 - loss: 0.3958\n",
      "Epoch 35/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8327 - loss: 0.4105\n",
      "Epoch 36/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8326 - loss: 0.4105\n",
      "Epoch 37/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8371 - loss: 0.4020\n",
      "Epoch 38/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8416 - loss: 0.3944\n",
      "Epoch 39/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8331 - loss: 0.4109\n",
      "Epoch 40/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8287 - loss: 0.4147\n",
      "Epoch 41/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8330 - loss: 0.4112\n",
      "Epoch 42/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8382 - loss: 0.4045\n",
      "Epoch 43/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8387 - loss: 0.3932\n",
      "Epoch 44/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8305 - loss: 0.4065\n",
      "Epoch 45/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.3968\n",
      "Epoch 46/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8307 - loss: 0.4104\n",
      "Epoch 47/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8338 - loss: 0.4038\n",
      "Epoch 48/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8403 - loss: 0.3985\n",
      "Epoch 49/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8352 - loss: 0.3967\n",
      "Epoch 50/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8340 - loss: 0.4126\n",
      "Epoch 51/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8287 - loss: 0.4124\n",
      "Epoch 52/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8325 - loss: 0.4071\n",
      "Epoch 53/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8376 - loss: 0.3971\n",
      "Epoch 54/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8488 - loss: 0.3857\n",
      "Epoch 55/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8396 - loss: 0.3911\n",
      "Epoch 56/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8368 - loss: 0.4008\n",
      "Epoch 57/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8326 - loss: 0.4050\n",
      "Epoch 58/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8399 - loss: 0.3949\n",
      "Epoch 59/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8276 - loss: 0.4101\n",
      "Epoch 60/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8328 - loss: 0.4107\n",
      "Epoch 61/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8319 - loss: 0.4096\n",
      "Epoch 62/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8402 - loss: 0.3961\n",
      "Epoch 63/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8292 - loss: 0.4104\n",
      "Epoch 64/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8448 - loss: 0.3921\n",
      "Epoch 65/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8386 - loss: 0.3928\n",
      "Epoch 66/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8335 - loss: 0.4016\n",
      "Epoch 67/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8444 - loss: 0.3957\n",
      "Epoch 68/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8297 - loss: 0.4105\n",
      "Epoch 69/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.3976\n",
      "Epoch 70/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3944\n",
      "Epoch 71/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.3952\n",
      "Epoch 72/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8304 - loss: 0.4073\n",
      "Epoch 73/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8388 - loss: 0.3992\n",
      "Epoch 74/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8383 - loss: 0.4013\n",
      "Epoch 75/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8342 - loss: 0.4056\n",
      "Epoch 76/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.3996\n",
      "Epoch 77/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8355 - loss: 0.4022\n",
      "Epoch 78/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8318 - loss: 0.4039\n",
      "Epoch 79/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8406 - loss: 0.3936\n",
      "Epoch 80/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8377 - loss: 0.4019\n",
      "Epoch 81/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8388 - loss: 0.4015\n",
      "Epoch 82/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8367 - loss: 0.3968\n",
      "Epoch 83/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8389 - loss: 0.3948\n",
      "Epoch 84/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8358 - loss: 0.4051\n",
      "Epoch 85/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8327 - loss: 0.4036\n",
      "Epoch 86/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8414 - loss: 0.3958\n",
      "Epoch 87/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8345 - loss: 0.4034\n",
      "Epoch 88/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8370 - loss: 0.4012\n",
      "Epoch 89/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8422 - loss: 0.3927\n",
      "Epoch 90/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8371 - loss: 0.4036\n",
      "Epoch 91/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8432 - loss: 0.3946\n",
      "Epoch 92/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.3990\n",
      "Epoch 93/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8405 - loss: 0.3955\n",
      "Epoch 94/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8442 - loss: 0.3953\n",
      "Epoch 95/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8268 - loss: 0.4165\n",
      "Epoch 96/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8350 - loss: 0.4027\n",
      "Epoch 97/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8428 - loss: 0.3956\n",
      "Epoch 98/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8393 - loss: 0.3997\n",
      "Epoch 99/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8442 - loss: 0.3907\n",
      "Epoch 100/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8418 - loss: 0.3928\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7904 - loss: 0.6572\n",
      "Epoch 2/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7984 - loss: 0.4503\n",
      "Epoch 3/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8002 - loss: 0.4325\n",
      "Epoch 4/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8007 - loss: 0.4307\n",
      "Epoch 5/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8025 - loss: 0.4254\n",
      "Epoch 6/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7982 - loss: 0.4275\n",
      "Epoch 7/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8170 - loss: 0.4212\n",
      "Epoch 8/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8371 - loss: 0.4061\n",
      "Epoch 9/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8354 - loss: 0.4091\n",
      "Epoch 10/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8380 - loss: 0.4070\n",
      "Epoch 11/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8281 - loss: 0.4165\n",
      "Epoch 12/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8381 - loss: 0.4076\n",
      "Epoch 13/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8336 - loss: 0.4032\n",
      "Epoch 14/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8374 - loss: 0.4066\n",
      "Epoch 15/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8384 - loss: 0.4040\n",
      "Epoch 16/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8338 - loss: 0.4026\n",
      "Epoch 17/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8436 - loss: 0.3953\n",
      "Epoch 18/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8325 - loss: 0.4121\n",
      "Epoch 19/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8321 - loss: 0.4031\n",
      "Epoch 20/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8398 - loss: 0.3913\n",
      "Epoch 21/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8352 - loss: 0.4061\n",
      "Epoch 22/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8422 - loss: 0.3917\n",
      "Epoch 23/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8317 - loss: 0.4052\n",
      "Epoch 24/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8299 - loss: 0.4133\n",
      "Epoch 25/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8368 - loss: 0.4013\n",
      "Epoch 26/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8407 - loss: 0.4007\n",
      "Epoch 27/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8386 - loss: 0.3925\n",
      "Epoch 28/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8378 - loss: 0.4004\n",
      "Epoch 29/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8395 - loss: 0.3908\n",
      "Epoch 30/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8395 - loss: 0.3922\n",
      "Epoch 31/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8369 - loss: 0.3901\n",
      "Epoch 32/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8481 - loss: 0.3842\n",
      "Epoch 33/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8435 - loss: 0.3825\n",
      "Epoch 34/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8325 - loss: 0.3995\n",
      "Epoch 35/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8380 - loss: 0.3954\n",
      "Epoch 36/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8319 - loss: 0.4016\n",
      "Epoch 37/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8370 - loss: 0.4023\n",
      "Epoch 38/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8326 - loss: 0.4037\n",
      "Epoch 39/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8466 - loss: 0.3865\n",
      "Epoch 40/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8480 - loss: 0.3800\n",
      "Epoch 41/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8448 - loss: 0.3890\n",
      "Epoch 42/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8398 - loss: 0.3939\n",
      "Epoch 43/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8350 - loss: 0.3958\n",
      "Epoch 44/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8368 - loss: 0.3927\n",
      "Epoch 45/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8443 - loss: 0.3882\n",
      "Epoch 46/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8452 - loss: 0.3849\n",
      "Epoch 47/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8459 - loss: 0.3907\n",
      "Epoch 48/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8366 - loss: 0.3942\n",
      "Epoch 49/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8377 - loss: 0.4012\n",
      "Epoch 50/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8466 - loss: 0.3817\n",
      "Epoch 51/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8438 - loss: 0.3869\n",
      "Epoch 52/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8363 - loss: 0.3943\n",
      "Epoch 53/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8480 - loss: 0.3759\n",
      "Epoch 54/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8428 - loss: 0.3897\n",
      "Epoch 55/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8382 - loss: 0.3910\n",
      "Epoch 56/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8426 - loss: 0.3840\n",
      "Epoch 57/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8419 - loss: 0.3899\n",
      "Epoch 58/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8395 - loss: 0.3929\n",
      "Epoch 59/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8418 - loss: 0.3947\n",
      "Epoch 60/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8411 - loss: 0.3930\n",
      "Epoch 61/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8463 - loss: 0.3802\n",
      "Epoch 62/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8464 - loss: 0.3795\n",
      "Epoch 63/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8534 - loss: 0.3796\n",
      "Epoch 64/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8442 - loss: 0.3874\n",
      "Epoch 65/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8497 - loss: 0.3898\n",
      "Epoch 66/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8457 - loss: 0.3834\n",
      "Epoch 67/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8389 - loss: 0.3917\n",
      "Epoch 68/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8448 - loss: 0.3830\n",
      "Epoch 69/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8500 - loss: 0.3784\n",
      "Epoch 70/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8472 - loss: 0.3869\n",
      "Epoch 71/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8540 - loss: 0.3716\n",
      "Epoch 72/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8499 - loss: 0.3799\n",
      "Epoch 73/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8526 - loss: 0.3781\n",
      "Epoch 74/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8452 - loss: 0.3770\n",
      "Epoch 75/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8620 - loss: 0.3519\n",
      "Epoch 76/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8532 - loss: 0.3688\n",
      "Epoch 77/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8516 - loss: 0.3676\n",
      "Epoch 78/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8480 - loss: 0.3794\n",
      "Epoch 79/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8586 - loss: 0.3583\n",
      "Epoch 80/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8604 - loss: 0.3575\n",
      "Epoch 81/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8579 - loss: 0.3513\n",
      "Epoch 82/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8580 - loss: 0.3568\n",
      "Epoch 83/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8531 - loss: 0.3653\n",
      "Epoch 84/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8509 - loss: 0.3663\n",
      "Epoch 85/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8555 - loss: 0.3569\n",
      "Epoch 86/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8584 - loss: 0.3530\n",
      "Epoch 87/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8607 - loss: 0.3512\n",
      "Epoch 88/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8579 - loss: 0.3482\n",
      "Epoch 89/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8537 - loss: 0.3596\n",
      "Epoch 90/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8560 - loss: 0.3563\n",
      "Epoch 91/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8595 - loss: 0.3591\n",
      "Epoch 92/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8652 - loss: 0.3371\n",
      "Epoch 93/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8592 - loss: 0.3482\n",
      "Epoch 94/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8615 - loss: 0.3464\n",
      "Epoch 95/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8542 - loss: 0.3560\n",
      "Epoch 96/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8634 - loss: 0.3450\n",
      "Epoch 97/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8552 - loss: 0.3552\n",
      "Epoch 98/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8640 - loss: 0.3433\n",
      "Epoch 99/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8611 - loss: 0.3413\n",
      "Epoch 100/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8591 - loss: 0.3472\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7964 - loss: 0.6277\n",
      "Epoch 2/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7987 - loss: 0.4417\n",
      "Epoch 3/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7963 - loss: 0.4366\n",
      "Epoch 4/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7964 - loss: 0.4287\n",
      "Epoch 5/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7966 - loss: 0.4270\n",
      "Epoch 6/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7981 - loss: 0.4158\n",
      "Epoch 7/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8003 - loss: 0.4244\n",
      "Epoch 8/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8195 - loss: 0.4146\n",
      "Epoch 9/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8200 - loss: 0.4194\n",
      "Epoch 10/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8232 - loss: 0.4096\n",
      "Epoch 11/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8220 - loss: 0.4256\n",
      "Epoch 12/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8250 - loss: 0.4183\n",
      "Epoch 13/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8341 - loss: 0.4090\n",
      "Epoch 14/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8264 - loss: 0.4166\n",
      "Epoch 15/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8253 - loss: 0.4260\n",
      "Epoch 16/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8301 - loss: 0.4107\n",
      "Epoch 17/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8318 - loss: 0.4117\n",
      "Epoch 18/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8354 - loss: 0.4047\n",
      "Epoch 19/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8383 - loss: 0.4094\n",
      "Epoch 20/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8296 - loss: 0.4118\n",
      "Epoch 21/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.4176\n",
      "Epoch 22/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8383 - loss: 0.3990\n",
      "Epoch 23/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8334 - loss: 0.4058\n",
      "Epoch 24/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8285 - loss: 0.4137\n",
      "Epoch 25/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8295 - loss: 0.4127\n",
      "Epoch 26/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8321 - loss: 0.4077\n",
      "Epoch 27/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8382 - loss: 0.3998\n",
      "Epoch 28/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8339 - loss: 0.4125\n",
      "Epoch 29/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8332 - loss: 0.4127\n",
      "Epoch 30/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8309 - loss: 0.4063\n",
      "Epoch 31/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8384 - loss: 0.4004\n",
      "Epoch 32/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8353 - loss: 0.4068\n",
      "Epoch 33/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8271 - loss: 0.4119\n",
      "Epoch 34/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8320 - loss: 0.4059\n",
      "Epoch 35/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8331 - loss: 0.4063\n",
      "Epoch 36/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8365 - loss: 0.4020\n",
      "Epoch 37/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8337 - loss: 0.4074\n",
      "Epoch 38/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8320 - loss: 0.4073\n",
      "Epoch 39/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8403 - loss: 0.3976\n",
      "Epoch 40/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8297 - loss: 0.4067\n",
      "Epoch 41/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8328 - loss: 0.4051\n",
      "Epoch 42/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8339 - loss: 0.4026\n",
      "Epoch 43/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8379 - loss: 0.4042\n",
      "Epoch 44/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8303 - loss: 0.4089\n",
      "Epoch 45/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8337 - loss: 0.4072\n",
      "Epoch 46/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8294 - loss: 0.4064\n",
      "Epoch 47/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8402 - loss: 0.3953\n",
      "Epoch 48/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8368 - loss: 0.4014\n",
      "Epoch 49/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8443 - loss: 0.3919\n",
      "Epoch 50/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8353 - loss: 0.4015\n",
      "Epoch 51/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8384 - loss: 0.4024\n",
      "Epoch 52/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8284 - loss: 0.4091\n",
      "Epoch 53/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8250 - loss: 0.4124\n",
      "Epoch 54/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8360 - loss: 0.4082\n",
      "Epoch 55/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8334 - loss: 0.4113\n",
      "Epoch 56/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8324 - loss: 0.4032\n",
      "Epoch 57/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8326 - loss: 0.4023\n",
      "Epoch 58/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8432 - loss: 0.3893\n",
      "Epoch 59/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8353 - loss: 0.4043\n",
      "Epoch 60/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8408 - loss: 0.4000\n",
      "Epoch 61/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8325 - loss: 0.4035\n",
      "Epoch 62/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8401 - loss: 0.3924\n",
      "Epoch 63/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8413 - loss: 0.3947\n",
      "Epoch 64/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8309 - loss: 0.4142\n",
      "Epoch 65/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8335 - loss: 0.4062\n",
      "Epoch 66/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8343 - loss: 0.3939\n",
      "Epoch 67/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8329 - loss: 0.4017\n",
      "Epoch 68/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8316 - loss: 0.4058\n",
      "Epoch 69/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8367 - loss: 0.4019\n",
      "Epoch 70/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8338 - loss: 0.4087\n",
      "Epoch 71/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8350 - loss: 0.4085\n",
      "Epoch 72/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8378 - loss: 0.4067\n",
      "Epoch 73/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8388 - loss: 0.3918\n",
      "Epoch 74/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8348 - loss: 0.4040\n",
      "Epoch 75/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8443 - loss: 0.3924\n",
      "Epoch 76/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8355 - loss: 0.4033\n",
      "Epoch 77/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8379 - loss: 0.4006\n",
      "Epoch 78/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8307 - loss: 0.4084\n",
      "Epoch 79/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8352 - loss: 0.4058\n",
      "Epoch 80/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8380 - loss: 0.4064\n",
      "Epoch 81/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8340 - loss: 0.4076\n",
      "Epoch 82/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8287 - loss: 0.4153\n",
      "Epoch 83/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8340 - loss: 0.4031\n",
      "Epoch 84/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8431 - loss: 0.3988\n",
      "Epoch 85/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8335 - loss: 0.4036\n",
      "Epoch 86/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8269 - loss: 0.4144\n",
      "Epoch 87/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8384 - loss: 0.3941\n",
      "Epoch 88/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8406 - loss: 0.3951\n",
      "Epoch 89/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8394 - loss: 0.3963\n",
      "Epoch 90/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8414 - loss: 0.3899\n",
      "Epoch 91/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8370 - loss: 0.3992\n",
      "Epoch 92/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8377 - loss: 0.4016\n",
      "Epoch 93/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8384 - loss: 0.3977\n",
      "Epoch 94/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8341 - loss: 0.4090\n",
      "Epoch 95/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8394 - loss: 0.4026\n",
      "Epoch 96/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8307 - loss: 0.4071\n",
      "Epoch 97/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8394 - loss: 0.4043\n",
      "Epoch 98/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8355 - loss: 0.4044\n",
      "Epoch 99/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8342 - loss: 0.4047\n",
      "Epoch 100/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8322 - loss: 0.4102\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7943 - loss: 0.6289\n",
      "Epoch 2/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8038 - loss: 0.4348\n",
      "Epoch 3/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8020 - loss: 0.4264\n",
      "Epoch 4/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8009 - loss: 0.4232\n",
      "Epoch 5/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8047 - loss: 0.4228\n",
      "Epoch 6/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8185 - loss: 0.4334\n",
      "Epoch 7/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8214 - loss: 0.4225\n",
      "Epoch 8/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8314 - loss: 0.4184\n",
      "Epoch 9/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8332 - loss: 0.4029\n",
      "Epoch 10/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8314 - loss: 0.4163\n",
      "Epoch 11/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8338 - loss: 0.4049\n",
      "Epoch 12/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8336 - loss: 0.4077\n",
      "Epoch 13/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8313 - loss: 0.4057\n",
      "Epoch 14/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8310 - loss: 0.4030\n",
      "Epoch 15/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8333 - loss: 0.4062\n",
      "Epoch 16/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8273 - loss: 0.4069\n",
      "Epoch 17/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8368 - loss: 0.4015\n",
      "Epoch 18/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8359 - loss: 0.3991\n",
      "Epoch 19/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8330 - loss: 0.4017\n",
      "Epoch 20/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8303 - loss: 0.4062\n",
      "Epoch 21/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8406 - loss: 0.3910\n",
      "Epoch 22/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8429 - loss: 0.3893\n",
      "Epoch 23/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.3780\n",
      "Epoch 24/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8338 - loss: 0.3951\n",
      "Epoch 25/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8349 - loss: 0.3980\n",
      "Epoch 26/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8401 - loss: 0.3923\n",
      "Epoch 27/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8383 - loss: 0.3971\n",
      "Epoch 28/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8404 - loss: 0.3858\n",
      "Epoch 29/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8455 - loss: 0.3788\n",
      "Epoch 30/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8399 - loss: 0.3954\n",
      "Epoch 31/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8359 - loss: 0.3944\n",
      "Epoch 32/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8357 - loss: 0.4009\n",
      "Epoch 33/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8383 - loss: 0.3874\n",
      "Epoch 34/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8337 - loss: 0.3943\n",
      "Epoch 35/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8388 - loss: 0.3869\n",
      "Epoch 36/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8331 - loss: 0.3974\n",
      "Epoch 37/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8372 - loss: 0.4048\n",
      "Epoch 38/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8372 - loss: 0.3931\n",
      "Epoch 39/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8375 - loss: 0.3988\n",
      "Epoch 40/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8367 - loss: 0.3919\n",
      "Epoch 41/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.3988\n",
      "Epoch 42/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3895\n",
      "Epoch 43/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8387 - loss: 0.3885\n",
      "Epoch 44/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8440 - loss: 0.3867\n",
      "Epoch 45/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8364 - loss: 0.3987\n",
      "Epoch 46/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8393 - loss: 0.3915\n",
      "Epoch 47/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8434 - loss: 0.3841\n",
      "Epoch 48/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8389 - loss: 0.3854\n",
      "Epoch 49/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8396 - loss: 0.3916\n",
      "Epoch 50/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3931\n",
      "Epoch 51/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8405 - loss: 0.3868\n",
      "Epoch 52/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8430 - loss: 0.3866\n",
      "Epoch 53/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8492 - loss: 0.3740\n",
      "Epoch 54/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8454 - loss: 0.3771\n",
      "Epoch 55/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8445 - loss: 0.3748\n",
      "Epoch 56/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8513 - loss: 0.3643\n",
      "Epoch 57/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8551 - loss: 0.3563\n",
      "Epoch 58/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3657\n",
      "Epoch 59/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8574 - loss: 0.3456\n",
      "Epoch 60/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8523 - loss: 0.3605\n",
      "Epoch 61/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8519 - loss: 0.3555\n",
      "Epoch 62/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8533 - loss: 0.3585\n",
      "Epoch 63/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8501 - loss: 0.3620\n",
      "Epoch 64/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8575 - loss: 0.3503\n",
      "Epoch 65/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8629 - loss: 0.3419\n",
      "Epoch 66/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8568 - loss: 0.3508\n",
      "Epoch 67/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8582 - loss: 0.3533\n",
      "Epoch 68/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8542 - loss: 0.3448\n",
      "Epoch 69/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8545 - loss: 0.3566\n",
      "Epoch 70/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8561 - loss: 0.3521\n",
      "Epoch 71/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8568 - loss: 0.3478\n",
      "Epoch 72/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8600 - loss: 0.3445\n",
      "Epoch 73/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8606 - loss: 0.3453\n",
      "Epoch 74/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8537 - loss: 0.3564\n",
      "Epoch 75/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8575 - loss: 0.3504\n",
      "Epoch 76/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8549 - loss: 0.3469\n",
      "Epoch 77/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8473 - loss: 0.3687\n",
      "Epoch 78/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8578 - loss: 0.3542\n",
      "Epoch 79/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8503 - loss: 0.3566\n",
      "Epoch 80/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8482 - loss: 0.3629\n",
      "Epoch 81/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8513 - loss: 0.3651\n",
      "Epoch 82/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8539 - loss: 0.3567\n",
      "Epoch 83/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8601 - loss: 0.3498\n",
      "Epoch 84/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8587 - loss: 0.3444\n",
      "Epoch 85/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8652 - loss: 0.3424\n",
      "Epoch 86/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8571 - loss: 0.3535\n",
      "Epoch 87/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8493 - loss: 0.3609\n",
      "Epoch 88/100\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8526 - loss: 0.3556\n",
      "Epoch 89/100\n",
      "\u001b[1m244/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8538 - loss: 0.3645"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 26\u001b[0m\n\u001b[0;32m     17\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m32\u001b[39m],\n\u001b[0;32m     18\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m500\u001b[39m],\n\u001b[0;32m     19\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[0;32m     21\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator \u001b[38;5;241m=\u001b[39m classifier,\n\u001b[0;32m     22\u001b[0m                            param_grid \u001b[38;5;241m=\u001b[39m parameters,\n\u001b[0;32m     23\u001b[0m                            scoring \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     24\u001b[0m                            cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     27\u001b[0m best_parameters \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[0;32m     28\u001b[0m best_accuracy \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_score_\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    727\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    728\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 729\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\scikeras\\wrappers.py:1501\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[1;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight\n\u001b[0;32m   1500\u001b[0m     sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, y\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m-> 1501\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\scikeras\\wrappers.py:770\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[1;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    765\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit__epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs)\n\u001b[0;32m    767\u001b[0m )\n\u001b[0;32m    768\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 770\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    771\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    772\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    773\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    774\u001b[0m     warm_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarm_start,\n\u001b[0;32m    775\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    776\u001b[0m )\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\scikeras\\wrappers.py:938\u001b[0m, in \u001b[0;36mBaseWrapper._fit\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    934\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_encoder_\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    936\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_model_compatibility(y)\n\u001b[1;32m--> 938\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_keras_model(\n\u001b[0;32m    939\u001b[0m     X,\n\u001b[0;32m    940\u001b[0m     y,\n\u001b[0;32m    941\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    942\u001b[0m     warm_start\u001b[38;5;241m=\u001b[39mwarm_start,\n\u001b[0;32m    943\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m    944\u001b[0m     initial_epoch\u001b[38;5;241m=\u001b[39minitial_epoch,\n\u001b[0;32m    945\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    946\u001b[0m )\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\scikeras\\wrappers.py:535\u001b[0m, in \u001b[0;36mBaseWrapper._fit_keras_model\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    533\u001b[0m         hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args)\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 535\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args)\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m warm_start \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m initial_epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory_ \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:222\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mget_value()\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution), iterator\n\u001b[0;32m    226\u001b[0m     ):\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\optional_ops.py:186\u001b[0m, in \u001b[0;36m_OptionalImpl.get_value\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptionalGetValue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    184\u001b[0m                     [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor]) \u001b[38;5;28;01mas\u001b[39;00m scope:\n\u001b[0;32m    185\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 186\u001b[0m     result \u001b[38;5;241m=\u001b[39m gen_optional_ops\u001b[38;5;241m.\u001b[39moptional_get_value(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor,\n\u001b[0;32m    188\u001b[0m         name\u001b[38;5;241m=\u001b[39mscope,\n\u001b[0;32m    189\u001b[0m         output_types\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_types(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec),\n\u001b[0;32m    190\u001b[0m         output_shapes\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_shapes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec),\n\u001b[0;32m    191\u001b[0m     )\n\u001b[0;32m    192\u001b[0m   \u001b[38;5;66;03m# NOTE: We do not colocate the deserialization of composite tensors\u001b[39;00m\n\u001b[0;32m    193\u001b[0m   \u001b[38;5;66;03m# because not all ops are guaranteed to have non-GPU kernels.\u001b[39;00m\n\u001b[0;32m    194\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m structure\u001b[38;5;241m.\u001b[39mfrom_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec, result)\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_optional_ops.py:95\u001b[0m, in \u001b[0;36moptional_get_value\u001b[1;34m(optional, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m     94\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     _result \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_FastPathExecute(\n\u001b[0;32m     96\u001b[0m       _ctx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptionalGetValue\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, optional, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_types\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     97\u001b[0m       output_types, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_shapes\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_shapes)\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m     99\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# \"\"\"# Tuning of the Parameters\"\"\"\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# def build_classifier(optimizer='adam'):\n",
    "#     classifier = Sequential()\n",
    "#     classifier.add(Dense(units = 6, kernel_initializer = 'uniform',\n",
    "#                          activation = 'relu', input_dim = 11))\n",
    "#     classifier.add(Dense(units = 6, kernel_initializer = 'uniform',\n",
    "#                          activation = 'relu'))\n",
    "#     classifier.add(Dense(units = 1, kernel_initializer = 'uniform',\n",
    "#                          activation = 'sigmoid'))\n",
    "#     classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "#     return classifier\n",
    "\n",
    "# classifier = KerasClassifier(model = build_classifier)\n",
    "\n",
    "# parameters = {'batch_size': [25, 32],\n",
    "#               'epochs': [100, 500],\n",
    "#               'optimizer': ['adam', 'rmsprop']}                # Combinations of parameters to try = 2 * 2 * 2 = 8\n",
    "\n",
    "# grid_search = GridSearchCV(estimator = classifier,\n",
    "#                            param_grid = parameters,\n",
    "#                            scoring = 'accuracy',\n",
    "#                            cv = 10)\n",
    "\n",
    "# grid_search = grid_search.fit(X_train, y_train)               #### Time of Execution = +10min\n",
    "# best_parameters = grid_search.best_params_\n",
    "# best_accuracy = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "## Best Model Parameters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training the network with the best parameters\n",
    "# classifier = build_classifier(optimizer = best_parameters['optimizer'])\n",
    "# hist = classifier.fit(X_train, y_train, batch_size = best_parameters['batch_size'], epochs = best_parameters['epochs'])\n",
    "\n",
    "# # Predicting the Test set results\n",
    "# y_pred = classifier.predict(X_test)\n",
    "# y_pred = (y_pred > 0.5)\n",
    "\n",
    "# # Making the Confusion Matrix\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# # Print Statistics from Confusion Matrix\n",
    "# from sklearn.metrics import classification_report\n",
    "# target_names = ['Stay', 'Leave']\n",
    "# print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# # Visualizing Confusion Matrix\n",
    "# plt.figure(figsize = (8, 5))\n",
    "# sns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15}, \n",
    "#             yticklabels = ['Stay', 'Leave'], xticklabels = ['Predicted Stay', 'Predicted Leave'])\n",
    "# plt.yticks(rotation = 0)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8000 - loss: 0.6628 - val_accuracy: 0.7850 - val_loss: 0.4929\n",
      "Epoch 2/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8059 - loss: 0.4479 - val_accuracy: 0.7850 - val_loss: 0.4532\n",
      "Epoch 3/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8016 - loss: 0.4329 - val_accuracy: 0.7850 - val_loss: 0.4484\n",
      "Epoch 4/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8100 - loss: 0.4119 - val_accuracy: 0.7850 - val_loss: 0.4457\n",
      "Epoch 5/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7963 - loss: 0.4289 - val_accuracy: 0.7850 - val_loss: 0.4449\n",
      "Epoch 6/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7969 - loss: 0.4303 - val_accuracy: 0.7850 - val_loss: 0.4422\n",
      "Epoch 7/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7950 - loss: 0.4278 - val_accuracy: 0.7850 - val_loss: 0.4414\n",
      "Epoch 8/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8035 - loss: 0.4172 - val_accuracy: 0.7850 - val_loss: 0.4401\n",
      "Epoch 9/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8079 - loss: 0.4015 - val_accuracy: 0.7850 - val_loss: 0.4382\n",
      "Epoch 10/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8027 - loss: 0.4167 - val_accuracy: 0.8042 - val_loss: 0.4383\n",
      "Epoch 11/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8209 - loss: 0.4140 - val_accuracy: 0.8058 - val_loss: 0.4387\n",
      "Epoch 12/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8229 - loss: 0.4139 - val_accuracy: 0.8087 - val_loss: 0.4377\n",
      "Epoch 13/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8291 - loss: 0.4101 - val_accuracy: 0.8092 - val_loss: 0.4364\n",
      "Epoch 14/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8278 - loss: 0.4122 - val_accuracy: 0.8104 - val_loss: 0.4361\n",
      "Epoch 15/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8195 - loss: 0.4240 - val_accuracy: 0.8117 - val_loss: 0.4365\n",
      "Epoch 16/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8357 - loss: 0.4023 - val_accuracy: 0.8117 - val_loss: 0.4349\n",
      "Epoch 17/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8349 - loss: 0.4070 - val_accuracy: 0.8117 - val_loss: 0.4346\n",
      "Epoch 18/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8441 - loss: 0.3931 - val_accuracy: 0.8129 - val_loss: 0.4339\n",
      "Epoch 19/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8398 - loss: 0.4020 - val_accuracy: 0.8142 - val_loss: 0.4337\n",
      "Epoch 20/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8350 - loss: 0.4166 - val_accuracy: 0.8133 - val_loss: 0.4352\n",
      "Epoch 21/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3919 - val_accuracy: 0.8146 - val_loss: 0.4328\n",
      "Epoch 22/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8283 - loss: 0.4229 - val_accuracy: 0.8133 - val_loss: 0.4346\n",
      "Epoch 23/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8363 - loss: 0.4026 - val_accuracy: 0.8150 - val_loss: 0.4334\n",
      "Epoch 24/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3868 - val_accuracy: 0.8163 - val_loss: 0.4319\n",
      "Epoch 25/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8398 - loss: 0.4025 - val_accuracy: 0.8171 - val_loss: 0.4322\n",
      "Epoch 26/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8363 - loss: 0.4122 - val_accuracy: 0.8183 - val_loss: 0.4318\n",
      "Epoch 27/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8413 - loss: 0.4025 - val_accuracy: 0.8175 - val_loss: 0.4312\n",
      "Epoch 28/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8483 - loss: 0.3891 - val_accuracy: 0.8183 - val_loss: 0.4308\n",
      "Epoch 29/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8448 - loss: 0.3951 - val_accuracy: 0.8196 - val_loss: 0.4305\n",
      "Epoch 30/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8420 - loss: 0.3992 - val_accuracy: 0.8200 - val_loss: 0.4305\n",
      "Epoch 31/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8388 - loss: 0.4029 - val_accuracy: 0.8192 - val_loss: 0.4312\n",
      "Epoch 32/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8441 - loss: 0.4068 - val_accuracy: 0.8183 - val_loss: 0.4305\n",
      "Epoch 33/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.4079 - val_accuracy: 0.8200 - val_loss: 0.4300\n",
      "Epoch 34/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8429 - loss: 0.4001 - val_accuracy: 0.8188 - val_loss: 0.4302\n",
      "Epoch 35/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8417 - loss: 0.3984 - val_accuracy: 0.8204 - val_loss: 0.4291\n",
      "Epoch 36/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8393 - loss: 0.4000 - val_accuracy: 0.8208 - val_loss: 0.4281\n",
      "Epoch 37/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8413 - loss: 0.4021 - val_accuracy: 0.8179 - val_loss: 0.4298\n",
      "Epoch 38/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8404 - loss: 0.3971 - val_accuracy: 0.8213 - val_loss: 0.4284\n",
      "Epoch 39/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4041 - val_accuracy: 0.8204 - val_loss: 0.4278\n",
      "Epoch 40/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8490 - loss: 0.3816 - val_accuracy: 0.8217 - val_loss: 0.4273\n",
      "Epoch 41/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8382 - loss: 0.4028 - val_accuracy: 0.8229 - val_loss: 0.4274\n",
      "Epoch 42/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8354 - loss: 0.4032 - val_accuracy: 0.8208 - val_loss: 0.4283\n",
      "Epoch 43/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8441 - loss: 0.3977 - val_accuracy: 0.8221 - val_loss: 0.4269\n",
      "Epoch 44/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8452 - loss: 0.3961 - val_accuracy: 0.8217 - val_loss: 0.4264\n",
      "Epoch 45/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8428 - loss: 0.3888 - val_accuracy: 0.8221 - val_loss: 0.4272\n",
      "Epoch 46/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8558 - loss: 0.3773 - val_accuracy: 0.8225 - val_loss: 0.4258\n",
      "Epoch 47/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8439 - loss: 0.4008 - val_accuracy: 0.8221 - val_loss: 0.4260\n",
      "Epoch 48/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8494 - loss: 0.3867 - val_accuracy: 0.8225 - val_loss: 0.4255\n",
      "Epoch 49/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8354 - loss: 0.4029 - val_accuracy: 0.8221 - val_loss: 0.4260\n",
      "Epoch 50/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8384 - loss: 0.4087 - val_accuracy: 0.8200 - val_loss: 0.4259\n",
      "Epoch 51/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8470 - loss: 0.3916 - val_accuracy: 0.8204 - val_loss: 0.4250\n",
      "Epoch 52/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8450 - loss: 0.3939 - val_accuracy: 0.8204 - val_loss: 0.4256\n",
      "Epoch 53/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8468 - loss: 0.3877 - val_accuracy: 0.8204 - val_loss: 0.4248\n",
      "Epoch 54/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8418 - loss: 0.3956 - val_accuracy: 0.8213 - val_loss: 0.4258\n",
      "Epoch 55/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8447 - loss: 0.3912 - val_accuracy: 0.8217 - val_loss: 0.4245\n",
      "Epoch 56/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8437 - loss: 0.3992 - val_accuracy: 0.8196 - val_loss: 0.4257\n",
      "Epoch 57/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8428 - loss: 0.4045 - val_accuracy: 0.8196 - val_loss: 0.4266\n",
      "Epoch 58/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8371 - loss: 0.4047 - val_accuracy: 0.8208 - val_loss: 0.4251\n",
      "Epoch 59/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8453 - loss: 0.3973 - val_accuracy: 0.8225 - val_loss: 0.4240\n",
      "Epoch 60/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8445 - loss: 0.3862 - val_accuracy: 0.8225 - val_loss: 0.4241\n",
      "Epoch 61/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8421 - loss: 0.3960 - val_accuracy: 0.8204 - val_loss: 0.4246\n",
      "Epoch 62/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8534 - loss: 0.3821 - val_accuracy: 0.8217 - val_loss: 0.4243\n",
      "Epoch 63/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8372 - loss: 0.4084 - val_accuracy: 0.8217 - val_loss: 0.4237\n",
      "Epoch 64/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8464 - loss: 0.3895 - val_accuracy: 0.8208 - val_loss: 0.4236\n",
      "Epoch 65/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8380 - loss: 0.3987 - val_accuracy: 0.8225 - val_loss: 0.4238\n",
      "Epoch 66/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8352 - loss: 0.4100 - val_accuracy: 0.8229 - val_loss: 0.4249\n",
      "Epoch 67/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8377 - loss: 0.3990 - val_accuracy: 0.8221 - val_loss: 0.4235\n",
      "Epoch 68/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3900 - val_accuracy: 0.8221 - val_loss: 0.4238\n",
      "Epoch 69/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.3987 - val_accuracy: 0.8213 - val_loss: 0.4243\n",
      "Epoch 70/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8435 - loss: 0.3995 - val_accuracy: 0.8221 - val_loss: 0.4232\n",
      "Epoch 71/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8466 - loss: 0.3888 - val_accuracy: 0.8208 - val_loss: 0.4237\n",
      "Epoch 72/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8413 - loss: 0.4011 - val_accuracy: 0.8208 - val_loss: 0.4239\n",
      "Epoch 73/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8419 - loss: 0.4004 - val_accuracy: 0.8221 - val_loss: 0.4234\n",
      "Epoch 74/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8417 - loss: 0.3956 - val_accuracy: 0.8217 - val_loss: 0.4231\n",
      "Epoch 75/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8463 - loss: 0.3929 - val_accuracy: 0.8238 - val_loss: 0.4229\n",
      "Epoch 76/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8507 - loss: 0.3836 - val_accuracy: 0.8229 - val_loss: 0.4225\n",
      "Epoch 77/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8459 - loss: 0.3963 - val_accuracy: 0.8225 - val_loss: 0.4224\n",
      "Epoch 78/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8409 - loss: 0.3989 - val_accuracy: 0.8229 - val_loss: 0.4237\n",
      "Epoch 79/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8510 - loss: 0.3848 - val_accuracy: 0.8233 - val_loss: 0.4224\n",
      "Epoch 80/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3944 - val_accuracy: 0.8233 - val_loss: 0.4231\n",
      "Epoch 81/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8380 - loss: 0.4006 - val_accuracy: 0.8213 - val_loss: 0.4222\n",
      "Epoch 82/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8456 - loss: 0.3879 - val_accuracy: 0.8225 - val_loss: 0.4218\n",
      "Epoch 83/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8326 - loss: 0.4001 - val_accuracy: 0.8221 - val_loss: 0.4227\n",
      "Epoch 84/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8475 - loss: 0.3881 - val_accuracy: 0.8221 - val_loss: 0.4223\n",
      "Epoch 85/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8396 - loss: 0.3985 - val_accuracy: 0.8221 - val_loss: 0.4230\n",
      "Epoch 86/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8528 - loss: 0.3755 - val_accuracy: 0.8221 - val_loss: 0.4225\n",
      "Epoch 87/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8482 - loss: 0.3897 - val_accuracy: 0.8229 - val_loss: 0.4221\n",
      "Epoch 88/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8470 - loss: 0.3923 - val_accuracy: 0.8217 - val_loss: 0.4228\n",
      "Epoch 89/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8374 - loss: 0.4035 - val_accuracy: 0.8221 - val_loss: 0.4246\n",
      "Epoch 90/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8527 - loss: 0.3799 - val_accuracy: 0.8217 - val_loss: 0.4219\n",
      "Epoch 91/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8471 - loss: 0.3879 - val_accuracy: 0.8229 - val_loss: 0.4220\n",
      "Epoch 92/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8426 - loss: 0.3869 - val_accuracy: 0.8225 - val_loss: 0.4226\n",
      "Epoch 93/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8429 - loss: 0.3937 - val_accuracy: 0.8233 - val_loss: 0.4216\n",
      "Epoch 94/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8332 - loss: 0.4038 - val_accuracy: 0.8238 - val_loss: 0.4245\n",
      "Epoch 95/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3973 - val_accuracy: 0.8229 - val_loss: 0.4219\n",
      "Epoch 96/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8486 - loss: 0.3856 - val_accuracy: 0.8238 - val_loss: 0.4220\n",
      "Epoch 97/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8338 - loss: 0.4022 - val_accuracy: 0.8213 - val_loss: 0.4239\n",
      "Epoch 98/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8441 - loss: 0.3924 - val_accuracy: 0.8229 - val_loss: 0.4217\n",
      "Epoch 99/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8430 - loss: 0.3919 - val_accuracy: 0.8238 - val_loss: 0.4213\n",
      "Epoch 100/100\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8388 - loss: 0.4034 - val_accuracy: 0.8217 - val_loss: 0.4234\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Stay       0.84      0.98      0.91      1591\n",
      "       Leave       0.78      0.28      0.41       409\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.81      0.63      0.66      2000\n",
      "weighted avg       0.83      0.84      0.80      2000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creation of the model\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Creation of an empty model\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Training the network \n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "hist=classifier.fit(X_train, y_train, validation_split= 0.3, epochs = 100)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print Statistics from Confusion Matrix\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['Stay', 'Leave']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Visualizing Confusion Matrix\n",
    "plt.figure(figsize = (8, 5))\n",
    "sns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15}, \n",
    "            yticklabels = ['Stay', 'Leave'], xticklabels = ['Predicted Stay', 'Predicted Leave'])\n",
    "plt.yticks(rotation = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing Training and Validation Accuracy\n",
    "loss_train = hist.history['accuracy']\n",
    "loss_val = hist.history['val_accuracy']\n",
    "epochs = range(1,101)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n",
    "plt.plot(epochs, loss_val, 'b', label='Validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing Training and Validation Loss\n",
    "loss_train = hist.history['loss']\n",
    "loss_val = hist.history['val_loss']\n",
    "epochs = range(1,101)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
