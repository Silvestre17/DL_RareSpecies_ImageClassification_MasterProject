{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python standard library imports\n",
    "from typing import Self, Any\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model building imports\n",
    "from keras import Model, Sequential, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "from keras.ops import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training imports\n",
    "from keras.optimizers import SGD\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.metrics import CategoricalAccuracy, AUC, F1Score\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation operations\n",
    "from keras.layers import RandomBrightness, RandomFlip, RandomRotation\n",
    "from keras.layers import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom modules imports\n",
    "from src.utils import load_cifar10_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10\n",
    "\n",
    "# specify input_shape and number of classes\n",
    "input_shape = (32, 32, 3) # RGB\n",
    "n_classes = 10\n",
    "\n",
    "# 0. airplane\n",
    "# 1. car\n",
    "# 2. bird\n",
    "# 3. cat\n",
    "# 4. deer\n",
    "# 5. dog\n",
    "# 6. frog\n",
    "# 7. horse\n",
    "# 8. ship\n",
    "# 9. truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_range = (0.0, 1.0)\n",
    "\n",
    "augmentation_layer = Pipeline(\n",
    "    [\n",
    "        RandomBrightness(factor=0.1, value_range=value_range),\n",
    "        RandomFlip(),\n",
    "        RandomRotation(factor=0.1, fill_mode=\"reflect\")\n",
    "    ],\n",
    "    name=\"augmentation_layer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTinyCNN(Model):\n",
    "    \"\"\"\n",
    "    MyTinyCNN class, inherets from keras' Model class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self: Self, activation: str = \"relu\") -> None:\n",
    "        \"\"\"\n",
    "        Initialization\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(name=\"my_tiny_oo_cnn\")\n",
    "\n",
    "        self.augmentation_layer = augmentation_layer\n",
    "\n",
    "        self.conv_layer_1 = Conv2D(\n",
    "            filters=3 * 8,\n",
    "            kernel_size=(3, 3),\n",
    "            activation=activation,\n",
    "            name=\"conv_layer_1\"\n",
    "        )\n",
    "        self.max_pool_layer_1 = MaxPooling2D(\n",
    "            pool_size=(2, 2),\n",
    "            name=\"max_pool_layer_1\"\n",
    "        )\n",
    "\n",
    "        # exemplify non-sequential nature of computation possible with\n",
    "        # the functional and object-oriented methods\n",
    "        self.conv_layer_2l = Conv2D(\n",
    "            filters=3 * 16,\n",
    "            kernel_size=(3, 3),\n",
    "            activation=activation,\n",
    "            name=\"conv_layer_2l\",\n",
    "            padding=\"same\"\n",
    "        )\n",
    "        self.conv_layer_2r = Conv2D(\n",
    "            filters=3 * 16,\n",
    "            kernel_size=(2, 2),\n",
    "            activation=activation,\n",
    "            name=\"conv_layer_2r\",\n",
    "            padding=\"same\"\n",
    "        )\n",
    "        self.max_pool_layer_2 = MaxPooling2D(\n",
    "            pool_size=(2, 2),\n",
    "            name=\"max_pool_layer_2\"\n",
    "        )\n",
    "\n",
    "        self.flatten_layer = Flatten(name=\"flatten_layer\")\n",
    "        self.dropout = Dropout(rate=0.3)\n",
    "        self.dense_layer = Dense(\n",
    "            n_classes,\n",
    "            activation=\"softmax\",\n",
    "            name=\"classification_head\"\n",
    "        )\n",
    "\n",
    "    def call(self: Self, inputs: Any) -> Any:\n",
    "        \"\"\"\n",
    "        Forward call\n",
    "        \"\"\"\n",
    "\n",
    "        x = self.augmentation_layer(inputs)\n",
    "\n",
    "\n",
    "        x = self.conv_layer_1(x)\n",
    "        x = self.max_pool_layer_1(x)\n",
    "\n",
    "        # exemplify non-sequential nature of computation possible with\n",
    "        # the functional and object-oriented methods\n",
    "        x_l = self.conv_layer_2l(x)\n",
    "        x_r = self.conv_layer_2r(x)\n",
    "        x = add(x_l, x_r)\n",
    "        x = self.max_pool_layer_2(x)\n",
    "\n",
    "        x = self.flatten_layer(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return  self.dense_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our regularized MyTinyCNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_cifar10_sample(1024, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 32\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add L2 weight decay to the optimizer directly, don't add a new loss term\n",
    "model = MyTinyCNN()\n",
    "optimizer = SGD(learning_rate=0.01, name=\"optimizer\", weight_decay=0.01)\n",
    "loss = CategoricalCrossentropy(name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "## **Note:**\n",
    "\n",
    "O **`weight_decay=0.01`** é o $\\alpha$ que multiplica a norma L2 dos pesos na função de perda.\n",
    "\n",
    "$$ \\text{loss} = L_{reg} + \\alpha \\times L_{W} = \\frac{1}{2} \\times (x - \\hat{x})^2 + \\alpha \\times \\left( \\sum_{i=1}^{n} \\left| w_i \\right|^2 \\right) $$\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "categorical_accuracy = CategoricalAccuracy(name=\"accuracy\")\n",
    "auc = AUC(name=\"auc\")\n",
    "f1_score = F1Score(average=\"macro\", name=\"f1_score\")\n",
    "metrics = [categorical_accuracy, auc, f1_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traces the computation\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are callbacks?\n",
    "root_dir_path = Path(\".\")\n",
    "checkpoint_file_path = root_dir_path / \"checkpoint.keras\"\n",
    "metrics_file_path = root_dir_path = root_dir_path / \"metrics.csv\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    checkpoint_file_path,                                             # Salva para cada epoch guarda o modelo no nosso PC\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0\n",
    ")\n",
    "metrics_callback = CSVLogger(metrics_file_path)                       # Isto guarda as métricas no nosso PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is a learning rate scheduler ?\n",
    "def exp_decay_lr_scheduler(\n",
    "    epoch: int,                                              # O 1º e o 2º argumentos têm de ser o epoch e o lr nesta ordem\n",
    "    current_lr: float,\n",
    "    factor: float = 0.95\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Exponential decay learning rate scheduler\n",
    "    \"\"\"\n",
    "\n",
    "    current_lr *= factor\n",
    "\n",
    "    return current_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler_callback = LearningRateScheduler(exp_decay_lr_scheduler) # Ele fez um gráfico em que o lr é o y e o epoch é o x, e o lr vai diminuindo muito ao longo dos epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    checkpoint_callback,\n",
    "    metrics_callback,\n",
    "    lr_scheduler_callback\n",
    "]              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "52/52 - 4s - 72ms/step - accuracy: 0.1038 - auc: 0.4920 - f1_score: 0.0893 - loss: 2.3414 - val_accuracy: 0.1171 - val_auc: 0.5356 - val_f1_score: 0.0826 - val_loss: 2.2989 - learning_rate: 0.0095\n",
      "Epoch 2/32\n",
      "52/52 - 1s - 15ms/step - accuracy: 0.1197 - auc: 0.5233 - f1_score: 0.1049 - loss: 2.3048 - val_accuracy: 0.1415 - val_auc: 0.5622 - val_f1_score: 0.1110 - val_loss: 2.2796 - learning_rate: 0.0090\n",
      "Epoch 3/32\n",
      "52/52 - 1s - 15ms/step - accuracy: 0.1392 - auc: 0.5534 - f1_score: 0.1076 - loss: 2.2879 - val_accuracy: 0.1268 - val_auc: 0.5829 - val_f1_score: 0.0934 - val_loss: 2.2685 - learning_rate: 0.0086\n",
      "Epoch 4/32\n",
      "52/52 - 1s - 15ms/step - accuracy: 0.1429 - auc: 0.5733 - f1_score: 0.1221 - loss: 2.2774 - val_accuracy: 0.1317 - val_auc: 0.5511 - val_f1_score: 0.0897 - val_loss: 2.2851 - learning_rate: 0.0081\n",
      "Epoch 5/32\n",
      "52/52 - 1s - 14ms/step - accuracy: 0.1600 - auc: 0.5820 - f1_score: 0.1194 - loss: 2.2695 - val_accuracy: 0.2098 - val_auc: 0.6114 - val_f1_score: 0.1799 - val_loss: 2.2493 - learning_rate: 0.0077\n",
      "Epoch 6/32\n",
      "52/52 - 1s - 15ms/step - accuracy: 0.1612 - auc: 0.5972 - f1_score: 0.1365 - loss: 2.2605 - val_accuracy: 0.1317 - val_auc: 0.6031 - val_f1_score: 0.0977 - val_loss: 2.2501 - learning_rate: 0.0074\n",
      "Epoch 7/32\n",
      "52/52 - 1s - 15ms/step - accuracy: 0.1673 - auc: 0.6138 - f1_score: 0.1248 - loss: 2.2481 - val_accuracy: 0.1171 - val_auc: 0.6148 - val_f1_score: 0.0936 - val_loss: 2.2486 - learning_rate: 0.0070\n",
      "Epoch 8/32\n",
      "52/52 - 1s - 14ms/step - accuracy: 0.1795 - auc: 0.6367 - f1_score: 0.1522 - loss: 2.2349 - val_accuracy: 0.1366 - val_auc: 0.6296 - val_f1_score: 0.1016 - val_loss: 2.2327 - learning_rate: 0.0066\n",
      "Epoch 9/32\n",
      "52/52 - 1s - 14ms/step - accuracy: 0.1905 - auc: 0.6426 - f1_score: 0.1472 - loss: 2.2219 - val_accuracy: 0.1951 - val_auc: 0.6450 - val_f1_score: 0.1400 - val_loss: 2.2042 - learning_rate: 0.0063\n",
      "Epoch 10/32\n",
      "52/52 - 1s - 14ms/step - accuracy: 0.1844 - auc: 0.6422 - f1_score: 0.1431 - loss: 2.2130 - val_accuracy: 0.2293 - val_auc: 0.6736 - val_f1_score: 0.2055 - val_loss: 2.1811 - learning_rate: 0.0060\n",
      "Epoch 11/32\n",
      "52/52 - 1s - 13ms/step - accuracy: 0.2112 - auc: 0.6587 - f1_score: 0.1825 - loss: 2.1971 - val_accuracy: 0.1951 - val_auc: 0.6441 - val_f1_score: 0.1651 - val_loss: 2.2014 - learning_rate: 0.0057\n",
      "Epoch 12/32\n",
      "52/52 - 1s - 13ms/step - accuracy: 0.2039 - auc: 0.6622 - f1_score: 0.1683 - loss: 2.1876 - val_accuracy: 0.1756 - val_auc: 0.6638 - val_f1_score: 0.1444 - val_loss: 2.1797 - learning_rate: 0.0054\n",
      "Epoch 13/32\n",
      "52/52 - 1s - 13ms/step - accuracy: 0.2210 - auc: 0.6768 - f1_score: 0.1768 - loss: 2.1660 - val_accuracy: 0.2049 - val_auc: 0.6647 - val_f1_score: 0.1634 - val_loss: 2.1607 - learning_rate: 0.0051\n",
      "Epoch 14/32\n",
      "52/52 - 1s - 13ms/step - accuracy: 0.2137 - auc: 0.6829 - f1_score: 0.1836 - loss: 2.1495 - val_accuracy: 0.2049 - val_auc: 0.6779 - val_f1_score: 0.1971 - val_loss: 2.1511 - learning_rate: 0.0049\n",
      "Epoch 15/32\n",
      "52/52 - 1s - 13ms/step - accuracy: 0.2344 - auc: 0.6839 - f1_score: 0.2094 - loss: 2.1450 - val_accuracy: 0.1805 - val_auc: 0.6662 - val_f1_score: 0.1343 - val_loss: 2.1476 - learning_rate: 0.0046\n",
      "Epoch 16/32\n",
      "52/52 - 1s - 13ms/step - accuracy: 0.2222 - auc: 0.6835 - f1_score: 0.2010 - loss: 2.1400 - val_accuracy: 0.2049 - val_auc: 0.6696 - val_f1_score: 0.1589 - val_loss: 2.1577 - learning_rate: 0.0044\n",
      "Epoch 17/32\n",
      "52/52 - 1s - 13ms/step - accuracy: 0.2149 - auc: 0.6780 - f1_score: 0.1851 - loss: 2.1396 - val_accuracy: 0.1902 - val_auc: 0.6845 - val_f1_score: 0.1637 - val_loss: 2.1173 - learning_rate: 0.0042\n",
      "Epoch 18/32\n",
      "52/52 - 1s - 13ms/step - accuracy: 0.2344 - auc: 0.6948 - f1_score: 0.2071 - loss: 2.1242 - val_accuracy: 0.1707 - val_auc: 0.6822 - val_f1_score: 0.1485 - val_loss: 2.1315 - learning_rate: 0.0040\n",
      "Epoch 19/32\n",
      "52/52 - 1s - 13ms/step - accuracy: 0.2100 - auc: 0.6909 - f1_score: 0.1851 - loss: 2.1178 - val_accuracy: 0.2634 - val_auc: 0.6974 - val_f1_score: 0.2376 - val_loss: 2.0964 - learning_rate: 0.0038\n",
      "Epoch 20/32\n",
      "52/52 - 1s - 14ms/step - accuracy: 0.2344 - auc: 0.6957 - f1_score: 0.2141 - loss: 2.1139 - val_accuracy: 0.2000 - val_auc: 0.7019 - val_f1_score: 0.1728 - val_loss: 2.0874 - learning_rate: 0.0036\n",
      "Epoch 21/32\n",
      "52/52 - 1s - 14ms/step - accuracy: 0.2454 - auc: 0.6998 - f1_score: 0.2171 - loss: 2.1058 - val_accuracy: 0.2000 - val_auc: 0.6903 - val_f1_score: 0.1842 - val_loss: 2.1038 - learning_rate: 0.0034\n",
      "Epoch 22/32\n",
      "52/52 - 1s - 14ms/step - accuracy: 0.2271 - auc: 0.6960 - f1_score: 0.2028 - loss: 2.1094 - val_accuracy: 0.1805 - val_auc: 0.6752 - val_f1_score: 0.1446 - val_loss: 2.1337 - learning_rate: 0.0032\n",
      "Epoch 23/32\n",
      "52/52 - 1s - 14ms/step - accuracy: 0.2308 - auc: 0.6985 - f1_score: 0.2003 - loss: 2.1050 - val_accuracy: 0.2341 - val_auc: 0.7068 - val_f1_score: 0.2052 - val_loss: 2.0837 - learning_rate: 0.0031\n",
      "Epoch 24/32\n",
      "52/52 - 1s - 14ms/step - accuracy: 0.2466 - auc: 0.7055 - f1_score: 0.2252 - loss: 2.0947 - val_accuracy: 0.2244 - val_auc: 0.6916 - val_f1_score: 0.1755 - val_loss: 2.1091 - learning_rate: 0.0029\n",
      "Epoch 25/32\n",
      "52/52 - 1s - 14ms/step - accuracy: 0.2357 - auc: 0.7048 - f1_score: 0.2140 - loss: 2.0925 - val_accuracy: 0.1951 - val_auc: 0.6958 - val_f1_score: 0.1782 - val_loss: 2.0991 - learning_rate: 0.0028\n",
      "Epoch 26/32\n",
      "52/52 - 1s - 14ms/step - accuracy: 0.2430 - auc: 0.7061 - f1_score: 0.2180 - loss: 2.0889 - val_accuracy: 0.2244 - val_auc: 0.6924 - val_f1_score: 0.2067 - val_loss: 2.0926 - learning_rate: 0.0026\n",
      "Epoch 27/32\n",
      "52/52 - 1s - 14ms/step - accuracy: 0.2430 - auc: 0.7107 - f1_score: 0.2248 - loss: 2.0774 - val_accuracy: 0.2098 - val_auc: 0.6990 - val_f1_score: 0.2034 - val_loss: 2.0938 - learning_rate: 0.0025\n",
      "Epoch 28/32\n",
      "52/52 - 1s - 14ms/step - accuracy: 0.2759 - auc: 0.7092 - f1_score: 0.2584 - loss: 2.0747 - val_accuracy: 0.2146 - val_auc: 0.6993 - val_f1_score: 0.1938 - val_loss: 2.1010 - learning_rate: 0.0024\n",
      "Epoch 29/32\n",
      "52/52 - 1s - 14ms/step - accuracy: 0.2369 - auc: 0.7141 - f1_score: 0.2247 - loss: 2.0722 - val_accuracy: 0.2488 - val_auc: 0.6895 - val_f1_score: 0.2137 - val_loss: 2.0995 - learning_rate: 0.0023\n",
      "Epoch 30/32\n",
      "52/52 - 1s - 14ms/step - accuracy: 0.2576 - auc: 0.7103 - f1_score: 0.2288 - loss: 2.0764 - val_accuracy: 0.2244 - val_auc: 0.7044 - val_f1_score: 0.2077 - val_loss: 2.0780 - learning_rate: 0.0021\n",
      "Epoch 31/32\n",
      "52/52 - 1s - 14ms/step - accuracy: 0.2112 - auc: 0.7031 - f1_score: 0.1940 - loss: 2.0924 - val_accuracy: 0.2098 - val_auc: 0.6917 - val_f1_score: 0.1984 - val_loss: 2.0980 - learning_rate: 0.0020\n",
      "Epoch 32/32\n",
      "52/52 - 1s - 14ms/step - accuracy: 0.2625 - auc: 0.7153 - f1_score: 0.2395 - loss: 2.0693 - val_accuracy: 0.2439 - val_auc: 0.6981 - val_f1_score: 0.2173 - val_loss: 2.0849 - learning_rate: 0.0019\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "_ = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.25,\n",
       " 'auc': 0.7233818769454956,\n",
       " 'f1_score': 0.2239234894514084,\n",
       " 'loss': 2.0405728816986084}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate on the test set\n",
    "model.evaluate(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    batch_size=batch_size,\n",
    "    return_dict=True,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is label smoothing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next class:\n",
    "# Real data, real models, real world"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
