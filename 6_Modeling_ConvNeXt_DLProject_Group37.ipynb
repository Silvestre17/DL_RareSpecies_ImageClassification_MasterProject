{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1834cc3d7b582eb2",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center; justify-content: center; flex-wrap: wrap;\">\n",
    "    <div style=\"flex: 1; max-width: 400px; display: flex; justify-content: center;\">\n",
    "        <img src=\"https://i.ibb.co/JBPWVYR/Logo-Nova-IMS-Black.png\" style=\"max-width: 50%; height: auto; margin-top: 50px; margin-bottom: 50px;margin-left: 6rem;\">\n",
    "    </div>\n",
    "    <div style=\"flex: 2; text-align: center; margin-top: 20px;margin-left: 8rem;\">\n",
    "        <div style=\"font-size: 28px; font-weight: bold; line-height: 1.2;\">\n",
    "            <span style=\"color: #22c1c3;\">DL Project |</span> <span style=\"color: #08529C;\">Predicting Rare Species from Images using Deep Learning</span>\n",
    "        </div>\n",
    "        <div style=\"font-size: 17px; font-weight: bold; margin-top: 10px;\">\n",
    "            Spring Semester | 2024 - 2025\n",
    "        </div>\n",
    "        <div style=\"font-size: 17px; font-weight: bold;\">\n",
    "            Master in Data Science and Advanced Analytics\n",
    "        </div>\n",
    "        <div style=\"margin-top: 20px;\">\n",
    "            <div>AndrÃ© Silvestre, 20240502</div>\n",
    "            <div>Diogo Duarte, 20240525</div>\n",
    "            <div>Filipa Pereira, 20240509</div>\n",
    "            <div>Maria Cruz, 20230760</div>\n",
    "            <div>Umeima Mahomed, 20240543</div>\n",
    "        </div>\n",
    "        <div style=\"margin-top: 20px; font-weight: bold;\">\n",
    "            Group 37\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827c9197",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right, #22c1c3, #27b1dd, #2d9cfd, #090979); \n",
    "            padding: 1px; color: white; border-radius: 500px; text-align: center;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f603cf1cb0fd531",
   "metadata": {},
   "source": [
    "## **ğŸ“š Libraries Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c91174e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 15:39:40.859964: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-14 15:39:41.055554: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744641581.156807  998360 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744641581.183200  998360 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-14 15:39:41.394043: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from typing_extensions import Self, Any      # For Python 3.10\n",
    "# from typing import Self, Any               # For Python >3.11\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Data manipulation imports\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Deep learning imports\n",
    "import tensorflow as tf\n",
    "from keras.ops import add\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import Model, Sequential, Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Rescaling, Lambda, BatchNormalization, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras import regularizers                                                                           # For L2 regularization\n",
    "#import visualkeras\n",
    "\n",
    "# Evaluation imports\n",
    "from keras.metrics import CategoricalAccuracy, AUC, F1Score, Precision, Recall\n",
    "\n",
    "# Other imports\n",
    "from itertools import product\n",
    "\n",
    "# Set the style of the visualization\n",
    "pd.set_option('future.no_silent_downcasting', True)   # use int instead of float in DataFrame\n",
    "pd.set_option(\"display.max_columns\", None)            # display all columns\n",
    "\n",
    "# Disable warnings (FutureWarning)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d062f5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.18.0\n",
      "Is TensorFlow built with CUDA? True\n",
      "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU Device Name: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744641584.052962  998360 gpu_device.cc:2022] Created device /device:GPU:0 with 8814 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"Is TensorFlow built with CUDA?\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"GPU Device Name:\", tf.test.gpu_device_name())                                # (if error in Google Colab: Make sure your Hardware accelerator is set to GPU. \n",
    "                                                                                    # Runtime > Change runtime type > Hardware Accelerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24fb75d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "Python version: 3.12.3 (main, Feb  4 2025, 14:48:35) [GCC 13.3.0]\n",
      "CUDA version: 12.5.1\n",
      "cuDNN version: 9\n"
     ]
    }
   ],
   "source": [
    "# Get build information from TensorFlow\n",
    "build_info = tf.sysconfig.get_build_info()\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"CUDA version:\", build_info.get(\"cuda_version\", \"Not available\"))\n",
    "print(\"cuDNN version:\", build_info.get(\"cudnn_version\", \"Not available\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e540451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom module for importing data, visualization, and utilities\n",
    "import utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5d91a720daf9a2",
   "metadata": {},
   "source": [
    "## **ğŸ§® Import Databases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b87da922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data\n",
    "train_dir = Path(\"data/RareSpecies_Split/train\")\n",
    "val_dir = Path(\"data/RareSpecies_Split/val\")\n",
    "test_dir = Path(\"data/RareSpecies_Split/test\")\n",
    "\n",
    "# For Google Collab\n",
    "# train_dir = Path(\"/content/RareSpecies_Split/train\")\n",
    "# val_dir = Path(\"/content/RareSpecies_Split/val\")\n",
    "# test_dir = Path(\"/content/RareSpecies_Split/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5977e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Generators \n",
    "n_classes = 202                                     # Number of classes (we already know this based on previous notebook)\n",
    "image_size = (224, 224)                             # Image size (224x224)\n",
    "img_height, img_width = image_size                  # Image dimensions\n",
    "batch_size = 64                                     # Batch size\n",
    "input_shape = (img_height, img_width, 3)            # Input shape of the model\n",
    "value_range = (0.0, 1.0)                            # Range of pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd04ae91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9586 files belonging to 202 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744641584.900380  998360 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8814 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1198 files belonging to 202 classes.\n",
      "Found 1199 files belonging to 202 classes.\n",
      "\n",
      "Loaded: Train (9600), Val (1216), Test (1216)\n"
     ]
    }
   ],
   "source": [
    "# Get class names from directory\n",
    "class_names = sorted(os.listdir(train_dir))\n",
    "class_indices = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "# Import the image dataset from the directory\n",
    "from utilities import load_images_from_directory\n",
    "train_datagen, val_datagen, test_datagen = load_images_from_directory(train_dir, val_dir, test_dir,\n",
    "                                                                      labels='inferred', label_mode='categorical',\n",
    "                                                                      class_names=class_names, color_mode='rgb',\n",
    "                                                                      batch_size=batch_size, image_size=image_size, seed=2025, \n",
    "                                                                      interpolation='bilinear', crop_to_aspect_ratio=False, pad_to_aspect_ratio=False)\n",
    "\n",
    "print(f\"\\nLoaded: Train ({train_datagen.cardinality().numpy() * batch_size}), \"\n",
    "        f\"Val ({val_datagen.cardinality().numpy() * batch_size}), \"\n",
    "        f\"Test ({test_datagen.cardinality().numpy() * batch_size})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ba8a0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch shape: (64, 224, 224, 3) (64, 202)\n",
      "Val batch shape: (64, 224, 224, 3) (64, 202)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 15:39:53.293953: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-04-14 15:39:53.466977: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test batch shape: (64, 224, 224, 3) (64, 202)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the data (batch_size, img_width, img_height, 3)\n",
    "for x, y in train_datagen.take(1):\n",
    "    print(\"Train batch shape:\", x.shape, y.shape)\n",
    "for x, y in val_datagen.take(1):\n",
    "    print(\"Val batch shape:\", x.shape, y.shape)\n",
    "for x, y in test_datagen.take(1):\n",
    "    print(\"Test batch shape:\", x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f158b792ebd291",
   "metadata": {},
   "source": [
    "# <a class='anchor' id='3'></a>\n",
    "<br>\n",
    "<style>\n",
    "@import url('https://fonts.cdnfonts.com/css/avenir-next-lt-pro?styles=29974');\n",
    "</style>\n",
    "\n",
    "<div style=\"background: linear-gradient(to right, #22c1c3, #27b1dd, #2d9cfd, #090979); \n",
    "            padding: 10px; color: white; border-radius: 300px; text-align: center;\">\n",
    "    <center><h1 style=\"margin-left: 140px;margin-top: 10px; margin-bottom: 4px; color: white;\n",
    "                       font-size: 32px; font-family: 'Avenir Next LT Pro', sans-serif;\">\n",
    "        <b>3 | Modeling - ConvNetXt</b></h1></center>\n",
    "</div>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<center><img src=\"\" style=\"width: 700px\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26312ae5b0368022",
   "metadata": {},
   "source": [
    "# **ğŸ’¡ Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3556121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/convnext/convnext_tiny_notop.h5\n",
      "\u001b[1m111650432/111650432\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"rare_species_cnn\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"rare_species_cnn\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ Rescale_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ convnext_tiny (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">27,820,128</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Global_Average_Pooling          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Dropout_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Output_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">155,338</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ Rescale_Layer (\u001b[38;5;33mRescaling\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ convnext_tiny (\u001b[38;5;33mFunctional\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m768\u001b[0m)      â”‚    \u001b[38;5;34m27,820,128\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Global_Average_Pooling          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Dropout_Layer (\u001b[38;5;33mDropout\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Output_Layer (\u001b[38;5;33mDense\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m202\u001b[0m)            â”‚       \u001b[38;5;34m155,338\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,975,466</span> (106.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m27,975,466\u001b[0m (106.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,975,466</span> (106.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m27,975,466\u001b[0m (106.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ConvNeXtTiny\n",
    "\n",
    "class RareSpeciesCNN(Model):\n",
    "    \"\"\"Custom CNN for rare species classification using ConvNeXt backbone.\"\"\"\n",
    "    def __init__(self, n_classes=202,\n",
    "                 apply_grayscale=False,\n",
    "                 apply_contrast=False, contrast_factor=1.5,\n",
    "                 apply_saturation=False, saturation_factor=1.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.apply_grayscale = apply_grayscale\n",
    "        self.apply_contrast = apply_contrast\n",
    "        self.apply_saturation = apply_saturation\n",
    "\n",
    "        # Preprocessing Layers\n",
    "        self.rescale_layer = Rescaling(scale=1/255.0, name=\"Rescale_Layer\")\n",
    "\n",
    "        if self.apply_contrast:\n",
    "            self.contrast_layer = Lambda(\n",
    "                lambda x: tf.image.adjust_contrast(x, contrast_factor=contrast_factor),\n",
    "                name='Adjust_Contrast'\n",
    "            )\n",
    "\n",
    "        if self.apply_saturation:\n",
    "            self.saturation_layer = Lambda(\n",
    "                lambda x: tf.image.adjust_saturation(x, saturation_factor=saturation_factor),\n",
    "                name='Adjust_Saturation'\n",
    "            )\n",
    "\n",
    "        if self.apply_grayscale:\n",
    "            self.grayscale_layer = Lambda(\n",
    "                lambda x: tf.image.rgb_to_grayscale(x),\n",
    "                name='RGB_to_Grayscale'\n",
    "            )\n",
    "            self.grayscale_to_rgb_layer = Lambda(\n",
    "                lambda x: tf.image.grayscale_to_rgb(x),\n",
    "                name='Grayscale_to_RGB'\n",
    "            )\n",
    "\n",
    "        # ConvNeXt Backbone\n",
    "        self.convnext_base = ConvNeXtTiny(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(224, 224, 3)\n",
    "        )\n",
    "\n",
    "        # Classification Head\n",
    "        self.global_avg_pool = GlobalAveragePooling2D(name=\"Global_Average_Pooling\")\n",
    "        self.dropout = Dropout(0.7, name=\"Dropout_Layer\")\n",
    "        self.dense_output = Dense(n_classes, activation='softmax', name=\"Output_Layer\")\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.rescale_layer(inputs)\n",
    "\n",
    "        if self.apply_contrast:\n",
    "            x = self.contrast_layer(x)\n",
    "        if self.apply_saturation:\n",
    "            x = self.saturation_layer(x)\n",
    "        if self.apply_grayscale:\n",
    "            x = self.grayscale_layer(x)\n",
    "            x = self.grayscale_to_rgb_layer(x)\n",
    "\n",
    "        x = self.convnext_base(x, training=training)\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "        outputs = self.dense_output(x)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "# Example Instantiation and Summary\n",
    "model = RareSpeciesCNN(\n",
    "    n_classes=n_classes,\n",
    "    apply_grayscale=False,\n",
    "    apply_contrast=False,\n",
    "    apply_saturation=False,\n",
    ")\n",
    "\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "_ = model.call(inputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "391168a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "# optimizer = SGD(learning_rate=0.1, weight_decay=0.01, name=\"Optimizer\")                                         # SGD with decay for stability\n",
    "optimizer = Adam(learning_rate=0.001, weight_decay=0.01, name=\"Optimizer\")                                        # Adam for faster convergence\n",
    "\n",
    "loss = CategoricalCrossentropy(name=\"Loss\")                                                                       # Suitable for multi-class one-hot labels\n",
    "metrics = [CategoricalAccuracy(name=\"accuracy\"), \n",
    "           Precision(name=\"precision\"),\n",
    "           Recall(name=\"recall\"), \n",
    "           F1Score(average=\"macro\", name=\"f1_score\"),\n",
    "           AUC(name=\"auc\")]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb397465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mModel name:\u001b[0m RareSpeciesCNN_20250414\n"
     ]
    }
   ],
   "source": [
    "# Create a directory for saving the model and logs\n",
    "model_name = f\"RareSpeciesCNN_{datetime.datetime.now().strftime('%Y%m%d')}\"                                                                             # Model name \n",
    "print(f\"\\n\\033[1mModel name:\\033[0m {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e62494e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "# Create a directory for saving the model and logs\n",
    "os.makedirs(\"./ModelCallbacks\", exist_ok=True)      # Create directory if it doesn't exist\n",
    "model_name = f\"RareSpeciesCNN_{datetime.datetime.now().strftime('%Y%m%d')}\"                                                                             # Model name \n",
    "callbacks = [\n",
    "    ModelCheckpoint(f\"./ModelCallbacks/checkpoint_{model_name}.keras\", monitor=\"val_loss\", save_best_only=True, verbose=0),       # Save best model\n",
    "    CSVLogger(f\"./ModelCallbacks/metrics_{model_name}.csv\"),                                                                      # Log training metrics\n",
    "    LearningRateScheduler(lambda epoch, lr: lr * 0.95),                                                                           # Exponential decay for learning rate\n",
    "    EarlyStopping(monitor='val_loss', patience=3, verbose=1)                                                                      # Stop training when the validation loss stops improving\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f48a4f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc436a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1744641769.737000  998535 service.cc:148] XLA service 0x7f3b4000a450 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1744641769.747928  998535 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9\n",
      "2025-04-14 15:42:50.211222: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1744641771.836719  998535 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-04-14 15:42:53.729602: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 76 bytes spill stores, 76 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:53.794494: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:53.877989: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_14382', 376 bytes spill stores, 376 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:53.911463: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_30', 284 bytes spill stores, 284 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:53.930442: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 56 bytes spill stores, 56 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:53.948871: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:54.003130: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 692 bytes spill stores, 692 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:54.016616: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:54.123063: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 280 bytes spill stores, 260 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:54.342418: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:54.602744: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_36', 316 bytes spill stores, 316 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:54.776866: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 192 bytes spill stores, 248 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:54.789888: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_30', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:54.850658: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_14382', 312 bytes spill stores, 316 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:55.052549: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_36', 156 bytes spill stores, 156 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:55.055381: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_30', 36 bytes spill stores, 36 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:55.072368: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_66', 796 bytes spill stores, 764 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:55.232119: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_36', 120 bytes spill stores, 120 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:55.253289: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12', 280 bytes spill stores, 260 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:55.283297: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_66', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:55.313577: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_36', 280 bytes spill stores, 284 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:55.328671: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18402', 80 bytes spill stores, 92 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:55.419509: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_36', 164 bytes spill stores, 164 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:55.429188: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_60', 640 bytes spill stores, 608 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:55.588964: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 640 bytes spill stores, 608 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:55.677414: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18402', 396 bytes spill stores, 396 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:55.689783: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_14382', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:55.747738: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 108 bytes spill stores, 108 bytes spill loads\n",
      "\n",
      "2025-04-14 15:42:55.781488: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_14382', 636 bytes spill stores, 680 bytes spill loads\n",
      "\n",
      "I0000 00:00:1744641787.970641  998535 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/150\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 548ms/step - accuracy: 0.0189 - auc: 0.5996 - f1_score: 0.0032 - loss: 5.4149 - precision: 0.0000e+00 - recall: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 15:44:32.902326: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_14382', 644 bytes spill stores, 680 bytes spill loads\n",
      "\n",
      "2025-04-14 15:44:33.199220: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_14382', 388 bytes spill stores, 320 bytes spill loads\n",
      "\n",
      "2025-04-14 15:44:33.379400: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_14382', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2025-04-14 15:44:33.511191: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18402', 44 bytes spill stores, 44 bytes spill loads\n",
      "\n",
      "2025-04-14 15:44:33.570734: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18402', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "2025-04-14 15:44:33.881320: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_14382', 568 bytes spill stores, 384 bytes spill loads\n",
      "\n",
      "2025-04-14 15:44:33.946572: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18402', 88 bytes spill stores, 88 bytes spill loads\n",
      "\n",
      "2025-04-14 15:44:34.060901: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18402', 376 bytes spill stores, 416 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m150/150\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654ms/step - accuracy: 0.0189 - auc: 0.5998 - f1_score: 0.0032 - loss: 5.4136 - precision: 0.0000e+00 - recall: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 15:44:47.477824: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2011', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2025-04-14 15:44:47.906025: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2011', 144 bytes spill stores, 144 bytes spill loads\n",
      "\n",
      "2025-04-14 15:44:47.965303: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2011', 504 bytes spill stores, 504 bytes spill loads\n",
      "\n",
      "2025-04-14 15:44:47.967061: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2011_0', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2025-04-14 15:44:51.636278: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2011', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2025-04-14 15:44:51.841917: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2011', 616 bytes spill stores, 532 bytes spill loads\n",
      "\n",
      "2025-04-14 15:44:51.989229: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2011', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2025-04-14 15:44:52.116208: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2011', 148 bytes spill stores, 148 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m150/150\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 727ms/step - accuracy: 0.0189 - auc: 0.6000 - f1_score: 0.0032 - loss: 5.4123 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0250 - val_auc: 0.6656 - val_f1_score: 2.4188e-04 - val_loss: 5.0448 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 9.5000e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m 15/150\u001b[0m \u001b[32mâ”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1:15\u001b[0m 558ms/step - accuracy: 0.0260 - auc: 0.6539 - f1_score: 0.0019 - loss: 5.0921 - precision: 0.0000e+00 - recall: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_datagen, batch_size = batch_size, epochs=10, validation_data=val_datagen, callbacks=callbacks, verbose=1)\n",
    "train_time = round(time.time() - start_time, 2)\n",
    "\n",
    "print(f\"\\nTraining completed in \\033[1m{train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\\033[0m).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204995d589f8431f",
   "metadata": {},
   "source": [
    "### <a class='anchor' id='3_1'></a> <a class='anchor' id='3_2'></a>  **ğŸ§ª Model Selection & ğŸ“ Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb023c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from utilities import plot_metrics\n",
    "\n",
    "os.makedirs(\"./ModelsEvaluation\", exist_ok=True)                                              # Create directory if it doesn't exist\n",
    "plot_metrics(history, file_path=f\"./ModelsEvaluation/2_Training_Validation_Metrics_{datetime.datetime.now().strftime('%Y%m%d')}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7d3e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation and test sets\n",
    "train_results = {'accuracy': history.history['accuracy'][-1], 'precision': history.history['precision'][-1], 'recall': history.history['recall'][-1], 'f1_score': history.history['f1_score'][-1], 'auc': history.history['auc'][-1]}\n",
    "val_results = model.evaluate(val_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "test_results = model.evaluate(test_datagen, batch_size=batch_size, return_dict=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1caf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "from utilities import display_side_by_side, create_evaluation_dataframe\n",
    "results_df = create_evaluation_dataframe(\n",
    "    model_name=\"Baseline Model\",\n",
    "    variation=\"Original | Grayscale=F | Contrast=F | Saturation=F | Adam=0.001\",           # Dataset | Grayscale | Contrast | Saturation | Optimizer=Learning Rate\n",
    "    train_metrics=train_results, val_metrics=val_results, test_metrics=test_results, train_time=train_time,\n",
    "    csv_save_path= f\"./ModelsEvaluation/2_BaselineModel_TrainingValidationMetrics_{model_name}.csv\"      # Save the results to a CSV file\n",
    ")\n",
    "display_side_by_side(results_df, super_title=\"Model Evaluation Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dff3bdf66c1f233",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a5816b",
   "metadata": {},
   "source": [
    "# **ğŸ”— Bibliography/References**\n",
    "\n",
    "**[[1]](https://)** AAAAAAAAAA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
