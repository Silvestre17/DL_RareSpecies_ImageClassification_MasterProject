{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1834cc3d7b582eb2",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center; justify-content: center; flex-wrap: wrap;\">\n",
    "    <div style=\"flex: 1; max-width: 400px; display: flex; justify-content: center;\">\n",
    "        <img src=\"https://i.ibb.co/JBPWVYR/Logo-Nova-IMS-Black.png\" style=\"max-width: 50%; height: auto; margin-top: 50px; margin-bottom: 50px;margin-left: 6rem;\">\n",
    "    </div>\n",
    "    <div style=\"flex: 2; text-align: center; margin-top: 20px;margin-left: 8rem;\">\n",
    "        <div style=\"font-size: 28px; font-weight: bold; line-height: 1.2;\">\n",
    "            <span style=\"color: #22c1c3;\">DL Project |</span> <span style=\"color: #08529C;\">Predicting Rare Species from Images using Deep Learning</span>\n",
    "        </div>\n",
    "        <div style=\"font-size: 17px; font-weight: bold; margin-top: 10px;\">\n",
    "            Spring Semester | 2024 - 2025\n",
    "        </div>\n",
    "        <div style=\"font-size: 17px; font-weight: bold;\">\n",
    "            Master in Data Science and Advanced Analytics\n",
    "        </div>\n",
    "        <div style=\"margin-top: 20px;\">\n",
    "            <div>Andr√© Silvestre, 20240502</div>\n",
    "            <div>Diogo Duarte, 20240525</div>\n",
    "            <div>Filipa Pereira, 20240509</div>\n",
    "            <div>Maria Cruz, 20230760</div>\n",
    "            <div>Umeima Mahomed, 20240543</div>\n",
    "        </div>\n",
    "        <div style=\"margin-top: 20px; font-weight: bold;\">\n",
    "            Group 37\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827c9197",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right, #22c1c3, #27b1dd, #2d9cfd, #090979); \n",
    "            padding: 1px; color: white; border-radius: 500px; text-align: center;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f603cf1cb0fd531",
   "metadata": {},
   "source": [
    "## **üìö Libraries Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c91174e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 22:17:53.800039: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743286674.160297   43886 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743286674.230800   43886 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-29 22:17:54.635123: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from typing_extensions import Self, Any      # For Python 3.10\n",
    "# from typing import Self, Any               # For Python >3.11\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Data manipulation imports\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Deep learning imports\n",
    "import tensorflow as tf\n",
    "from keras.ops import add\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import Model, Sequential, Input\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "# Image processing imports (Data Augmentation)\n",
    "from tensorflow.keras.layers import Rescaling, RandAugment\n",
    "\n",
    "# Pretrained model imports\n",
    "from tensorflow.keras.applications import ConvNeXtBase\n",
    "\n",
    "# Evaluation imports\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.metrics import CategoricalAccuracy, AUC, F1Score, Precision, Recall\n",
    "\n",
    "# Other imports\n",
    "from itertools import product\n",
    "\n",
    "# Image processing imports\n",
    "from matplotlib.image import imread\n",
    "from PIL import Image\n",
    "\n",
    "# Set the style of the visualization\n",
    "pd.set_option('future.no_silent_downcasting', True)   # use int instead of float in DataFrame\n",
    "pd.set_option(\"display.max_columns\", None)            # display all columns\n",
    "\n",
    "# Disable warnings (FutureWarning)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# For better resolution plots\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# Setting seaborn style\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d062f5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.18.0\n",
      "Is TensorFlow built with CUDA? True\n",
      "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU Device Name: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743286678.889168   43886 gpu_device.cc:2022] Created device /device:GPU:0 with 3586 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"Is TensorFlow built with CUDA?\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"GPU Device Name:\", tf.test.gpu_device_name())\n",
    "\n",
    "if tf.test.is_built_with_cuda():\n",
    "    tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24fb75d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary function to display multiple dataframes side by side\n",
    "# Source: https://python.plainenglish.io/displaying-multiple-dataframes-side-by-side-in-jupyter-lab-notebook-9a4649a4940\n",
    "from IPython.display import display_html\n",
    "from itertools import chain,cycle\n",
    "def display_side_by_side(*args, super_title, titles=cycle([''])):\n",
    "    \"\"\"\n",
    "    :param args: Variable number of DataFrame objects to be displayed side by side.\n",
    "    :param super_title: The main title to be displayed at the top of the combined view.\n",
    "    :param titles: An iterable containing titles for each DataFrame to be displayed. Defaults to an infinite cycle of empty strings.\n",
    "    \n",
    "    :return: None. The function generates and displays HTML content side by side for given DataFrames.\n",
    "    \"\"\"\n",
    "    html_str = ''\n",
    "    html_str += f'<h1 style=\"text-align: left; margin-bottom: -15px;\">{super_title}</h1><br>'\n",
    "    html_str += '<div style=\"display: flex;\">'\n",
    "    for df, title in zip(args, chain(titles, cycle(['</br>']))):\n",
    "        html_str += f'<div style=\"margin-right: 20px;\"><h3 style=\"text-align: center;color:#555555;\">{title}</h3>'\n",
    "        html_str += df.to_html().replace('table', 'table style=\"display:inline; margin-right: 20px;\"')\n",
    "        html_str += '</div>'\n",
    "    html_str += '</div>'\n",
    "    display_html(html_str, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5d91a720daf9a2",
   "metadata": {},
   "source": [
    "## **üßÆ Import Databases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87da922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run in Google Collab to download the dataset already splitted\n",
    "# # Source: https://stackoverflow.com/questions/25010369/wget-curl-large-file-from-google-drivez\n",
    "# # Download the file from Google Drive using wget\n",
    "# !wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate \\\n",
    "#   \"https://drive.usercontent.google.com/download?id=1EYwK5a0wzwg5dHSFhn38zRsi7cihEXtc&export=download\" -O- | \\\n",
    "#   sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p' > /tmp/confirm.txt\n",
    "\n",
    "# # Read the confirmation token from the temporary file\n",
    "# with open('/tmp/confirm.txt', 'r') as f:\n",
    "#     confirm_token = f.read().strip()\n",
    "\n",
    "# # Download the file using the confirmation token and cookies\n",
    "# !wget --load-cookies /tmp/cookies.txt \\\n",
    "#   \"https://drive.usercontent.google.com/download?id=1EYwK5a0wzwg5dHSFhn38zRsi7cihEXtc&export=download&confirm={confirm_token}\" \\\n",
    "#   -O /content/RareSpecies_Split.zip\n",
    "\n",
    "# # Clean up temporary files\n",
    "# !rm /tmp/cookies.txt /tmp/confirm.txt\n",
    "\n",
    "# # List files in the /content directory to verify the download\n",
    "# !ls -lh /content/\n",
    "\n",
    "# # Unzip the downloaded file\n",
    "# !unzip /content/RareSpecies_Split.zip -d /content/\n",
    "\n",
    "# # List the unzipped files to verify\n",
    "# !ls -lh /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5977e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data\n",
    "train_dir = Path(\"data/train\")\n",
    "val_dir = Path(\"data/val\")\n",
    "test_dir = Path(\"data/test\")\n",
    "\n",
    "# For Google Collab\n",
    "# train_dir = Path(\"/content/RareSpecies_Split/train\")\n",
    "# val_dir = Path(\"/content/RareSpecies_Split/val\")\n",
    "# test_dir = Path(\"/content/RareSpecies_Split/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd04ae91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8388 files belonging to 202 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743286684.745621   43886 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3586 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1797 files belonging to 202 classes.\n",
      "Found 1798 files belonging to 202 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image Generators\n",
    "n_classes = 202                                     # Number of classes (we already know this based on previous notebook)\n",
    "image_size = (224, 224)                             # Size of the images\n",
    "img_width, img_height = 224, 224               \n",
    "batch_size = 16                                     # Batch size\n",
    "input_shape = (img_width, img_height, 3)            # Input shape of the model\n",
    "value_range = (0.0, 1.0)                            # Range of pixel values\n",
    "\n",
    "# Data generators with built-in rescaling (no augmentation yet)\n",
    "\n",
    "# Training data generator\n",
    "train_datagen = image_dataset_from_directory(\n",
    "    train_dir,                                      # Path to the directory\n",
    "    labels='inferred',                              # Type of labels to generate (inferred = from the directory structure)\n",
    "    label_mode='categorical',                       # Type of labels to generate (categorical = 'float32' tensor of shape (batch_size, num_classes), representing a one-hot encoding of the class index.)\n",
    "    color_mode='rgb',                               # Color mode to read images\n",
    "    batch_size=batch_size,                          # Size of the batches of data\n",
    "    image_size=(img_width, img_height),             # Size of the images to read\n",
    "    shuffle=True,                                   # Whether to shuffle the data\n",
    "    seed=2025,                                      # Random seed for shuffling and transformations\n",
    "    interpolation='bilinear',                       # Interpolation method to resample the image\n",
    ")\n",
    "\n",
    "# Validation data generator\n",
    "val_datagen = image_dataset_from_directory(val_dir, labels='inferred', label_mode='categorical', color_mode='rgb', batch_size=batch_size,\n",
    "                                           image_size=(img_width, img_height), shuffle=True, seed=2025, interpolation='bilinear')\n",
    "\n",
    "# Test data generator\n",
    "test_datagen = image_dataset_from_directory(test_dir, labels='inferred', label_mode='categorical', color_mode='rgb', batch_size=batch_size,\n",
    "                                            image_size=(img_width, img_height), shuffle=True, seed=2025, interpolation='bilinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f158b792ebd291",
   "metadata": {},
   "source": [
    "# <a class='anchor' id='3'></a>\n",
    "<br>\n",
    "<style>\n",
    "@import url('https://fonts.cdnfonts.com/css/avenir-next-lt-pro?styles=29974');\n",
    "</style>\n",
    "\n",
    "<div style=\"background: linear-gradient(to right, #22c1c3, #27b1dd, #2d9cfd, #090979); \n",
    "            padding: 10px; color: white; border-radius: 300px; text-align: center;\">\n",
    "    <center><h1 style=\"margin-left: 140px;margin-top: 10px; margin-bottom: 4px; color: white;\n",
    "                       font-size: 32px; font-family: 'Avenir Next LT Pro', sans-serif;\">\n",
    "        <b>3 | Modeling - ConvNetXt</b></h1></center>\n",
    "</div>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<center><img src=\"\" style=\"width: 700px\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26312ae5b0368022",
   "metadata": {},
   "source": [
    "# **üí° Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3556121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Model\n",
    "class ConvNetXt(Model):\n",
    "    \"\"\"Convolutional Neural Network for image classification | ConvNetXt Pretrained Model.\"\"\"\n",
    "    def __init__(self: Self) -> None:\n",
    "        \"\"\"Initializes the model.\"\"\"\n",
    "        \n",
    "        # Call the parent class constructor\n",
    "        super().__init__()\n",
    "        \n",
    "        # Rescaling layer\n",
    "        self.rescale_layer = Rescaling(scale= 1 / 255.0, name=\"Rescale_Layer\")    # Rescales pixel values to [0, 1]\n",
    "        \n",
    "        # Augmentation layer\n",
    "        self.augmentation = RandAugment(value_range=(0, 1), name=\"RandAugment_Layer\")  # Applies random augmentations to the input images\n",
    "        \n",
    "        # Pre-trained architecture\n",
    "        self.pre_trained_architecture  = ConvNeXtBase(weights=\"imagenet\")\n",
    "        \n",
    "        # Classification head\n",
    "        self.flatten = Flatten(name=\"Flatten_Layer\")                                  # Flattens the output for the dense layer\n",
    "        # self.dropout = Dropout(0.3)                                                   # Prevents overfitting\n",
    "        self.dense = Dense(n_classes, activation='softmax', name=\"Dense_Layer\")       # Outputs probabilities for 202 classes\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        \"\"\"Defines the forward pass.\"\"\"\n",
    "        x = self.rescale_layer(inputs)                      # Rescale the input images\n",
    "        x = self.augmentation(x)                            # Apply augmentations\n",
    "        x = self.pre_trained_architecture(x)                # Pass through the pre-trained architecture\n",
    "        x = self.flatten(x)                                # Flatten the output\n",
    "        # x = self.dropout(x)                               # Apply dropout\n",
    "        x = self.dense(x)                                  # Pass through the dense layer\n",
    "        return x                                           # Return the output\n",
    "        \n",
    "        \n",
    "# Instantiate the model\n",
    "model = ConvNetXt()\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "_ = model.call(inputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391168a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "optimizer = SGD(learning_rate=0.01, name=\"Optimizer\")                  # SGD with decay for stability\n",
    "loss = CategoricalCrossentropy(name=\"Loss\")                            # Suitable for multi-class one-hot labels\n",
    "metrics = [CategoricalAccuracy(name=\"accuracy\"), \n",
    "           Precision(name=\"precision\"),\n",
    "           Recall(name=\"recall\"), \n",
    "           F1Score(average=\"macro\", name=\"f1_score\"),\n",
    "           AUC(name=\"auc\")]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb397465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"checkpoint.keras\", monitor=\"val_loss\", save_best_only=True, verbose=0),        # Save best model\n",
    "    CSVLogger(\"metrics.csv\"),                                                                       # Log training metrics\n",
    "    LearningRateScheduler(lambda epoch, lr: lr * 0.95)                                              # Exponential decay for learning rate\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62494e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_datagen, batch_size = batch_size, epochs=5, validation_data=val_datagen, callbacks=callbacks, verbose=2)\n",
    "train_time = round(time.time() - start_time, 2)\n",
    "\n",
    "print(f\"Training completed in \\033[1m{train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\\033[0m).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f48a4f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204995d589f8431f",
   "metadata": {},
   "source": [
    "### <a class='anchor' id='3_1'></a> <a class='anchor' id='3_2'></a>  **üß™ Model Selection & üìè Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ffc2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot training and validation metrics\n",
    "def plot_metrics(history):\n",
    "    \"\"\"Plots training and validation loss, accuracy, and F1 score.\"\"\"\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(18, 4))\n",
    "    metrics = [('loss', 'Loss'), ('accuracy', 'Accuracy'), ('f1_score', 'F1 Score')]\n",
    "    for i, (metric, title) in enumerate(metrics):\n",
    "        ax[i].plot(history.history[metric], label='Train', color='#22c1c3')\n",
    "        ax[i].plot(history.history[f'val_{metric}'], label='Validation', color='#090979')\n",
    "        ax[i].set_title(title, fontsize=14, fontweight='bold')\n",
    "        ax[i].set_xlabel('Epoch', fontsize=12)\n",
    "        ax[i].set_ylabel(title, fontsize=12)\n",
    "        ax[i].legend()\n",
    "        sns.despine(top=True, right=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nTraining Metrics Plot:\")\n",
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31336690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "train_results = model.evaluate(train_datagen, batch_size=batch_size, return_dict=True, verbose=2)\n",
    "val_results = model.evaluate(val_datagen, batch_size=batch_size, return_dict=True, verbose=2)\n",
    "test_results = model.evaluate(test_datagen, batch_size=batch_size, return_dict=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632582b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect results in DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    \"Models\": [\"Baseline Model\"],\n",
    "    \"Time of Execution\": [train_time],\n",
    "    \"Training Set Accuracy\": [train_results['accuracy']],\n",
    "    \"Training Set Precision\": [train_results['precision']],\n",
    "    \"Training Set Recall\": [train_results['recall']],\n",
    "    \"Training Set F1 Score\": [train_results['f1_score']],\n",
    "    \"Training Set AUROC\": [train_results['auc']],\n",
    "    \"Validation Set Accuracy\": [val_results['accuracy']],\n",
    "    \"Validation Set Precision\": [val_results['precision']],\n",
    "    \"Validation Set Recall\": [val_results['recall']],\n",
    "    \"Validation Set F1 Score\": [val_results['f1_score']],\n",
    "    \"Validation Set AUROC\": [val_results['auc']],\n",
    "    \"Test Set Accuracy\": [test_results['accuracy']],\n",
    "    \"Test Set Precision\": [test_results['precision']],\n",
    "    \"Test Set Recall\": [test_results['recall']],\n",
    "    \"Test Set F1 Score\": [test_results['f1_score']],\n",
    "    \"Test Set AUROC\": [test_results['auc']]\n",
    "})\n",
    "\n",
    "train_df = results_df[['Models', 'Time of Execution', 'Training Set Accuracy', \n",
    "                       'Training Set Precision', 'Training Set Recall', 'Training Set F1 Score', 'Training Set AUROC']]\n",
    "val_df = results_df[['Models', 'Validation Set Accuracy', 'Validation Set Precision', 'Validation Set Recall', \n",
    "                     'Validation Set F1 Score', 'Validation Set AUROC']]\n",
    "test_df = results_df[['Models', 'Test Set Accuracy', 'Test Set Precision', 'Test Set Recall', \n",
    "                      'Test Set F1 Score', 'Test Set AUROC']]\n",
    "\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "display_side_by_side([train_df, val_df, test_df], \n",
    "                     titles = [\"Training Set\", \"Validation Set\", \"Test Set\"], \n",
    "                     super_title = \"Classification Models | Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb50d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "results_df.to_csv(\"ModelsEvaluation/BaselineModelEvaluation_1_29.03.2025.csv\", index=False)                         ### Change the name of the file to save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d9d90f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e2e827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b849b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84b90a90",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e61c8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95a3689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dff3bdf66c1f233",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a5816b",
   "metadata": {},
   "source": [
    "# **üîó Bibliography/References**\n",
    "\n",
    "**[[1]](https://)** AAAAAAAAAA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf218",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
