{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1834cc3d7b582eb2",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center; justify-content: center; flex-wrap: wrap;\">\n",
    "    <div style=\"flex: 1; max-width: 400px; display: flex; justify-content: center;\">\n",
    "        <img src=\"https://i.ibb.co/JBPWVYR/Logo-Nova-IMS-Black.png\" style=\"max-width: 50%; height: auto; margin-top: 50px; margin-bottom: 50px;margin-left: 6rem;\">\n",
    "    </div>\n",
    "    <div style=\"flex: 2; text-align: center; margin-top: 20px;margin-left: 8rem;\">\n",
    "        <div style=\"font-size: 28px; font-weight: bold; line-height: 1.2;\">\n",
    "            <span style=\"color: #22c1c3;\">DL Project |</span> <span style=\"color: #08529C;\">Predicting Rare Species from Images using Deep Learning</span>\n",
    "        </div>\n",
    "        <div style=\"font-size: 17px; font-weight: bold; margin-top: 10px;\">\n",
    "            Spring Semester | 2024 - 2025\n",
    "        </div>\n",
    "        <div style=\"font-size: 17px; font-weight: bold;\">\n",
    "            Master in Data Science and Advanced Analytics\n",
    "        </div>\n",
    "        <div style=\"margin-top: 20px;\">\n",
    "            <div>Andr√© Silvestre, 20240502</div>\n",
    "            <div>Diogo Duarte, 20240525</div>\n",
    "            <div>Filipa Pereira, 20240509</div>\n",
    "            <div>Maria Cruz, 20230760</div>\n",
    "            <div>Umeima Mahomed, 20240543</div>\n",
    "        </div>\n",
    "        <div style=\"margin-top: 20px; font-weight: bold;\">\n",
    "            Group 37\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827c9197",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right, #22c1c3, #27b1dd, #2d9cfd, #090979); \n",
    "            padding: 1px; color: white; border-radius: 500px; text-align: center;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaa725c",
   "metadata": {},
   "source": [
    "## **üìö Libraries Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bab2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from typing_extensions import Self, Any      # For Python 3.10\n",
    "# from typing import Self, Any               # For Python >3.11\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Data manipulation imports\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Deep learning imports\n",
    "import tensorflow as tf\n",
    "from keras.ops import add\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras import Model, Sequential, Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Rescaling, Lambda, BatchNormalization, Activation, GlobalAveragePooling2D\n",
    "# import visualkeras\n",
    "\n",
    "# Evaluation imports\n",
    "from keras.metrics import CategoricalAccuracy, AUC, F1Score, Precision, Recall\n",
    "\n",
    "# Other imports\n",
    "from itertools import product\n",
    "\n",
    "# Set the style of the visualization\n",
    "pd.set_option('future.no_silent_downcasting', True)   # use int instead of float in DataFrame\n",
    "pd.set_option(\"display.max_columns\", None)            # display all columns\n",
    "\n",
    "# Disable warnings (FutureWarning)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(2025)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "# Source: https://keras.io/getting_started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\n",
    "tf.keras.utils.set_random_seed(2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9078c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a SSL context that does not verify the server‚Äôs certificate - Needed for downloading pretrained models\n",
    "# Source: https://precli.readthedocs.io/0.3.4/rules/python/stdlib/ssl_create_unverified_context.html\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abda1a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"Is TensorFlow built with CUDA?\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"GPU Device Name:\", tf.test.gpu_device_name())                                # (if error in Google Colab: Make sure your Hardware accelerator is set to GPU. \n",
    "                                                                                    # Runtime > Change runtime type > Hardware Accelerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41f247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get build information from TensorFlow\n",
    "build_info = tf.sysconfig.get_build_info()\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"CUDA version:\", build_info.get(\"cuda_version\", \"Not available\"))\n",
    "print(\"cuDNN version:\", build_info.get(\"cudnn_version\", \"Not available\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0060ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom module for importing data, visualization, and utilities\n",
    "import utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17af3004",
   "metadata": {},
   "source": [
    "## **üßÆ Import Databases**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c63feeb",
   "metadata": {},
   "source": [
    "#### **üü® Google Collab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4200dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run in Google Collab to download the dataset already splitted\n",
    "# # Source: https://stackoverflow.com/questions/25010369/wget-curl-large-file-from-google-drivez\n",
    "# # Download the file from Google Drive using wget\n",
    "# !wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate \\\n",
    "#   \"https://drive.usercontent.google.com/download?id=1dmr2cGxgM-kp1aXlmd9cQzVCkcl4JTFo&export=download\" -O- | \\\n",
    "#   sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p' > /tmp/confirm.txt\n",
    "\n",
    "# # Read the confirmation token from the temporary file\n",
    "# with open('/tmp/confirm.txt', 'r') as f:\n",
    "#     confirm_token = f.read().strip()\n",
    "\n",
    "# # Download the file using the confirmation token and cookies\n",
    "# !wget --load-cookies /tmp/cookies.txt \\\n",
    "#   \"https://drive.usercontent.google.com/download?id=1dmr2cGxgM-kp1aXlmd9cQzVCkcl4JTFo&export=download&confirm={confirm_token}\" \\\n",
    "#   -O /content/RareSpecies_Split.zip\n",
    "\n",
    "# # Clean up temporary files\n",
    "# !rm /tmp/cookies.txt /tmp/confirm.txt\n",
    "\n",
    "# # List files in the /content directory to verify the download\n",
    "# !ls -lh /content/\n",
    "\n",
    "# # Unzip the downloaded file\n",
    "# !unzip /content/RareSpecies_Split.zip -d /content/\n",
    "\n",
    "# # List the unzipped files to verify\n",
    "# !ls -lh /content/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80664c89",
   "metadata": {},
   "source": [
    "### **üñåÔ∏è SMOTE (Data Augmentation)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c231f3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Generators \n",
    "n_classes = 202                                     # Number of classes (we already know this based on previous notebook)\n",
    "image_size = (224, 224)                             # Image size (224x224)\n",
    "img_height, img_width = image_size                  # Image dimensions\n",
    "batch_size = 64                                     # Batch size (keep consistent with previous training)\n",
    "input_shape = (img_height, img_width, 3)            # Input shape of the model\n",
    "value_range = (0.0, 1.0)                            # Range of pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcf2da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SMOTE training data\n",
    "train_DataAugmentationSMOTE_dir = Path(\"data/RareSpecies_Split/train_DataAugmentationSMOTE\")\n",
    "val_dir = Path(\"data/RareSpecies_Split/val\")\n",
    "test_dir = Path(\"data/RareSpecies_Split/test\")\n",
    "\n",
    "# train_DataAugmentationSMOTE_dir = Path(\"/content/RareSpecies_Split/train_DataAugmentationSMOTE\")\n",
    "# val_dir = Path(\"/content/RareSpecies_Split/val\")\n",
    "# test_dir = Path(\"/content/RareSpecies_Split/test\")\n",
    "\n",
    "# Get class names from directory\n",
    "class_names = sorted(os.listdir(train_DataAugmentationSMOTE_dir))\n",
    "class_indices = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "# Import the image dataset from the directory\n",
    "from utilities import load_images_from_directory\n",
    "train_DataAugmentationSMOTE_datagen, val_datagen, test_datagen = load_images_from_directory(train_DataAugmentationSMOTE_dir, val_dir, test_dir,\n",
    "                                                                      labels='inferred', label_mode='categorical',\n",
    "                                                                      class_names=class_names, color_mode='rgb',\n",
    "                                                                      batch_size=batch_size, image_size=image_size, seed=2025, \n",
    "                                                                      interpolation='bilinear', crop_to_aspect_ratio=False, pad_to_aspect_ratio=False)\n",
    "# Check the shape of the data (batch_size, img_width, img_height, 3)\n",
    "for x, y in train_DataAugmentationSMOTE_datagen.take(1):\n",
    "    print(\"Train batch shape:\", x.shape, y.shape)\n",
    "for x, y in val_datagen.take(1):\n",
    "    print(\"Val batch shape:\", x.shape, y.shape)\n",
    "for x, y in test_datagen.take(1):\n",
    "    print(\"Test batch shape:\", x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f158b792ebd291",
   "metadata": {},
   "source": [
    "# <a class='anchor' id='3'></a>\n",
    "<br>\n",
    "<style>\n",
    "@import url('https://fonts.cdnfonts.com/css/avenir-next-lt-pro?styles=29974');\n",
    "</style>\n",
    "\n",
    "<div style=\"background: linear-gradient(to right, #22c1c3, #27b1dd, #2d9cfd, #090979); \n",
    "            padding: 10px; color: white; border-radius: 300px; text-align: center;\">\n",
    "    <center><h1 style=\"margin-left: 140px;margin-top: 10px; margin-bottom: 4px; color: white;\n",
    "                       font-size: 32px; font-family: 'Avenir Next LT Pro', sans-serif;\">\n",
    "        <b>Tuning Best Model</b></h1></center>\n",
    "</div>\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883adb6e",
   "metadata": {},
   "source": [
    "## **üí° Best Model Building Function for Keras Tuner** (ConvNeXtBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73447e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tune best combination model\n",
    "# Source: https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/\n",
    "#         https://keras.io/guides/transfer_learning/\n",
    "#         https://keras.io/keras_tuner/getting_started/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838fa0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Keras Tuner ---\n",
    "# Source: https://keras.io/keras_tuner/\n",
    "# Make sure it's installed: \n",
    "\n",
    "# !pip install keras-tuner -q\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3556121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ConvNeXtBase               # Specific model\n",
    "from tensorflow.keras.applications.convnext import preprocess_input  # Specific preprocessing\n",
    "\n",
    "def build_model(hp):\n",
    "    \"\"\"\n",
    "    Builds a ConvNeXtBase model with hyperparameters for tuning.\n",
    "\n",
    "    Args:\n",
    "        hp (keras_tuner.HyperParameters): Hyperparameters object from Keras Tuner.\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: Compiled Keras model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Hyperparameters\n",
    "    # Source: https://keras.io/keras_tuner/api/hyperparameters/\n",
    "    hp_unfreeze = hp.Boolean(\"unfreeze_base\", default=False)\n",
    "    # Note: If unfreezing, use a lower learning rate -> We choose LR < 1e-3 (used in all previous models)\n",
    "    # Source: https://keras.io/guides/transfer_learning/#do-a-round-of-finetuning-of-the-entire-model\n",
    "    hp_learning_rate = hp.Choice(\"learning_rate\", values=[1e-3, 1e-4, 1e-5])\n",
    "    hp_optimizer_choice = hp.Choice(\"optimizer\", values=['adam', 'sgd', 'rmsprop'])\n",
    "    hp_dropout_rate = hp.Float(\"dropout_rate\", min_value=0.3, max_value=0.7, step=0.1)\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------------------------------\n",
    "    # Base Model (ConvNeXtBase)\n",
    "    # Source: https://keras.io/api/applications/convnext/#convnextbase-function\n",
    "    base_model = ConvNeXtBase(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "\n",
    "    # Set Trainability\n",
    "    # Freeze the base model initially\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Unfreeze layers if the hyperparameter is set\n",
    "    # Source: https://keras.io/guides/transfer_learning/\n",
    "    if hp_unfreeze:\n",
    "        print(\"NOTE: Unfreezing the base ConvNeXtBase model for this trial.\")\n",
    "        base_model.trainable = True\n",
    "        # Optional: Fine-tune only the top layers instead of all\n",
    "        # fine_tune_at = 100 # Example: Unfreeze layers from this index onwards\n",
    "        # for layer in base_model.layers[:fine_tune_at]:\n",
    "        #     layer.trainable = False\n",
    "\n",
    "    # Model Construction\n",
    "    inputs = Input(shape=input_shape, name=\"Input_Layer\")\n",
    "\n",
    "    # Apply the specific preprocessing for ConvNeXtBase\n",
    "    # Source: https://keras.io/api/applications/convnext/#preprocessinput-function\n",
    "    x = Lambda(lambda img: preprocess_input(img), name='ConvNeXtBase_Preprocess')(inputs)\n",
    "\n",
    "    # Pass through the base model\n",
    "    x = base_model(x, training=base_model.trainable) # training=False if frozen, True if unfrozen\n",
    "\n",
    "    # Classification Head (Same as class RareSpeciesCNN_ConvNeXtBase - 7nd notebook)\n",
    "    x = GlobalAveragePooling2D(name=\"Global_Average_Pooling\")(x)\n",
    "    x = Dense(128, name=\"Dense_Layer1\")(x)\n",
    "    # Use the hyperparameter for dropout rate\n",
    "    x = Dropout(hp_dropout_rate, name=\"Dropout_Layer\")(x)\n",
    "    outputs = Dense(n_classes, activation='softmax', name=\"Output_Layer\")(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    # Optimizer Selection\n",
    "    # Source: https://keras.io/api/optimizers/\n",
    "    if hp_optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=hp_learning_rate)               # Removed weight decay for simplicity in tuning\n",
    "    elif hp_optimizer_choice == 'sgd':\n",
    "        optimizer = SGD(learning_rate=hp_learning_rate, momentum=0.9) # Added momentum, common for SGD\n",
    "    elif hp_optimizer_choice == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=hp_learning_rate)\n",
    "\n",
    "    # --- Compile Model ---\n",
    "    # Source: https://keras.io/api/models/model_training_apis/\n",
    "    loss = CategoricalCrossentropy(name=\"Loss\")\n",
    "    metrics = [\n",
    "        CategoricalAccuracy(name=\"accuracy\"),\n",
    "        F1Score(average=\"macro\", name=\"f1_score\"), # Using F1 Macro as the primary metric\n",
    "        Precision(name=\"precision\"),\n",
    "        Recall(name=\"recall\"),\n",
    "        AUC(name=\"auc\")\n",
    "    ]\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391168a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the build function\n",
    "hp = kt.HyperParameters()\n",
    "test_model = build_model(hp)\n",
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d9d90f",
   "metadata": {},
   "source": [
    "### **‚öôÔ∏è Keras Tuner Setup (`Hyperband`)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e2e827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://keras.io/keras_tuner/tuners/hyperband/\n",
    "tuner = kt.Hyperband(\n",
    "    hypermodel=build_model,\n",
    "    objective=kt.Objective(\"val_f1_score\", direction=\"max\"), # Primary objective: maximize validation F1 macro score\n",
    "    max_epochs=15,                                           # Max epochs *per trial execution* within Hyperband brackets\n",
    "    factor=3,                                                # Reduction factor for epochs and number of models per bracket\n",
    "    hyperband_iterations=1,                                  # Number of times to iterate over the full Hyperband algorithm\n",
    "    seed=2025,                                               # Seed for reproducibility within the tuner\n",
    "    directory=\"keras_tuner_dir\",\n",
    "    project_name=f\"ConvNeXtBase_FineTune_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}\",\n",
    "    overwrite=True                                           # Set to False to resume previous tuning runs\n",
    ")\n",
    "\n",
    "# Print a summary of the search space\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b849b2d",
   "metadata": {},
   "source": [
    "### **üöÄ Run the Hyperparameter Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e61c8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks for the search phase (applied to each trial)\n",
    "# Early stopping is crucial here to stop non-promising trials quickly\n",
    "search_callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss', # Monitor validation loss for stopping trials\n",
    "        patience=5,         # Stop after 5 epochs of no improvement in val_loss\n",
    "        verbose=1,\n",
    "        restore_best_weights=True # Restore weights from the epoch with the best val_loss\n",
    "    )\n",
    "    # Note: ReduceLROnPlateau is usually NOT used during the search itself,\n",
    "    #       as the tuner is already exploring different learning rates.\n",
    "    # We will use it when retraining the final best model.\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95a3689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the search\n",
    "# Use a moderate number of epochs for the overall search.\n",
    "# `max_epochs` in the tuner definition controls the limit *within* Hyperband.\n",
    "search_start_time = time.time()\n",
    "tuner.search(\n",
    "    train_DataAugmentationSMOTE_datagen,\n",
    "    epochs=30,                              # Overall epochs budget for the search process\n",
    "    validation_data=val_datagen,\n",
    "    callbacks=search_callbacks,\n",
    "    verbose=1                               # Set to 2 for more detailed logs per epoch, 1 for progress bar per epoch\n",
    ")\n",
    "search_time = round(time.time() - search_start_time, 2)\n",
    "print(f\"\\n\\033[1mHyperparameter Search Completed in\\033[0m {search_time} seconds ({str(datetime.timedelta(seconds=search_time))} h)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2262afb",
   "metadata": {},
   "source": [
    "#### **üìä Get and Display Best Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9c1d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the optimal hyperparameters\n",
    "# Source: https://keras.io/keras_tuner/api/tuners/base_tuner/\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "- \\033[1mOptimal Learning Rate:\\033[0m {best_hps.get('learning_rate')}\n",
    "- \\033[1mOptimal Optimizer:\\033[0m {best_hps.get('optimizer')}\n",
    "- \\033[1mOptimal Dropout Rate:\\033[0m {best_hps.get('dropout_rate')}\n",
    "- \\033[1mUnfreeze Base Model:\\033[0m {best_hps.get('unfreeze_base')}\n",
    "\"\"\")\n",
    "\n",
    "# Show summary of top results\n",
    "tuner.results_summary(num_trials=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bbba42",
   "metadata": {},
   "source": [
    "### **üöÇ Retrain the Best Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf34d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for saving model checkpoints and evaluation logs\n",
    "os.makedirs(\"./ModelCallbacks/8_ConvNeXtBaseFinetuned\", exist_ok=True)      # exist_ok=True | Create directory if it doesn't exist\n",
    "os.makedirs(\"./ModelsEvaluation/8_ConvNeXtBaseFinetuned\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with the optimal hyperparameters\n",
    "final_model = build_model(best_hps)\n",
    "final_model.summary()\n",
    "\n",
    "# Define callbacks for the final training phase\n",
    "model_name = f\"ConvNeXtBase_BestFineTuned_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "final_callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        f\"./ModelCallbacks/8_ConvNeXtBaseFinetuned/BestModel_checkpoint_{model_name}.keras\",\n",
    "        monitor=\"val_f1_score\", # Save based on best validation F1 score\n",
    "        mode=\"max\",             # Maximize F1 score\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    CSVLogger(f\"./ModelCallbacks/8_ConvNeXtBaseFinetuned/BestModel_metrics_{model_name}.csv\"),\n",
    "    ReduceLROnPlateau(          # Now we use ReduceLROnPlateau\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=5,\n",
    "        verbose=1,\n",
    "        min_lr=1e-7             # Set a lower minimum learning rate\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,              # Allow more patience for final training\n",
    "        verbose=1,\n",
    "        restore_best_weights=True # Restore best weights based on val_loss\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train the final model\n",
    "# Use a larger number of epochs for final training, relying on EarlyStopping\n",
    "print(f\"\\nStarting Final Training for {model_name}\")\n",
    "start_time = time.time()\n",
    "history = final_model.fit(\n",
    "    train_DataAugmentationSMOTE_datagen,\n",
    "    epochs=100,                                 # Set a high epoch number, EarlyStopping will handle it\n",
    "    validation_data=val_datagen,\n",
    "    callbacks=final_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "train_time = round(time.time() - start_time, 2)\n",
    "print(f\"\\nFinal Training completed in {train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae4f1b5",
   "metadata": {},
   "source": [
    "#### **üß™ Final Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6305229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from utilities import plot_metrics\n",
    "plot_metrics(history, file_path=f\"./ModelsEvaluation/8_ConvNeXtBaseFinetuned/8_BestModel_TrainingValidationMetrics_{model_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4049d7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation and test sets\n",
    "train_results = {'accuracy': history.history['accuracy'][-1], 'precision': history.history['precision'][-1], 'recall': history.history['recall'][-1], 'f1_score': history.history['f1_score'][-1], 'auc': history.history['auc'][-1]}\n",
    "val_results = final_model.evaluate(val_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "test_results = final_model.evaluate(test_datagen, batch_size=batch_size, return_dict=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c4d889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "from utilities import display_side_by_side, create_evaluation_dataframe\n",
    "results_df = create_evaluation_dataframe(\n",
    "    model_name=\"ConvNeXtBase_FineTuned\",\n",
    "    variation=f\"LR={best_hps.get('learning_rate')}, Optim={best_hps.get('optimizer')}, Dropout={best_hps.get('dropout_rate'):.2f}, Unfreeze={best_hps.get('unfreeze_base')}\",\n",
    "    train_metrics=train_results,\n",
    "    val_metrics=val_results,\n",
    "    test_metrics=test_results,\n",
    "    train_time=train_time, # This is the final retraining time\n",
    "    csv_save_path=f\"./ModelsEvaluation/8_ConvNeXtBaseFinetuned/8_BestModel_EvaluationResults_{model_name}.csv\"\n",
    ")\n",
    "display_side_by_side(results_df, super_title=\"Final Fine-Tuned Model Evaluation Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot n right and n wrong predictions\n",
    "from utilities import plot_predictions\n",
    "plot_predictions(\n",
    "    model=final_model,\n",
    "    class_names=class_names,\n",
    "    train_dir=train_DataAugmentationSMOTE_dir,\n",
    "    test_data=test_datagen,\n",
    "    num_images=10,\n",
    "    file_path=f\"./ModelsEvaluation/8_ConvNeXtBaseFinetuned/8_TestPredictions_{model_name}.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dff3bdf66c1f233",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a5816b",
   "metadata": {},
   "source": [
    "# **üîó Bibliography/References**\n",
    "\n",
    "**[[1]](https://keras.io/keras_tuner/api/)** Team, K. (2025). Keras documentation: KerasTuner API documentation. Keras.io. https://keras.io/keras_tuner/api/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf218",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
