{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1834cc3d7b582eb2",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center; justify-content: center; flex-wrap: wrap;\">\n",
    "    <div style=\"flex: 1; max-width: 400px; display: flex; justify-content: center;\">\n",
    "        <img src=\"https://i.ibb.co/JBPWVYR/Logo-Nova-IMS-Black.png\" style=\"max-width: 50%; height: auto; margin-top: 50px; margin-bottom: 50px;margin-left: 6rem;\">\n",
    "    </div>\n",
    "    <div style=\"flex: 2; text-align: center; margin-top: 20px;margin-left: 8rem;\">\n",
    "        <div style=\"font-size: 28px; font-weight: bold; line-height: 1.2;\">\n",
    "            <span style=\"color: #22c1c3;\">DL Project |</span> <span style=\"color: #08529C;\">Predicting Rare Species from Images using Deep Learning</span>\n",
    "        </div>\n",
    "        <div style=\"font-size: 17px; font-weight: bold; margin-top: 10px;\">\n",
    "            Spring Semester | 2024 - 2025\n",
    "        </div>\n",
    "        <div style=\"font-size: 17px; font-weight: bold;\">\n",
    "            Master in Data Science and Advanced Analytics\n",
    "        </div>\n",
    "        <div style=\"margin-top: 20px;\">\n",
    "            <div>André Silvestre, 20240502</div>\n",
    "            <div>Diogo Duarte, 20240525</div>\n",
    "            <div>Filipa Pereira, 20240509</div>\n",
    "            <div>Maria Cruz, 20230760</div>\n",
    "            <div>Umeima Mahomed, 20240543</div>\n",
    "        </div>\n",
    "        <div style=\"margin-top: 20px; font-weight: bold;\">\n",
    "            Group 37\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827c9197",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right, #22c1c3, #27b1dd, #2d9cfd, #090979); \n",
    "            padding: 1px; color: white; border-radius: 500px; text-align: center;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f603cf1cb0fd531",
   "metadata": {},
   "source": [
    "## **📚 Libraries Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9e5710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install visualkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c91174e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 16:08:30.614101: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744556910.812029   16460 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744556910.872394   16460 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744556911.286298   16460 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744556911.286337   16460 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744556911.286339   16460 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744556911.286342   16460 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-13 16:08:31.328180: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from typing_extensions import Self, Any      # For Python 3.10\n",
    "# from typing import Self, Any               # For Python >3.11\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Data manipulation imports\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Deep learning imports\n",
    "import tensorflow as tf\n",
    "from keras.ops import add\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import Model, Sequential, Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Rescaling, Lambda, BatchNormalization, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras import regularizers                                                                           # For L2 regularization\n",
    "import visualkeras\n",
    "\n",
    "# Evaluation imports\n",
    "from keras.metrics import CategoricalAccuracy, AUC, F1Score, Precision, Recall\n",
    "\n",
    "# Other imports\n",
    "from itertools import product\n",
    "\n",
    "# Set the style of the visualization\n",
    "pd.set_option('future.no_silent_downcasting', True)   # use int instead of float in DataFrame\n",
    "pd.set_option(\"display.max_columns\", None)            # display all columns\n",
    "\n",
    "# Disable warnings (FutureWarning)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f0d56ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.19.0\n",
      "Is TensorFlow built with CUDA? True\n",
      "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU Device Name: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744556918.559210   16460 gpu_device.cc:2019] Created device /device:GPU:0 with 3586 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"Is TensorFlow built with CUDA?\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"GPU Device Name:\", tf.test.gpu_device_name())                                # (if error in Google Colab: Make sure your Hardware accelerator is set to GPU. \n",
    "                                                                                    # Runtime > Change runtime type > Hardware Accelerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd59b789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n",
      "Python version: 3.10.12 (main, Feb  4 2025, 14:57:36) [GCC 11.4.0]\n",
      "CUDA version: 12.5.1\n",
      "cuDNN version: 9\n"
     ]
    }
   ],
   "source": [
    "# Get build information from TensorFlow\n",
    "build_info = tf.sysconfig.get_build_info()\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"CUDA version:\", build_info.get(\"cuda_version\", \"Not available\"))\n",
    "print(\"cuDNN version:\", build_info.get(\"cudnn_version\", \"Not available\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0d96104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra: https://www.tensorflow.org/api_docs/python/tf/config/experimental/set_memory_growth\n",
    "# If you’re using a GPU, TensorFlow might pre-allocate GPU memory, leaving less for CPU operations. \n",
    "# Enabling memory growth lets the GPU allocate only what’s needed.\n",
    "if tf.test.is_built_with_cuda():\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "            # tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            tf.config.experimental.set_memory_growth(gpu, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1e0633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom module for importing data, visualization, and utilities\n",
    "import utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb366e4",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right, #22c1c3, #27b1dd, #2d9cfd, #090979); \n",
    "            padding: 1px; color: white; border-radius: 500px; text-align: center;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5d91a720daf9a2",
   "metadata": {},
   "source": [
    "## **🧮 Import Databases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a69d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run in Google Collab to download the dataset already splitted\n",
    "# # Source: https://stackoverflow.com/questions/25010369/wget-curl-large-file-from-google-drivez\n",
    "# # Download the file from Google Drive using wget\n",
    "# !wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate \\\n",
    "#   \"https://drive.usercontent.google.com/download?id=1dmr2cGxgM-kp1aXlmd9cQzVCkcl4JTFo&export=download\" -O- | \\\n",
    "#   sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p' > /tmp/confirm.txt\n",
    "\n",
    "# # Read the confirmation token from the temporary file\n",
    "# with open('/tmp/confirm.txt', 'r') as f:\n",
    "#     confirm_token = f.read().strip()\n",
    "\n",
    "# # Download the file using the confirmation token and cookies\n",
    "# !wget --load-cookies /tmp/cookies.txt \\\n",
    "#   \"https://drive.usercontent.google.com/download?id=1dmr2cGxgM-kp1aXlmd9cQzVCkcl4JTFo&export=download&confirm={confirm_token}\" \\\n",
    "#   -O /content/RareSpecies_Split.zip\n",
    "\n",
    "# # Clean up temporary files\n",
    "# !rm /tmp/cookies.txt /tmp/confirm.txt\n",
    "\n",
    "# # List files in the /content directory to verify the download\n",
    "# !ls -lh /content/\n",
    "\n",
    "# # Unzip the downloaded file\n",
    "# !unzip /content/RareSpecies_Split.zip -d /content/\n",
    "\n",
    "# # List the unzipped files to verify\n",
    "# !ls -lh /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b87da922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data\n",
    "train_dir = Path(\"data/RareSpecies_Split/train\")\n",
    "val_dir = Path(\"data/RareSpecies_Split/val\")\n",
    "test_dir = Path(\"data/RareSpecies_Split/test\")\n",
    "\n",
    "# For Google Collab\n",
    "# train_dir = Path(\"/content/RareSpecies_Split/train\")\n",
    "# val_dir = Path(\"/content/RareSpecies_Split/val\")\n",
    "# test_dir = Path(\"/content/RareSpecies_Split/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5977e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Generators \n",
    "n_classes = 202                                     # Number of classes (we already know this based on previous notebook)\n",
    "image_size = (224, 224)                             # Image size (224x224)\n",
    "img_height, img_width = image_size                  # Image dimensions\n",
    "batch_size = 64                                     # Batch size\n",
    "input_shape = (img_height, img_width, 3)            # Input shape of the model\n",
    "value_range = (0.0, 1.0)                            # Range of pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6686885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9586 files belonging to 202 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744556920.210259   16460 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3586 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1198 files belonging to 202 classes.\n",
      "Found 1199 files belonging to 202 classes.\n",
      "\n",
      "Loaded: Train (9600), Val (1216), Test (1216)\n"
     ]
    }
   ],
   "source": [
    "# Get class names from directory\n",
    "class_names = sorted(os.listdir(train_dir))\n",
    "class_indices = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "# Import the image dataset from the directory\n",
    "from utilities import load_images_from_directory\n",
    "train_datagen, val_datagen, test_datagen = load_images_from_directory(train_dir, val_dir, test_dir,\n",
    "                                                                      labels='inferred', label_mode='categorical',\n",
    "                                                                      class_names=class_names, color_mode='rgb',\n",
    "                                                                      batch_size=batch_size, image_size=image_size, seed=2025, \n",
    "                                                                      interpolation='bilinear', crop_to_aspect_ratio=False, pad_to_aspect_ratio=False)\n",
    "\n",
    "print(f\"\\nLoaded: Train ({train_datagen.cardinality().numpy() * batch_size}), \"\n",
    "        f\"Val ({val_datagen.cardinality().numpy() * batch_size}), \"\n",
    "        f\"Test ({test_datagen.cardinality().numpy() * batch_size})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83cbf32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch shape: (64, 224, 224, 3) (64, 202)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 16:08:44.055793: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val batch shape: (64, 224, 224, 3) (64, 202)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 16:08:44.547556: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test batch shape: (64, 224, 224, 3) (64, 202)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 16:08:45.038699: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 67160576 bytes after encountering the first element of size 67160576 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the data (batch_size, img_width, img_height, 3)\n",
    "for x, y in train_datagen.take(1):\n",
    "    print(\"Train batch shape:\", x.shape, y.shape)\n",
    "for x, y in val_datagen.take(1):\n",
    "    print(\"Val batch shape:\", x.shape, y.shape)\n",
    "for x, y in test_datagen.take(1):\n",
    "    print(\"Test batch shape:\", x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f158b792ebd291",
   "metadata": {},
   "source": [
    "# <a class='anchor' id='3'></a>\n",
    "<br>\n",
    "<style>\n",
    "@import url('https://fonts.cdnfonts.com/css/avenir-next-lt-pro?styles=29974');\n",
    "</style>\n",
    "\n",
    "<div style=\"background: linear-gradient(to right, #22c1c3, #27b1dd, #2d9cfd, #090979); \n",
    "            padding: 10px; color: white; border-radius: 300px; text-align: center;\">\n",
    "    <center><h1 style=\"margin-left: 140px;margin-top: 10px; margin-bottom: 4px; color: white;\n",
    "                       font-size: 32px; font-family: 'Avenir Next LT Pro', sans-serif;\">\n",
    "        <b>3 | Modeling - Baseline Model</b></h1></center>\n",
    "</div>\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26312ae5b0368022",
   "metadata": {},
   "source": [
    "# **💡 Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3556121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"rare_species_cnn\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"rare_species_cnn\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Rescale_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv_Block1_Conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv_Block1_BN                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv_Block1_Act (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv_Block1_Pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv_Block2_Conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv_Block2_BN                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv_Block2_Act (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv_Block2_Pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv_Block3_Conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv_Block3_BN                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv_Block3_Act (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv_Block3_Pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Global_Average_Pooling          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_Layer1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_Layer1_BN                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_Layer1_Act (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">26,058</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Rescale_Layer (\u001b[38;5;33mRescaling\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv_Block1_Conv (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv_Block1_BN                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv_Block1_Act (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv_Block1_Pool (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv_Block2_Conv (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv_Block2_BN                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv_Block2_Act (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv_Block2_Pool (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv_Block3_Conv (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv_Block3_BN                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv_Block3_Act (\u001b[38;5;33mActivation\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv_Block3_Pool (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Global_Average_Pooling          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten_Layer (\u001b[38;5;33mFlatten\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_Layer1 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_Layer1_BN                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_Layer1_Act (\u001b[38;5;33mActivation\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_Layer (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m202\u001b[0m)            │        \u001b[38;5;34m26,058\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">137,226</span> (536.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m137,226\u001b[0m (536.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">136,522</span> (533.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m136,522\u001b[0m (533.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> (2.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m704\u001b[0m (2.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Baseline Model\n",
    "class RareSpeciesCNN(Model):\n",
    "    \"\"\"Custom CNN for rare species classification.\n",
    "    \n",
    "    Architecture: Simple CNN \n",
    "    Why: Small model to establish baseline, avoiding overfitting on 202 classes.\n",
    "    Alternatives: Deeper CNNs (e.g., ResNet) or transfer learning (e.g., EfficientNet).\n",
    "    Allows selection of preprocessing steps like grayscale, contrast, and saturation adjustment.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_classes=202,                                   # Number of output classes\n",
    "                 apply_grayscale=False,                                 # If True, convert images to grayscale\n",
    "                 apply_contrast=False, contrast_factor=1.5,             # 1.5 = increase contrast\n",
    "                 apply_saturation=False, saturation_factor=1.5):        # 1.5 = increase saturation\n",
    "        \"\"\"Initializes the model.\n",
    "        \n",
    "        Args:\n",
    "            n_classes (int): Number of output classes.\n",
    "            apply_grayscale (bool): If True, convert images to grayscale first.\n",
    "            apply_contrast (bool): If True, adjust image contrast.\n",
    "            contrast_factor (float): Factor for contrast adjustment.\n",
    "            apply_saturation (bool): If True, adjust image saturation.\n",
    "            saturation_factor (float): Factor for saturation adjustment.\n",
    "        \"\"\"\n",
    "        super().__init__() # Call the parent class constructor\n",
    "        \n",
    "        # Store preprocessing flags and factors\n",
    "        self.apply_grayscale = apply_grayscale\n",
    "        self.apply_contrast = apply_contrast\n",
    "        self.apply_saturation = apply_saturation\n",
    "        \n",
    "        # --- Preprocessing Layers ---        \n",
    "        # Rescaling layer (always applied)\n",
    "        self.rescale_layer = Rescaling(scale= 1 / 255.0, name=\"Rescale_Layer\")    # Rescales pixel values to [0, 1]\n",
    "        \n",
    "        # Conditionally define Lambda layer for contrast adjustment\n",
    "        if self.apply_contrast:\n",
    "            # Define Lambda layer for contrast adjustment\n",
    "            # Source: https://keras.io/api/layers/core_layers/lambda/\n",
    "            #         https://www.tensorflow.org/api_docs/python/tf/image/adjust_contrast\n",
    "            #         contrast_factor > 1 increases contrast, < 1 decreases contrast\n",
    "            self.contrast_layer = Lambda(\n",
    "                lambda x: tf.image.adjust_contrast(x, contrast_factor=contrast_factor),\n",
    "                name='Adjust_Contrast'\n",
    "            )\n",
    "        \n",
    "        # Conditionally define Lambda layer for saturation adjustment\n",
    "        if self.apply_saturation:\n",
    "            # Define Lambda layer for saturation adjustment\n",
    "            # Source: https://www.tensorflow.org/api_docs/python/tf/image/adjust_saturation\n",
    "            #         saturation_factor > 1 increases saturation, < 1 decreases saturation\n",
    "            self.saturation_layer = Lambda(\n",
    "                lambda x: tf.image.adjust_saturation(x, saturation_factor=saturation_factor),\n",
    "                name='Adjust_Saturation'\n",
    "            )\n",
    "            \n",
    "        # Conditionally define Lambda layer for grayscale conversion\n",
    "        if self.apply_grayscale:\n",
    "            # Define Lambda layer for grayscale conversion\n",
    "            # Source: https://www.tensorflow.org/api_docs/python/tf/image/rgb_to_grayscale\n",
    "            self.grayscale_layer = Lambda(\n",
    "                lambda x: tf.image.rgb_to_grayscale(x), \n",
    "                name='RGB_to_Grayscale'\n",
    "            )\n",
    "            # IMPORTANT: Add a Conv2D layer immediately after grayscale to ensure \n",
    "            #            the number of channels is compatible with subsequent layers \n",
    "            #            if they expect 3 channels. Here, we'll keep it 1 channel and adjust conv1.\n",
    "            # Alternatively, convert grayscale back to 3 identical channels:\n",
    "            # self.grayscale_to_rgb_layer = Lambda(\n",
    "            #     lambda x: tf.image.grayscale_to_rgb(x),\n",
    "            #     name='Grayscale_to_RGB'\n",
    "            # )\n",
    "            \n",
    "            \n",
    "        # --- Convolutional Layers ---\n",
    "        # Adjust the first Conv layer's input channels if grayscale is applied and not converted back to RGB\n",
    "        # If grayscale IS applied, the input to conv1 will have 1 channel.\n",
    "        # If grayscale IS NOT applied, the input will have 3 channels (after rescaling).\n",
    "        # We will handle this by checking the shape dynamically or assuming subsequent layers can handle 1 channel if needed.\n",
    "        # For simplicity here, let's assume conv1 works with either 1 or 3 channels.\n",
    "        # If grayscale is applied, the input depth is 1, otherwise 3.\n",
    "        # A more robust way might involve explicitly setting input_shape or checking channels.\n",
    "        # Let's define conv1 to work even if input is grayscale (1 channel)\n",
    "        \n",
    "        # Block 1\n",
    "        # Source: https://stackoverflow.com/questions/60157742/convolutional-neural-network-cnn-input-shape/61075207#61075207 (Explain Conv2D)\n",
    "        self.conv1 = Conv2D(filters=32, kernel_size=(3, 3), padding='same', name=\"Conv_Block1_Conv\")\n",
    "        self.bn1 = BatchNormalization(name=\"Conv_Block1_BN\")\n",
    "        self.act1 = Activation('relu', name=\"Conv_Block1_Act\")\n",
    "        self.pool1 = MaxPooling2D(pool_size=(2, 2), name=\"Conv_Block1_Pool\") # Output: 112x112x32\n",
    "\n",
    "        # Block 2\n",
    "        self.conv2 = Conv2D(filters=64, kernel_size=(3, 3), padding='same', name=\"Conv_Block2_Conv\")\n",
    "        self.bn2 = BatchNormalization(name=\"Conv_Block2_BN\")\n",
    "        self.act2 = Activation('relu', name=\"Conv_Block2_Act\")\n",
    "        self.pool2 = MaxPooling2D(pool_size=(2, 2), name=\"Conv_Block2_Pool\") # Output: 56x56x64\n",
    "\n",
    "        # Block 3\n",
    "        self.conv3 = Conv2D(filters=128, kernel_size=(3, 3), padding='same', name=\"Conv_Block3_Conv\")\n",
    "        self.bn3 = BatchNormalization(name=\"Conv_Block3_BN\")\n",
    "        self.act3 = Activation('relu', name=\"Conv_Block3_Act\")\n",
    "        self.pool3 = MaxPooling2D(pool_size=(2, 2), name=\"Conv_Block3_Pool\") # Output: 28x28x128\n",
    "\n",
    "        # --- Classification Head ---\n",
    "        self.global_avg_pool = GlobalAveragePooling2D(name=\"Global_Average_Pooling\")\n",
    "        self.flatten = Flatten(name=\"Flatten_Layer\")\n",
    "        self.dense1 = Dense(128, name=\"Dense_Layer1\")                                     # Smaller intermediate dense layer\n",
    "        self.bn_dense1 = BatchNormalization(name=\"Dense_Layer1_BN\")\n",
    "        self.act_dense1 = Activation('relu', name=\"Dense_Layer1_Act\")\n",
    "        self.dropout = Dropout(0.7, name=\"Dropout_Layer\")\n",
    "        self.dense_output = Dense(n_classes, activation='softmax', name=\"Output_Layer\")\n",
    "\n",
    "    def call(self: Self, inputs: Any, training:bool=False) -> Any:\n",
    "        \"\"\"Defines the forward pass of the model.\n",
    "        \n",
    "        Args:\n",
    "            inputs: Input tensor (batch of images).\n",
    "            training (bool): Indicates if the model is in training mode (for Dropout).\n",
    "            \n",
    "        Returns:\n",
    "            Output tensor (probabilities for each class).\n",
    "        \"\"\"\n",
    "        # Apply mandatory rescaling\n",
    "        x = self.rescale_layer(inputs)\n",
    "        \n",
    "        # Apply conditional preprocessing layers\n",
    "        if self.apply_contrast:\n",
    "            x = self.contrast_layer(x)\n",
    "        if self.apply_saturation:\n",
    "            x = self.saturation_layer(x)\n",
    "        if self.apply_grayscale:\n",
    "            x = self.grayscale_layer(x)\n",
    "            # If subsequent layers strictly require 3 channels, uncomment this:\n",
    "            # x = self.grayscale_to_rgb_layer(x) \n",
    "            # Note: If grayscale is applied, conv1 will process a 1-channel input unless converted back.\n",
    "        \n",
    "        # Conv Block 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = self.act1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # Conv Block 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x, training=training)\n",
    "        x = self.act2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # Conv Block 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x, training=training)\n",
    "        x = self.act3(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # Classification Head\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.bn_dense1(x, training=training)\n",
    "        x = self.act_dense1(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "        outputs = self.dense_output(x)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "# Example Instantiation and Summary\n",
    "model = RareSpeciesCNN(\n",
    "    n_classes=n_classes, \n",
    "    apply_grayscale=False, \n",
    "    apply_contrast=False,                         \n",
    "    apply_saturation=False,\n",
    ")\n",
    "\n",
    "# Build the model by providing an input shape\n",
    "inputs = Input(shape=(img_width, img_height, 3))        # Input shape\n",
    "_ = model.call(inputs)                                  # Call the model to build it\n",
    "model.summary()                                         # Print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dde8dc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=651x477>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the model architecture\n",
    "# Source: https://www.kaggle.com/code/devsubhash/visualize-deep-learning-models-using-visualkeras\n",
    "visualkeras.layered_view(model, \n",
    "                         legend=True, \n",
    "                         show_dimension=True,\n",
    "                         scale_xy=1,                                        # Adjust the scale of the image\n",
    "                        #  scale_z=1,\n",
    "                         # to_file='./BaselineModel_Architecture.png',\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "391168a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "# optimizer = SGD(learning_rate=0.1, weight_decay=0.01, name=\"Optimizer\")                                         # SGD with decay for stability\n",
    "optimizer = Adam(learning_rate=0.001, weight_decay=0.01, name=\"Optimizer\")                                        # Adam for faster convergence\n",
    "\n",
    "loss = CategoricalCrossentropy(name=\"Loss\")                                                                       # Suitable for multi-class one-hot labels\n",
    "metrics = [CategoricalAccuracy(name=\"accuracy\"), \n",
    "           Precision(name=\"precision\"),\n",
    "           Recall(name=\"recall\"), \n",
    "           F1Score(average=\"macro\", name=\"f1_score\"),\n",
    "           AUC(name=\"auc\")]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5ed55ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mModel name:\u001b[0m RareSpeciesCNN_20250412\n"
     ]
    }
   ],
   "source": [
    "# Create a directory for saving the model and logs\n",
    "model_name = f\"RareSpeciesCNN_{datetime.datetime.now().strftime('%Y%m%d')}\"                                                                             # Model name \n",
    "print(f\"\\n\\033[1mModel name:\\033[0m {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "870a01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "# Create a directory for saving the model and logs\n",
    "os.makedirs(\"./ModelCallbacks\", exist_ok=True)      # Create directory if it doesn't exist\n",
    "model_name = f\"RareSpeciesCNN_{datetime.datetime.now().strftime('%Y%m%d')}\"                                                                             # Model name \n",
    "callbacks = [\n",
    "    ModelCheckpoint(f\"./ModelCallbacks/checkpoint_{model_name}.keras\", monitor=\"val_loss\", save_best_only=True, verbose=0),       # Save best model\n",
    "    CSVLogger(f\"./ModelCallbacks/metrics_{model_name}.csv\"),                                                                      # Log training metrics\n",
    "    LearningRateScheduler(lambda epoch, lr: lr * 0.95),                                                                           # Exponential decay for learning rate\n",
    "    EarlyStopping(monitor='val_loss', patience=3, verbose=1)                                                                      # Stop training when the validation loss stops improving\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f48a4f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668d0768",
   "metadata": {},
   "source": [
    "### **Original Dataset | Grayscale=F | Contrast=F | Saturation=F**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b6dda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_datagen, batch_size = batch_size, epochs=10, validation_data=val_datagen, callbacks=callbacks, verbose=1)\n",
    "train_time = round(time.time() - start_time, 2)\n",
    "\n",
    "print(f\"\\nTraining completed in \\033[1m{train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\\033[0m).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204995d589f8431f",
   "metadata": {},
   "source": [
    "##### **🧪 Model Selection & 📏 Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ffc2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from utilities import plot_metrics\n",
    "\n",
    "os.makedirs(\"./ModelsEvaluation\", exist_ok=True)                                              # Create directory if it doesn't exist\n",
    "plot_metrics(history, file_path=f\"./ModelsEvaluation/2_Training_Validation_Metrics_{datetime.datetime.now().strftime('%Y%m%d')}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbae5954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation and test sets\n",
    "train_results = {'accuracy': history.history['accuracy'][-1], 'precision': history.history['precision'][-1], 'recall': history.history['recall'][-1], 'f1_score': history.history['f1_score'][-1], 'auc': history.history['auc'][-1]}\n",
    "val_results = model.evaluate(val_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "test_results = model.evaluate(test_datagen, batch_size=batch_size, return_dict=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb1867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "from utilities import display_side_by_side, create_evaluation_dataframe\n",
    "results_df = create_evaluation_dataframe(\n",
    "    model_name=\"Baseline Model\",\n",
    "    variation=\"Original | Grayscale=F | Contrast=F | Saturation=F | Adam=0.001\",           # Dataset | Grayscale | Contrast | Saturation | Optimizer=Learning Rate\n",
    "    train_metrics=train_results, val_metrics=val_results, test_metrics=test_results, train_time=train_time,\n",
    "    csv_save_path= f\"./ModelsEvaluation/2_BaselineModel_TrainingValidationMetrics_{model_name}.csv\"      # Save the results to a CSV file\n",
    ")\n",
    "display_side_by_side(results_df, super_title=\"Model Evaluation Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2414b175",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eba7ca3",
   "metadata": {},
   "source": [
    "## **Original Dataset | Grayscale=T | Contrast=F | Saturation=F**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model - Original Dataset | Grayscale=T | Contrast=F | Saturation=F\n",
    "model = RareSpeciesCNN(\n",
    "    n_classes=n_classes, \n",
    "    apply_grayscale=True, \n",
    "    apply_contrast=False,                         \n",
    "    apply_saturation=False\n",
    ")\n",
    "\n",
    "# Build the model by providing an input shape\n",
    "inputs = Input(shape=(img_width, img_height, 3))        # Input shape\n",
    "_ = model.call(inputs)                                  # Call the model to build it\n",
    "model.summary()                                         # Print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747d62fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "# optimizer = SGD(learning_rate=0.1, weight_decay=0.01, name=\"Optimizer\")                                         # SGD with decay for stability\n",
    "optimizer = Adam(learning_rate=0.001, weight_decay=0.01, name=\"Optimizer\")                                        # Adam for faster convergence\n",
    "\n",
    "loss = CategoricalCrossentropy(name=\"Loss\")                                                                       # Suitable for multi-class one-hot labels\n",
    "metrics = [CategoricalAccuracy(name=\"accuracy\"), Precision(name=\"precision\"), Recall(name=\"recall\"), F1Score(average=\"macro\", name=\"f1_score\"), AUC(name=\"auc\")]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "model_name = f\"RareSpeciesCNN_{datetime.datetime.now().strftime('%Y%m%d')}_OriginalGrayscale\" # Model name \n",
    "callbacks = [ModelCheckpoint(f\"./ModelCallbacks/checkpoint_{model_name}.keras\", monitor=\"val_loss\", save_best_only=True, verbose=0), CSVLogger(f\"./ModelCallbacks/metrics_{model_name}.csv\"), LearningRateScheduler(lambda epoch, lr: lr * 0.95), EarlyStopping(monitor='val_loss', patience=3, verbose=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_datagen, batch_size = batch_size, epochs=10, validation_data=val_datagen, callbacks=callbacks, verbose=1)\n",
    "train_time = round(time.time() - start_time, 2)\n",
    "print(f\"\\nTraining completed in \\033[1m{train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\\033[0m).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad9d878",
   "metadata": {},
   "source": [
    "##### **🧪 Model Selection & 📏 Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ca3f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from utilities import plot_metrics\n",
    "plot_metrics(history, file_path=f\"./ModelsEvaluation/2_BaselineModel_TrainingValidationMetrics_{model_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f46460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation and test sets\n",
    "train_results = {'accuracy': history.history['accuracy'][-1], 'precision': history.history['precision'][-1], 'recall': history.history['recall'][-1], 'f1_score': history.history['f1_score'][-1], 'auc': history.history['auc'][-1]}\n",
    "val_results = model.evaluate(val_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "test_results = model.evaluate(test_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "\n",
    "# Display results\n",
    "from utilities import display_side_by_side, create_evaluation_dataframe\n",
    "results_df = create_evaluation_dataframe(\n",
    "    model_name=\"Baseline Model\", variation=\"Original | Grayscale=T | Contrast=F | Saturation=F | Adam=0.001\",   # Dataset | Grayscale | Contrast | Saturation | Optimizer=Learning Rate\n",
    "    train_metrics=train_results, val_metrics=val_results, test_metrics=test_results, train_time=train_time,\n",
    "    csv_save_path= f\"./ModelsEvaluation/2_BaselineModel_TrainingValidationMetrics_{model_name}.csv\"\n",
    ")\n",
    "display_side_by_side(results_df, super_title=\"Model Evaluation Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5fd275",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e5f6df",
   "metadata": {},
   "source": [
    "## **Original Dataset | Grayscale=F | Contrast=T | Saturation=F**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model - Original Dataset | Grayscale=F | Contrast=T | Saturation=F\n",
    "model = RareSpeciesCNN(\n",
    "    n_classes=n_classes, \n",
    "    apply_grayscale=False, \n",
    "    apply_contrast=True,                         \n",
    "    apply_saturation=False\n",
    ")\n",
    "# Build the model by providing an input shape\n",
    "inputs = Input(shape=(img_width, img_height, 3))        # Input shape\n",
    "_ = model.call(inputs)                                  # Call the model to build it\n",
    "model.summary()                                         # Print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "# optimizer = SGD(learning_rate=0.1, weight_decay=0.01, name=\"Optimizer\")                                         # SGD with decay for stability\n",
    "optimizer = Adam(learning_rate=0.001, weight_decay=0.01, name=\"Optimizer\")                                        # Adam for faster convergence\n",
    "loss = CategoricalCrossentropy(name=\"Loss\")                                                                       # Suitable for multi-class one-hot labels\n",
    "metrics = [CategoricalAccuracy(name=\"accuracy\"), Precision(name=\"precision\"), Recall(name=\"recall\"), F1Score(average=\"macro\", name=\"f1_score\"), AUC(name=\"auc\")]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e70195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "model_name = f\"RareSpeciesCNN_{datetime.datetime.now().strftime('%Y%m%d')}_OriginalContrast\" # Model name\n",
    "callbacks = [ModelCheckpoint(f\"./ModelCallbacks/checkpoint_{model_name}.keras\", monitor=\"val_loss\", save_best_only=True, verbose=0), CSVLogger(f\"./ModelCallbacks/metrics_{model_name}.csv\"), LearningRateScheduler(lambda epoch, lr: lr * 0.95), EarlyStopping(monitor='val_loss', patience=3, verbose=1)]\n",
    "\n",
    "# Train model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_datagen, batch_size = batch_size, epochs=10, validation_data=val_datagen, callbacks=callbacks, verbose=1)\n",
    "train_time = round(time.time() - start_time, 2)\n",
    "print(f\"\\nTraining completed in \\033[1m{train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\\033[0m).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23f44b1",
   "metadata": {},
   "source": [
    "#### **🧪 Model Selection & 📏 Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from utilities import plot_metrics\n",
    "plot_metrics(history, file_path=f\"./ModelsEvaluation/2_BaselineModel_TrainingValidationMetrics_{model_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation and test sets\n",
    "train_results = {'accuracy': history.history['accuracy'][-1], 'precision': history.history['precision'][-1], 'recall': history.history['recall'][-1], 'f1_score': history.history['f1_score'][-1], 'auc': history.history['auc'][-1]}\n",
    "val_results = model.evaluate(val_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "test_results = model.evaluate(test_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "\n",
    "# Display results\n",
    "from utilities import display_side_by_side, create_evaluation_dataframe\n",
    "results_df = create_evaluation_dataframe(\n",
    "    model_name=\"Baseline Model\", variation=\"Original | Grayscale=F | Contrast=T | Saturation=F | Adam=0.001\",   # Dataset | Grayscale | Contrast | Saturation | Optimizer=Learning Rate\n",
    "    train_metrics=train_results, val_metrics=val_results, test_metrics=test_results, train_time=train_time,\n",
    "    csv_save_path= f\"./ModelsEvaluation/2_BaselineModel_TrainingValidationMetrics_{model_name}.csv\"\n",
    ")\n",
    "display_side_by_side(results_df, super_title=\"Model Evaluation Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea3ba86",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd48fe8",
   "metadata": {},
   "source": [
    "## **Original Dataset | Grayscale=F | Contrast=F | Saturation=T**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model - Original Dataset | Grayscale=F | Contrast=F | Saturation=T\n",
    "model = RareSpeciesCNN(\n",
    "    n_classes=n_classes, \n",
    "    apply_grayscale=False, \n",
    "    apply_contrast=False,                         \n",
    "    apply_saturation=True\n",
    ")\n",
    "\n",
    "# Build the model by providing an input shape\n",
    "inputs = Input(shape=(img_width, img_height, 3))        # Input shape\n",
    "_ = model.call(inputs)                                  # Call the model to build it\n",
    "model.summary()                                         # Print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "# optimizer = SGD(learning_rate=0.1, weight_decay=0.01, name=\"Optimizer\")                                         # SGD with decay for stability\n",
    "optimizer = Adam(learning_rate=0.001, weight_decay=0.01, name=\"Optimizer\")                                        # Adam for faster convergence\n",
    "loss = CategoricalCrossentropy(name=\"Loss\")                                                                       # Suitable for multi-class one-hot labels\n",
    "metrics = [CategoricalAccuracy(name=\"accuracy\"), Precision(name=\"precision\"), Recall(name=\"recall\"), F1Score(average=\"macro\", name=\"f1_score\"), AUC(name=\"auc\")]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "model_name = f\"RareSpeciesCNN_{datetime.datetime.now().strftime('%Y%m%d')}_OriginalSaturation\" # Model name\n",
    "callbacks = [ModelCheckpoint(f\"./ModelCallbacks/checkpoint_{model_name}.keras\", monitor=\"val_loss\", save_best_only=True, verbose=0), CSVLogger(f\"./ModelCallbacks/metrics_{model_name}.csv\"), LearningRateScheduler(lambda epoch, lr: lr * 0.95), EarlyStopping(monitor='val_loss', patience=3, verbose=1)]\n",
    "\n",
    "# Train model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_datagen, batch_size = batch_size, epochs=10, validation_data=val_datagen, callbacks=callbacks, verbose=1)\n",
    "train_time = round(time.time() - start_time, 2)\n",
    "print(f\"\\nTraining completed in \\033[1m{train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\\033[0m).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceb6878",
   "metadata": {},
   "source": [
    "### **🧪 Model Selection & 📏 Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from utilities import plot_metrics\n",
    "plot_metrics(history, file_path=f\"./ModelsEvaluation/2_BaselineModel_TrainingValidationMetrics_{model_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c12b41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation and test sets\n",
    "train_results = {'accuracy': history.history['accuracy'][-1], 'precision': history.history['precision'][-1], 'recall': history.history['recall'][-1], 'f1_score': history.history['f1_score'][-1], 'auc': history.history['auc'][-1]}\n",
    "val_results = model.evaluate(val_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "test_results = model.evaluate(test_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "\n",
    "# Display results\n",
    "from utilities import display_side_by_side, create_evaluation_dataframe\n",
    "results_df = create_evaluation_dataframe(\n",
    "    model_name=\"Baseline Model\", variation=\"Original | Grayscale=F | Contrast=F | Saturation=T | Adam=0.001\",   # Dataset | Grayscale | Contrast | Saturation | Optimizer=Learning Rate\n",
    "    train_metrics=train_results, val_metrics=val_results, test_metrics=test_results, train_time=train_time,\n",
    "    csv_save_path= f\"./ModelsEvaluation/2_BaselineModel_TrainingValidationMetrics_{model_name}.csv\"\n",
    ")\n",
    "display_side_by_side(results_df, super_title=\"Model Evaluation Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6eab287",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa058b52",
   "metadata": {},
   "source": [
    "# **🖌️ SMOTE (Dataset Augmentation)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceaca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data with Data Augmentation (SMOTE)\n",
    "from utilities import load_images_from_directory\n",
    "\n",
    "train_DataAugmentationSMOTE_dir = Path(\"data/RareSpecies_Split/train_DataAugmentationSMOTE\")\n",
    "val_dir = Path(\"data/RareSpecies_Split/val\")\n",
    "test_dir = Path(\"data/RareSpecies_Split/test\")\n",
    "\n",
    "# train_DataAugmentationSMOTE_dir = Path(\"/content/RareSpecies_Split/train_DataAugmentationSMOTE\")\n",
    "# val_dir = Path(\"/content/RareSpecies_Split/val\")\n",
    "# test_dir = Path(\"/content/RareSpecies_Split/test\")\n",
    "\n",
    "class_names = sorted(os.listdir(train_DataAugmentationSMOTE_dir))\n",
    "class_indices = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "# Import the image dataset from the directory\n",
    "train_DataAugmentationSMOTE_datagen, val_datagen, test_datagen = load_images_from_directory(train_DataAugmentationSMOTE_dir, val_dir, test_dir,\n",
    "                                                                      labels='inferred', label_mode='categorical',\n",
    "                                                                      class_names=class_names, color_mode='rgb',\n",
    "                                                                      batch_size=batch_size, image_size=image_size, seed=2025, \n",
    "                                                                      interpolation='bilinear', crop_to_aspect_ratio=False, pad_to_aspect_ratio=False)\n",
    "\n",
    "# Check the shape of the data (batch_size, img_width, img_height, 3)\n",
    "for x, y in train_DataAugmentationSMOTE_datagen.take(1):\n",
    "    print(\"Train batch shape:\", x.shape, y.shape)\n",
    "for x, y in val_datagen.take(1):\n",
    "    print(\"Val batch shape:\", x.shape, y.shape)\n",
    "for x, y in test_datagen.take(1):\n",
    "    print(\"Test batch shape:\", x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bf32cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution\n",
    "train_class_counts = {class_name: len(list((train_DataAugmentationSMOTE_dir / class_name).glob('*')))\n",
    "                      for class_name in list(class_names)}\n",
    "train_class_distribution = pd.DataFrame({\n",
    "    'n': train_class_counts.values(),\n",
    "    '%': [count / sum(train_class_counts.values()) * 100 for count in train_class_counts.values()],\n",
    "})\n",
    "train_class_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e99728",
   "metadata": {},
   "source": [
    "## **SMOTE Data Augmentation | Grayscale=F | Contrast=F | Saturation=F**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fe8e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model - SMOTE Data Augmentation | Grayscale=F | Contrast=F | Saturation=F\n",
    "model = RareSpeciesCNN(\n",
    "    n_classes=n_classes, \n",
    "    apply_grayscale=False, \n",
    "    apply_contrast=False,                         \n",
    "    apply_saturation=False\n",
    ")\n",
    "\n",
    "# Build the model by providing an input shape\n",
    "inputs = Input(shape=(img_width, img_height, 3))        # Input shape\n",
    "_ = model.call(inputs)                                  # Call the model to build it\n",
    "model.summary()                                         # Print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0706e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.001, weight_decay=0.01, name=\"Optimizer\")\n",
    "loss = CategoricalCrossentropy(name=\"Loss\")\n",
    "metrics = [CategoricalAccuracy(name=\"accuracy\"), Precision(name=\"precision\"), Recall(name=\"recall\"), F1Score(average=\"macro\", name=\"f1_score\"), AUC(name=\"auc\")]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3b864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "model_name = f\"RareSpeciesCNN_{datetime.datetime.now().strftime('%Y%m%d')}_SMOTE\"\n",
    "callbacks = [ModelCheckpoint(f\"./ModelCallbacks/checkpoint_{model_name}.keras\", monitor=\"val_loss\", save_best_only=True, verbose=0), CSVLogger(f\"./ModelCallbacks/metrics_{model_name}.csv\"), LearningRateScheduler(lambda epoch, lr: lr * 0.95), EarlyStopping(monitor='val_loss', patience=3, verbose=1)]\n",
    "\n",
    "# Train model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_DataAugmentationSMOTE_datagen, batch_size=batch_size, epochs=10, validation_data=val_datagen, callbacks=callbacks, verbose=1)\n",
    "train_time = round(time.time() - start_time, 2)\n",
    "print(f\"\\nTraining completed in \\033[1m{train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\\033[0m).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40a1230",
   "metadata": {},
   "source": [
    "#### **🧪 Model Selection & 📏 Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from utilities import plot_metrics\n",
    "plot_metrics(history, file_path=f\"./ModelsEvaluation/2_BaselineModel_TrainingValidationMetrics_{model_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53615bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation and test sets\n",
    "train_results = {'accuracy': history.history['accuracy'][-1], 'precision': history.history['precision'][-1], 'recall': history.history['recall'][-1], 'f1_score': history.history['f1_score'][-1], 'auc': history.history['auc'][-1]}\n",
    "val_results = model.evaluate(val_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "test_results = model.evaluate(test_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "\n",
    "# Display results\n",
    "from utilities import display_side_by_side, create_evaluation_dataframe\n",
    "results_df = create_evaluation_dataframe(\n",
    "    model_name=\"Baseline Model\", variation=\"SMOTE | Grayscale=F | Contrast=F | Saturation=F | Adam=0.001\",\n",
    "    train_metrics=train_results, val_metrics=val_results, test_metrics=test_results, train_time=train_time, \n",
    "    csv_save_path= f\"./ModelsEvaluation/2_BaselineModel_TrainingValidationMetrics_{model_name}.csv\"\n",
    ")\n",
    "display_side_by_side(results_df, super_title=\"Model Evaluation Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4704891c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855128e0",
   "metadata": {},
   "source": [
    "## **SMOTE Data Augmentation | Grayscale=T | Contrast=F | Saturation=F**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb87bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model - SMOTE Data Augmentation | Grayscale=T | Contrast=F | Saturation=F\n",
    "model = RareSpeciesCNN(\n",
    "    n_classes=n_classes, \n",
    "    apply_grayscale=True, \n",
    "    apply_contrast=False,                         \n",
    "    apply_saturation=False\n",
    ")\n",
    "\n",
    "# Build the model by providing an input shape\n",
    "inputs = Input(shape=(img_width, img_height, 3))        # Input shape\n",
    "_ = model.call(inputs)                                  # Call the model to build it\n",
    "model.summary()                                         # Print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888466f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.001, weight_decay=0.01, name=\"Optimizer\")\n",
    "loss = CategoricalCrossentropy(name=\"Loss\")\n",
    "metrics = [CategoricalAccuracy(name=\"accuracy\"), Precision(name=\"precision\"), Recall(name=\"recall\"), F1Score(average=\"macro\", name=\"f1_score\"), AUC(name=\"auc\")]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d648f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "model_name = f\"RareSpeciesCNN_{datetime.datetime.now().strftime('%Y%m%d')}_SMOTEGrayscale\"\n",
    "callbacks = [ModelCheckpoint(f\"./ModelCallbacks/checkpoint_{model_name}.keras\", monitor=\"val_loss\", save_best_only=True, verbose=0), CSVLogger(f\"./ModelCallbacks/metrics_{model_name}.csv\"), LearningRateScheduler(lambda epoch, lr: lr * 0.95), EarlyStopping(monitor='val_loss', patience=3, verbose=1)]\n",
    "\n",
    "# Train model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_DataAugmentationSMOTE_datagen, batch_size=batch_size, epochs=10, validation_data=val_datagen, callbacks=callbacks, verbose=1)\n",
    "train_time = round(time.time() - start_time, 2)\n",
    "print(f\"\\nTraining completed in \\033[1m{train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\\033[0m).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839340f7",
   "metadata": {},
   "source": [
    "#### **🧪 Model Selection & 📏 Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5dc3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from utilities import plot_metrics\n",
    "plot_metrics(history, file_path=f\"./ModelsEvaluation/2_BaselineModel_TrainingValidationMetrics_{model_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8143025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation and test sets\n",
    "train_results = {'accuracy': history.history['accuracy'][-1], 'precision': history.history['precision'][-1], 'recall': history.history['recall'][-1], 'f1_score': history.history['f1_score'][-1], 'auc': history.history['auc'][-1]}\n",
    "val_results = model.evaluate(val_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "test_results = model.evaluate(test_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "\n",
    "# Display results\n",
    "from utilities import display_side_by_side, create_evaluation_dataframe\n",
    "results_df = create_evaluation_dataframe(\n",
    "    model_name=\"Baseline Model\", variation=\"SMOTE | Grayscale=T | Contrast=F | Saturation=F | Adam=0.001\",\n",
    "    train_metrics=train_results, val_metrics=val_results, test_metrics=test_results, train_time=train_time,\n",
    "    csv_save_path= f\"./ModelsEvaluation/2_BaselineModel_TrainingValidationMetrics_{model_name}.csv\"\n",
    ")\n",
    "display_side_by_side(results_df, super_title=\"Model Evaluation Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f45f1c1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548200e1",
   "metadata": {},
   "source": [
    "## **SMOTE Data Augmentation | Grayscale=F | Contrast=T | Saturation=F**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b70988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model - SMOTE Data Augmentation | Grayscale=F | Contrast=T | Saturation=F\n",
    "model = RareSpeciesCNN(\n",
    "    n_classes=n_classes, \n",
    "    apply_grayscale=False, \n",
    "    apply_contrast=True,                         \n",
    "    apply_saturation=False\n",
    ")\n",
    "\n",
    "# Build the model by providing an input shape\n",
    "inputs = Input(shape=(img_width, img_height, 3))        # Input shape\n",
    "_ = model.call(inputs)                                  # Call the model to build it\n",
    "model.summary()                                         # Print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5d002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.001, weight_decay=0.01, name=\"Optimizer\")\n",
    "loss = CategoricalCrossentropy(name=\"Loss\")\n",
    "metrics = [CategoricalAccuracy(name=\"accuracy\"), Precision(name=\"precision\"), Recall(name=\"recall\"), F1Score(average=\"macro\", name=\"f1_score\"), AUC(name=\"auc\")]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a961ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "model_name = f\"RareSpeciesCNN_{datetime.datetime.now().strftime('%Y%m%d')}_SMOTEContrast\"\n",
    "callbacks = [ModelCheckpoint(f\"./ModelCallbacks/checkpoint_{model_name}.keras\", monitor=\"val_loss\", save_best_only=True, verbose=0), CSVLogger(f\"./ModelCallbacks/metrics_{model_name}.csv\"), LearningRateScheduler(lambda epoch, lr: lr * 0.95), EarlyStopping(monitor='val_loss', patience=3, verbose=1)]\n",
    "\n",
    "# Train model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_DataAugmentationSMOTE_datagen, batch_size=batch_size, epochs=10, validation_data=val_datagen, callbacks=callbacks, verbose=1)\n",
    "train_time = round(time.time() - start_time, 2)\n",
    "print(f\"\\nTraining completed in \\033[1m{train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\\033[0m).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69750aaf",
   "metadata": {},
   "source": [
    "#### **🧪 Model Selection & 📏 Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af33e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from utilities import plot_metrics\n",
    "plot_metrics(history, file_path=f\"./ModelsEvaluation/2_BaselineModel_TrainingValidationMetrics_{model_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571e4082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation and test sets\n",
    "train_results = {'accuracy': history.history['accuracy'][-1], 'precision': history.history['precision'][-1], 'recall': history.history['recall'][-1], 'f1_score': history.history['f1_score'][-1], 'auc': history.history['auc'][-1]}\n",
    "val_results = model.evaluate(val_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "test_results = model.evaluate(test_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "\n",
    "# Display results\n",
    "from utilities import display_side_by_side, create_evaluation_dataframe\n",
    "results_df = create_evaluation_dataframe(\n",
    "    model_name=\"Baseline Model\", variation=\"SMOTE | Grayscale=F | Contrast=T | Saturation=F | Adam=0.001\",\n",
    "    train_metrics=train_results, val_metrics=val_results, test_metrics=test_results, train_time=train_time,\n",
    "    csv_save_path= f\"./ModelsEvaluation/2_BaselineModel_TrainingValidationMetrics_{model_name}.csv\"\n",
    ")\n",
    "display_side_by_side(results_df, super_title=\"Model Evaluation Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3d1e50",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcd6e88",
   "metadata": {},
   "source": [
    "## **SMOTE Data Augmentation | Grayscale=F | Contrast=F | Saturation=T**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27586cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model - SMOTE Data Augmentation | Grayscale=F | Contrast=F | Saturation=T\n",
    "model = RareSpeciesCNN(\n",
    "    n_classes=n_classes, \n",
    "    apply_grayscale=False, \n",
    "    apply_contrast=False,                         \n",
    "    apply_saturation=True\n",
    ")\n",
    "\n",
    "# Build the model by providing an input shape\n",
    "inputs = Input(shape=(img_width, img_height, 3))        # Input shape\n",
    "_ = model.call(inputs)                                  # Call the model to build it\n",
    "model.summary()                                         # Print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b619b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.001, weight_decay=0.01, name=\"Optimizer\")\n",
    "loss = CategoricalCrossentropy(name=\"Loss\")\n",
    "metrics = [CategoricalAccuracy(name=\"accuracy\"), Precision(name=\"precision\"), Recall(name=\"recall\"), F1Score(average=\"macro\", name=\"f1_score\"), AUC(name=\"auc\")]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125280a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "model_name = f\"RareSpeciesCNN_{datetime.datetime.now().strftime('%Y%m%d')}_SMOTESaturation\"\n",
    "callbacks = [ModelCheckpoint(f\"./ModelCallbacks/checkpoint_{model_name}.keras\", monitor=\"val_loss\", save_best_only=True, verbose=0), CSVLogger(f\"./ModelCallbacks/metrics_{model_name}.csv\"), LearningRateScheduler(lambda epoch, lr: lr * 0.95), EarlyStopping(monitor='val_loss', patience=3, verbose=1)]\n",
    "\n",
    "# Train model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_DataAugmentationSMOTE_datagen, batch_size=batch_size, epochs=10, validation_data=val_datagen, callbacks=callbacks, verbose=1)\n",
    "train_time = round(time.time() - start_time, 2)\n",
    "print(f\"\\nTraining completed in \\033[1m{train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\\033[0m).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0178a011",
   "metadata": {},
   "source": [
    "#### **🧪 Model Selection & 📏 Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a54c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from utilities import plot_metrics\n",
    "plot_metrics(history, file_path=f\"./ModelsEvaluation/2_BaselineModel_TrainingValidationMetrics_{model_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a4e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation and test sets\n",
    "train_results = {'accuracy': history.history['accuracy'][-1], 'precision': history.history['precision'][-1], 'recall': history.history['recall'][-1], 'f1_score': history.history['f1_score'][-1], 'auc': history.history['auc'][-1]}\n",
    "val_results = model.evaluate(val_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "test_results = model.evaluate(test_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "\n",
    "# Display results\n",
    "from utilities import display_side_by_side, create_evaluation_dataframe\n",
    "results_df = create_evaluation_dataframe(\n",
    "    model_name=\"Baseline Model\", variation=\"SMOTE | Grayscale=F | Contrast=F | Saturation=T | Adam=0.001\",\n",
    "    train_metrics=train_results, val_metrics=val_results, test_metrics=test_results, train_time=train_time\n",
    ")\n",
    "display_side_by_side(results_df, super_title=\"Model Evaluation Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813f0433",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f8581f",
   "metadata": {},
   "source": [
    "# **🏋️ Weights**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8db97c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Samples in Each Class in the Original Training Set\n",
    "original_class_counts = {}\n",
    "total_samples = 0\n",
    "for class_name in class_names:\n",
    "    class_path = train_dir / class_name\n",
    "    if class_path.is_dir():\n",
    "        count = len(list(class_path.glob('*'))) # Count image files\n",
    "        original_class_counts[class_name] = count\n",
    "        total_samples += count\n",
    "    else:\n",
    "        print(f\"Warning: Expected directory not found: {class_path}\")\n",
    "\n",
    "# Calculate Class Weights\n",
    "# Formula: weight_for_class_i = (total_samples / (num_classes * samples_in_class_i))  -> This gives higher weight to smaller classes.\n",
    "class_weights = {}\n",
    "for class_name, count in original_class_counts.items():\n",
    "    if count == 0:\n",
    "        print(f\"Warning: Class '{class_name}' has 0 samples. Assigning weight 0.\")\n",
    "        weight = 0.0\n",
    "    else:\n",
    "        weight = (total_samples) / (len(class_names) * count)\n",
    "\n",
    "    # Get the index for this class name\n",
    "    class_index = class_indices[class_name]\n",
    "    class_weights[class_index] = weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc530feb",
   "metadata": {},
   "source": [
    "## **Weights | Grayscale=F | Contrast=F | Saturation=F**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a4119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model - Weights | Grayscale=F | Contrast=F | Saturation=F\n",
    "model = RareSpeciesCNN(\n",
    "    n_classes=n_classes, \n",
    "    apply_grayscale=False, \n",
    "    apply_contrast=False,                         \n",
    "    apply_saturation=False\n",
    ")\n",
    "\n",
    "# Build the model by providing an input shape\n",
    "inputs = Input(shape=(img_width, img_height, 3))        # Input shape\n",
    "_ = model.call(inputs)                                  # Call the model to build it\n",
    "model.summary()                                         # Print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ff47fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.001, weight_decay=0.01, name=\"Optimizer\")\n",
    "loss = CategoricalCrossentropy(name=\"Loss\")\n",
    "metrics = [CategoricalAccuracy(name=\"accuracy\"), Precision(name=\"precision\"), Recall(name=\"recall\"), F1Score(average=\"macro\", name=\"f1_score\"), AUC(name=\"auc\")]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e12cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "model_name = f\"RareSpeciesCNN_{datetime.datetime.now().strftime('%Y%m%d')}_Weights\"\n",
    "callbacks = [ModelCheckpoint(f\"./ModelCallbacks/checkpoint_{model_name}.keras\", monitor=\"val_loss\", save_best_only=True, verbose=0), CSVLogger(f\"./ModelCallbacks/metrics_{model_name}.csv\"), LearningRateScheduler(lambda epoch, lr: lr * 0.95), EarlyStopping(monitor='val_loss', patience=3, verbose=1)]\n",
    "\n",
    "# Train model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_datagen, batch_size=batch_size, epochs=10, validation_data=val_datagen, callbacks=callbacks, verbose=1, \n",
    "                    class_weight=class_weights) # Pass class weights to the fit method\n",
    "train_time = round(time.time() - start_time, 2)\n",
    "print(f\"\\nTraining completed in \\033[1m{train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\\033[0m).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dcaf33",
   "metadata": {},
   "source": [
    "#### **🧪 Model Selection & 📏 Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbc4475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from utilities import plot_metrics\n",
    "plot_metrics(history, file_path=f\"./ModelsEvaluation/2_BaselineModel_TrainingValidationMetrics_{model_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation and test sets\n",
    "train_results = {'accuracy': history.history['accuracy'][-1], 'precision': history.history['precision'][-1], 'recall': history.history['recall'][-1], 'f1_score': history.history['f1_score'][-1], 'auc': history.history['auc'][-1]}\n",
    "val_results = model.evaluate(val_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "test_results = model.evaluate(test_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "\n",
    "# Display results\n",
    "from utilities import display_side_by_side, create_evaluation_dataframe\n",
    "results_df = create_evaluation_dataframe(\n",
    "    model_name=\"Baseline Model\", variation=\"Weights | Grayscale=F | Contrast=F | Saturation=F | Adam=0.001\",\n",
    "    train_metrics=train_results, val_metrics=val_results, test_metrics=test_results, train_time=train_time\n",
    ")\n",
    "display_side_by_side(results_df, super_title=\"Model Evaluation Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00be14de",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18957c21",
   "metadata": {},
   "source": [
    "## **Weights | Grayscale=T | Contrast=F | Saturation=F**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488b732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model - Weights | Grayscale=T | Contrast=F | Saturation=F\n",
    "model = RareSpeciesCNN(\n",
    "    n_classes=n_classes, \n",
    "    apply_grayscale=True, \n",
    "    apply_contrast=False,                         \n",
    "    apply_saturation=False\n",
    ")\n",
    "\n",
    "# Build the model by providing an input shape\n",
    "inputs = Input(shape=(img_width, img_height, 3))        # Input shape\n",
    "_ = model.call(inputs)                                  # Call the model to build it\n",
    "model.summary()                                         # Print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f63302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.001, weight_decay=0.01, name=\"Optimizer\")\n",
    "loss = CategoricalCrossentropy(name=\"Loss\")\n",
    "metrics = [CategoricalAccuracy(name=\"accuracy\"), Precision(name=\"precision\"), Recall(name=\"recall\"), F1Score(average=\"macro\", name=\"f1_score\"), AUC(name=\"auc\")]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2881a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "model_name = f\"RareSpeciesCNN_{datetime.datetime.now().strftime('%Y%m%d')}_WeightsGrayscale\"\n",
    "callbacks = [ModelCheckpoint(f\"./ModelCallbacks/checkpoint_{model_name}.keras\", monitor=\"val_loss\", save_best_only=True, verbose=0), CSVLogger(f\"./ModelCallbacks/metrics_{model_name}.csv\"), LearningRateScheduler(lambda epoch, lr: lr * 0.95), EarlyStopping(monitor='val_loss', patience=3, verbose=1)]\n",
    "\n",
    "# Train model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_datagen, batch_size=batch_size, epochs=10, validation_data=val_datagen, callbacks=callbacks, verbose=1, class_weight=class_weights)\n",
    "train_time = round(time.time() - start_time, 2)\n",
    "print(f\"\\nTraining completed in \\033[1m{train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\\033[0m).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef4cc12",
   "metadata": {},
   "source": [
    "#### **🧪 Model Selection & 📏 Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd6b678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from utilities import plot_metrics\n",
    "plot_metrics(history, file_path=f\"./ModelsEvaluation/2_BaselineModel_TrainingValidationMetrics_{model_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaa8a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation and test sets\n",
    "train_results = {'accuracy': history.history['accuracy'][-1], 'precision': history.history['precision'][-1], 'recall': history.history['recall'][-1], 'f1_score': history.history['f1_score'][-1], 'auc': history.history['auc'][-1]}\n",
    "val_results = model.evaluate(val_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "test_results = model.evaluate(test_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "\n",
    "# Display results\n",
    "from utilities import display_side_by_side, create_evaluation_dataframe\n",
    "results_df = create_evaluation_dataframe(\n",
    "    model_name=\"Baseline Model\", variation=\"Weights | Grayscale=T | Contrast=F | Saturation=F | Adam=0.001\",\n",
    "    train_metrics=train_results, val_metrics=val_results, test_metrics=test_results, train_time=train_time\n",
    ")\n",
    "display_side_by_side(results_df, super_title=\"Model Evaluation Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3086b392",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5575d0",
   "metadata": {},
   "source": [
    "## **Weights | Grayscale=F | Contrast=T | Saturation=F**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf3a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model - Weights | Grayscale=F | Contrast=T | Saturation=F\n",
    "model = RareSpeciesCNN(\n",
    "    n_classes=n_classes, \n",
    "    apply_grayscale=False, \n",
    "    apply_contrast=True,                         \n",
    "    apply_saturation=False\n",
    ")\n",
    "\n",
    "# Build the model by providing an input shape\n",
    "inputs = Input(shape=(img_width, img_height, 3))        # Input shape\n",
    "_ = model.call(inputs)                                  # Call the model to build it\n",
    "model.summary()                                         # Print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cae109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.001, weight_decay=0.01, name=\"Optimizer\")\n",
    "loss = CategoricalCrossentropy(name=\"Loss\")\n",
    "metrics = [CategoricalAccuracy(name=\"accuracy\"), Precision(name=\"precision\"), Recall(name=\"recall\"), F1Score(average=\"macro\", name=\"f1_score\"), AUC(name=\"auc\")]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685fc126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "model_name = f\"RareSpeciesCNN_{datetime.datetime.now().strftime('%Y%m%d')}_WeightsContrast\"\n",
    "callbacks = [ModelCheckpoint(f\"./ModelCallbacks/checkpoint_{model_name}.keras\", monitor=\"val_loss\", save_best_only=True, verbose=0), CSVLogger(f\"./ModelCallbacks/metrics_{model_name}.csv\"), LearningRateScheduler(lambda epoch, lr: lr * 0.95), EarlyStopping(monitor='val_loss', patience=3, verbose=1)]\n",
    "\n",
    "# Train model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_datagen, batch_size=batch_size, epochs=10, validation_data=val_datagen, callbacks=callbacks, verbose=1, \n",
    "                    class_weight=class_weights)    # Pass class weights to the fit method\n",
    "train_time = round(time.time() - start_time, 2)\n",
    "print(f\"\\nTraining completed in \\033[1m{train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\\033[0m).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9271cfe4",
   "metadata": {},
   "source": [
    "#### **🧪 Model Selection & 📏 Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff70b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from utilities import plot_metrics\n",
    "plot_metrics(history, file_path=f\"./ModelsEvaluation/2_BaselineModel_TrainingValidationMetrics_{model_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3966299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation and test sets\n",
    "train_results = {'accuracy': history.history['accuracy'][-1], 'precision': history.history['precision'][-1], 'recall': history.history['recall'][-1], 'f1_score': history.history['f1_score'][-1], 'auc': history.history['auc'][-1]}\n",
    "val_results = model.evaluate(val_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "test_results = model.evaluate(test_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "\n",
    "# Display results\n",
    "from utilities import display_side_by_side, create_evaluation_dataframe\n",
    "results_df = create_evaluation_dataframe(\n",
    "    model_name=\"Baseline Model\", variation=\"Weights | Grayscale=F | Contrast=T | Saturation=F | Adam=0.001\",\n",
    "    train_metrics=train_results, val_metrics=val_results, test_metrics=test_results, train_time=train_time\n",
    ")\n",
    "display_side_by_side(results_df, super_title=\"Model Evaluation Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1512275",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1af494",
   "metadata": {},
   "source": [
    "## **Weights | Grayscale=F | Contrast=F | Saturation=T**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bce934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model - Weights | Grayscale=F | Contrast=F | Saturation=T\n",
    "model = RareSpeciesCNN(\n",
    "    n_classes=n_classes, \n",
    "    apply_grayscale=False, \n",
    "    apply_contrast=False,                         \n",
    "    apply_saturation=True\n",
    ")\n",
    "\n",
    "# Build the model by providing an input shape\n",
    "inputs = Input(shape=(img_width, img_height, 3))        # Input shape\n",
    "_ = model.call(inputs)                                  # Call the model to build it\n",
    "model.summary()                                         # Print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564ad3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.001, weight_decay=0.01, name=\"Optimizer\")\n",
    "loss = CategoricalCrossentropy(name=\"Loss\")\n",
    "metrics = [CategoricalAccuracy(name=\"accuracy\"), Precision(name=\"precision\"), Recall(name=\"recall\"), F1Score(average=\"macro\", name=\"f1_score\"), AUC(name=\"auc\")]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e15308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "model_name = f\"RareSpeciesCNN_{datetime.datetime.now().strftime('%Y%m%d')}_WeightsSaturation\"\n",
    "callbacks = [ModelCheckpoint(f\"./ModelCallbacks/checkpoint_{model_name}.keras\", monitor=\"val_loss\", save_best_only=True, verbose=0), CSVLogger(f\"./ModelCallbacks/metrics_{model_name}.csv\"), LearningRateScheduler(lambda epoch, lr: lr * 0.95), EarlyStopping(monitor='val_loss', patience=3, verbose=1)]\n",
    "\n",
    "# Train model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_datagen, batch_size=batch_size, epochs=10, validation_data=val_datagen, callbacks=callbacks, verbose=1, \n",
    "                    class_weight=class_weights)     # Pass class weights to the fit method\n",
    "train_time = round(time.time() - start_time, 2)\n",
    "print(f\"\\nTraining completed in \\033[1m{train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\\033[0m).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e851e605",
   "metadata": {},
   "source": [
    "#### **🧪 Model Selection & 📏 Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cd5c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from utilities import plot_metrics\n",
    "plot_metrics(history, file_path=f\"./ModelsEvaluation/2_BaselineModel_TrainingValidationMetrics_{model_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba643099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation and test sets\n",
    "train_results = {'accuracy': history.history['accuracy'][-1], 'precision': history.history['precision'][-1], 'recall': history.history['recall'][-1], 'f1_score': history.history['f1_score'][-1], 'auc': history.history['auc'][-1]}\n",
    "val_results = model.evaluate(val_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "test_results = model.evaluate(test_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "\n",
    "# Display results\n",
    "from utilities import display_side_by_side, create_evaluation_dataframe\n",
    "results_df = create_evaluation_dataframe(\n",
    "    model_name=\"Baseline Model\", variation=\"Weights | Grayscale=F | Contrast=F | Saturation=T | Adam=0.001\",\n",
    "    train_metrics=train_results, val_metrics=val_results, test_metrics=test_results, train_time=train_time,\n",
    "    csv_save_path= f\"./ModelsEvaluation/2_BaselineModel_TrainingValidationMetrics_{model_name}.csv\"\n",
    ")\n",
    "display_side_by_side(results_df, super_title=\"Model Evaluation Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d77537d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ea3f13",
   "metadata": {},
   "source": [
    "# **🥇 Best Model - Predictions Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43d84000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48480 files belonging to 202 classes.\n",
      "Found 1198 files belonging to 202 classes.\n",
      "Found 1199 files belonging to 202 classes.\n",
      "Train batch shape: (64, 224, 224, 3) (64, 202)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 16:08:56.199954: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 67108864 bytes after encountering the first element of size 67108864 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2025-04-13 16:08:56.200250: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 67108864 bytes after encountering the first element of size 67108864 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2025-04-13 16:08:56.331245: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-04-13 16:08:57.227139: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 67160576 bytes after encountering the first element of size 67160576 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2025-04-13 16:08:57.227239: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 67160576 bytes after encountering the first element of size 67160576 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val batch shape: (64, 224, 224, 3) (64, 202)\n",
      "Test batch shape: (64, 224, 224, 3) (64, 202)\n"
     ]
    }
   ],
   "source": [
    "# Import SMOTE training data\n",
    "train_DataAugmentationSMOTE_dir = Path(\"data/RareSpecies_Split/train_DataAugmentationSMOTE\")\n",
    "val_dir = Path(\"data/RareSpecies_Split/val\")\n",
    "test_dir = Path(\"data/RareSpecies_Split/test\")\n",
    "\n",
    "# train_DataAugmentationSMOTE_dir = Path(\"/content/RareSpecies_Split/train_DataAugmentationSMOTE\")\n",
    "# val_dir = Path(\"/content/RareSpecies_Split/val\")\n",
    "# test_dir = Path(\"/content/RareSpecies_Split/test\")\n",
    "\n",
    "# Import the image dataset from the directory\n",
    "train_DataAugmentationSMOTE_datagen, val_datagen, test_datagen = load_images_from_directory(train_DataAugmentationSMOTE_dir, val_dir, test_dir,\n",
    "                                                                      labels='inferred', label_mode='categorical',\n",
    "                                                                      class_names=class_names, color_mode='rgb',\n",
    "                                                                      batch_size=batch_size, image_size=image_size, seed=2025, \n",
    "                                                                      interpolation='bilinear', crop_to_aspect_ratio=False, pad_to_aspect_ratio=False)\n",
    "# Check the shape of the data (batch_size, img_width, img_height, 3)\n",
    "for x, y in train_DataAugmentationSMOTE_datagen.take(1):\n",
    "    print(\"Train batch shape:\", x.shape, y.shape)\n",
    "for x, y in val_datagen.take(1):\n",
    "    print(\"Val batch shape:\", x.shape, y.shape)\n",
    "for x, y in test_datagen.take(1):\n",
    "    print(\"Test batch shape:\", x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63012678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model by providing an input shape to load the best weights\n",
    "best_model = RareSpeciesCNN(\n",
    "    n_classes=n_classes, \n",
    "    apply_grayscale=False, \n",
    "    apply_contrast=False,                         \n",
    "    apply_saturation=False\n",
    ")\n",
    "\n",
    "inputs = Input(shape=(img_width, img_height, 3))   # Input shape\n",
    "best_model.build(inputs.shape)                          # Build the model\n",
    "\n",
    "# Load the best model weights (since we saved it during training - Callback > ModelCheckpoint > .keras)\n",
    "# Source: https://stackoverflow.com/questions/66138748/tensorflow-2-3-load-model-from-modelcheckpoint-callback-with-both-custom-layers\n",
    "best_model.load_weights(f\"./Collab/3_BaselineModel_Collab_CallbacksEvaluation_André_12.04.2025/content/ModelCallbacks/checkpoint_RareSpeciesCNN_20250413_SMOTE.keras\")\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001, weight_decay=0.01, name=\"Optimizer\")                                         # Adam for faster convergence\n",
    "loss = CategoricalCrossentropy(name=\"Loss\")                                                                        # Suitable for multi-class one-hot labels\n",
    "metrics = [CategoricalAccuracy(name=\"accuracy\"), Precision(name=\"precision\"), Recall(name=\"recall\"), F1Score(average=\"macro\", name=\"f1_score\"), AUC(name=\"auc\")]\n",
    "best_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation and test sets\n",
    "train_results = best_model.evaluate(train_DataAugmentationSMOTE_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "val_results = best_model.evaluate(val_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "test_results = best_model.evaluate(test_datagen, batch_size=batch_size, return_dict=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "from utilities import display_side_by_side, create_evaluation_dataframe\n",
    "results_df = create_evaluation_dataframe(\n",
    "    model_name=\"Best Model\", variation=\"SMOTE | Grayscale=F | Contrast=F | Saturation=F | Adam=0.001\",\n",
    "    train_metrics=train_results, val_metrics=val_results, test_metrics=test_results, train_time=None,\n",
    ")\n",
    "display_side_by_side(results_df, super_title=\"Model Evaluation Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edf458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the metrics\n",
    "from utilities import plot_metrics\n",
    "\n",
    "# Load the history from the CSV file\n",
    "history_csv_path = f\"./Collab/3_BaselineModel_Collab_CallbacksEvaluation_André_12.04.2025/content/ModelCallbacks/metrics_RareSpeciesCNN_20250413_SMOTE.csv\"\n",
    "history = pd.read_csv(history_csv_path)\n",
    "history.set_index('epoch', inplace=True)\n",
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252e6113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import plot_confusion_matrix\n",
    "\n",
    "# Plot confusion matrix for test set\n",
    "plot_confusion_matrix(\n",
    "    y_true=test_datagen.classes,\n",
    "    y_pred=model.predict(test_datagen, batch_size=batch_size),\n",
    "    title=\"Confusion Matrix | Best Baseline Model\",\n",
    "    # file_path=\"./ModelsEvaluation/3_TestConfusionMatrix_BestBaselineModel.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e2e827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 5 right and 5 wrong predictions\n",
    "from utilities import plot_predictions\n",
    "plot_predictions(\n",
    "    model=model,\n",
    "    data=test_datagen,\n",
    "    n_samples=5,\n",
    "    file_path=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b849b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddc8664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84b90a90",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba221ed",
   "metadata": {},
   "source": [
    "#### **🟨 Google Collab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e61c8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Google Collab Workspace\n",
    "# Source: https://stackoverflow.com/questions/48774285/how-to-download-file-created-in-colaboratory-workspace\n",
    "# !zip -r /content/ModelCallbacks.zip /content/ModelCallbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95a3689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !zip -r /content/ModelsEvaluation.zip /content/ModelsEvaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d79c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# files.download(\"/content/ModelCallbacks.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78b1efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files.download(\"/content/ModelsEvaluation.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dff3bdf66c1f233",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf218",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
