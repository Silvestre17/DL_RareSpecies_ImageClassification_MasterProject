{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1834cc3d7b582eb2",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center; justify-content: center; flex-wrap: wrap;\">\n",
    "    <div style=\"flex: 1; max-width: 400px; display: flex; justify-content: center;\">\n",
    "        <img src=\"https://i.ibb.co/JBPWVYR/Logo-Nova-IMS-Black.png\" style=\"max-width: 50%; height: auto; margin-top: 50px; margin-bottom: 50px;margin-left: 6rem;\">\n",
    "    </div>\n",
    "    <div style=\"flex: 2; text-align: center; margin-top: 20px;margin-left: 8rem;\">\n",
    "        <div style=\"font-size: 28px; font-weight: bold; line-height: 1.2;\">\n",
    "            <span style=\"color: #22c1c3;\">DL Project |</span> <span style=\"color: #08529C;\">Predicting Rare Species from Images using Deep Learning</span>\n",
    "        </div>\n",
    "        <div style=\"font-size: 17px; font-weight: bold; margin-top: 10px;\">\n",
    "            Spring Semester | 2024 - 2025\n",
    "        </div>\n",
    "        <div style=\"font-size: 17px; font-weight: bold;\">\n",
    "            Master in Data Science and Advanced Analytics\n",
    "        </div>\n",
    "        <div style=\"margin-top: 20px;\">\n",
    "            <div>Andr√© Silvestre, 20240502</div>\n",
    "            <div>Diogo Duarte, 20240525</div>\n",
    "            <div>Filipa Pereira, 20240509</div>\n",
    "            <div>Maria Cruz, 20230760</div>\n",
    "            <div>Umeima Mahomed, 20240543</div>\n",
    "        </div>\n",
    "        <div style=\"margin-top: 20px; font-weight: bold;\">\n",
    "            Group 37\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827c9197",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right, #22c1c3, #27b1dd, #2d9cfd, #090979); \n",
    "            padding: 1px; color: white; border-radius: 500px; text-align: center;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f603cf1cb0fd531",
   "metadata": {},
   "source": [
    "## **üìö Libraries Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c91174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install visualkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d062f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from typing_extensions import Self, Any      # For Python 3.10\n",
    "# from typing import Self, Any               # For Python >3.11\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Data manipulation imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Deep learning imports\n",
    "import tensorflow as tf\n",
    "from keras.ops import add\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import Model, Sequential, Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Rescaling, Lambda, BatchNormalization, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras import regularizers                                                                           # For L2 regularization\n",
    "import visualkeras\n",
    "\n",
    "# Evaluation imports\n",
    "from keras.metrics import CategoricalAccuracy, AUC, F1Score, Precision, Recall\n",
    "\n",
    "# Other imports\n",
    "from itertools import product\n",
    "\n",
    "# Set the style of the visualization\n",
    "pd.set_option('future.no_silent_downcasting', True)   # use int instead of float in DataFrame\n",
    "pd.set_option(\"display.max_columns\", None)            # display all columns\n",
    "\n",
    "# Disable warnings (FutureWarning)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4caae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8599eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd7d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000d4f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom module for importing data, visualization, and utilities\n",
    "import utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd16b3f",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right, #22c1c3, #27b1dd, #2d9cfd, #090979);\n",
    "            padding: 1px; color: white; border-radius: 500px; text-align: center;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5d91a720daf9a2",
   "metadata": {},
   "source": [
    "## **üßÆ Import Databases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87da922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in Google Collab to download the dataset already splitted\n",
    "# Source: https://stackoverflow.com/questions/25010369/wget-curl-large-file-from-google-drivez\n",
    "# Download the file from Google Drive using wget\n",
    "!wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate \\\n",
    "  \"https://drive.usercontent.google.com/download?id=11vkRJLP-re8E-8DWaoKeSuG66u64ez0J&export=download\" -O- | \\\n",
    "  sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p' > /tmp/confirm.txt\n",
    "\n",
    "# Read the confirmation token from the temporary file\n",
    "with open('/tmp/confirm.txt', 'r') as f:\n",
    "    confirm_token = f.read().strip()\n",
    "\n",
    "# Download the file using the confirmation token and cookies\n",
    "!wget --load-cookies /tmp/cookies.txt \\\n",
    "  \"https://drive.usercontent.google.com/download?id=11vkRJLP-re8E-8DWaoKeSuG66u64ez0J&export=download&confirm={confirm_token}\" \\\n",
    "  -O /content/RareSpecies_Split.zip\n",
    "\n",
    "# Clean up temporary files\n",
    "!rm /tmp/cookies.txt /tmp/confirm.txt\n",
    "\n",
    "# List files in the /content directory to verify the download\n",
    "!ls -lh /content/\n",
    "\n",
    "# Unzip the downloaded file\n",
    "!unzip /content/RareSpecies_Split.zip -d /content/\n",
    "\n",
    "# List the unzipped files to verify\n",
    "!ls -lh /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5977e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data (for Google Collab)\n",
    "train_dir = Path(\"/content/RareSpecies_Split/train\")\n",
    "val_dir = Path(\"/content/RareSpecies_Split/val\")\n",
    "test_dir = Path(\"/content/RareSpecies_Split/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ebe4da",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right,rgb(255, 252, 58),rgb(253, 173, 45),rgb(190, 64, 5),rgb(190, 64, 5));\n",
    "            padding: 1px; color: black; border-radius: 500px; text-align: left;\">\n",
    "\n",
    "image_size = (384, 384)   # EfficientNetV2S input size <br>\n",
    "batch_size = 24           # Reduced batch size - EfficientNetV2S is memory intensive <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67729e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Generators\n",
    "n_classes = 202                                     # Number of classes (we already know this based on previous notebook)\n",
    "image_size = (384, 384)                             # Image size (384x384)\n",
    "img_height, img_width = image_size                  # Image dimensions\n",
    "batch_size = 24                                     # Batch size\n",
    "input_shape = (img_height, img_width, 3)            # Input shape of the model\n",
    "value_range = (0.0, 1.0)                            # Range of pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35db967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names from directory\n",
    "class_names = sorted(os.listdir(train_dir))\n",
    "class_indices = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "# Import the image dataset from the directory\n",
    "from utilities import load_images_from_directory\n",
    "train_datagen, val_datagen, test_datagen = load_images_from_directory(train_dir, val_dir, test_dir,\n",
    "                                                                      labels='inferred', label_mode='categorical',\n",
    "                                                                      class_names=class_names, color_mode='rgb',\n",
    "                                                                      batch_size=batch_size, image_size=image_size, seed=2025,\n",
    "                                                                      interpolation='bilinear', crop_to_aspect_ratio=False, pad_to_aspect_ratio=False)\n",
    "\n",
    "print(f\"\\nLoaded: Train ({train_datagen.cardinality().numpy() * batch_size}), \"\n",
    "        f\"Val ({val_datagen.cardinality().numpy() * batch_size}), \"\n",
    "        f\"Test ({test_datagen.cardinality().numpy() * batch_size})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d68553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the data (batch_size, img_width, img_height, 3)\n",
    "for x, y in train_datagen.take(1):\n",
    "    print(\"Train batch shape:\", x.shape, y.shape)\n",
    "for x, y in val_datagen.take(1):\n",
    "    print(\"Val batch shape:\", x.shape, y.shape)\n",
    "for x, y in test_datagen.take(1):\n",
    "    print(\"Test batch shape:\", x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f158b792ebd291",
   "metadata": {},
   "source": [
    "# <a class='anchor' id='3'></a>\n",
    "<br>\n",
    "<style>\n",
    "@import url('https://fonts.cdnfonts.com/css/avenir-next-lt-pro?styles=29974');\n",
    "</style>\n",
    "\n",
    "<div style=\"background: linear-gradient(to right, #22c1c3, #27b1dd, #2d9cfd, #090979); \n",
    "            padding: 10px; color: white; border-radius: 300px; text-align: center;\">\n",
    "    <center><h1 style=\"margin-left: 140px;margin-top: 10px; margin-bottom: 4px; color: white;\n",
    "                       font-size: 32px; font-family: 'Avenir Next LT Pro', sans-serif;\">\n",
    "        <b>3 | Modeling - EfficientNetV2S</b></h1></center>\n",
    "</div>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<center><img src=\"\" style=\"width: 700px\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660022cf",
   "metadata": {},
   "source": [
    "`EfficientNetV2S` is a member of the `EfficientNetV2` family, an enhanced version of the original `EfficientNet` models. It's known for balancing speed and accuracy. The \"S\" indicates its size (small).\n",
    "Key improvements include:\n",
    "\n",
    "`Progressive Learning`: Gradually increasing image size and regularization during training; <br>\n",
    "`Efficient Architecture`: Using a combination of MBConv and faster Fused-MBConv blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0da3b2",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right,rgb(255, 252, 58),rgb(253, 173, 45),rgb(190, 64, 5),rgb(190, 64, 5));\n",
    "            padding: 0px; color: black; border-radius: 5px; text-align: left;\">\n",
    "\n",
    "4 par√¢metros: <br>\n",
    "weights='imagenet'/=None/='path' <br>\n",
    "include_top=False <br>\n",
    "input_shape=input_shape<br>\n",
    "pooling='avg'/='max'/None <br><br>\n",
    "\n",
    "Ir testando o dropout\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26312ae5b0368022",
   "metadata": {},
   "source": [
    "# **üí° Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3556121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications import EfficientNetV2S\n",
    "\n",
    "# # Load pre-trained EfficientNetV2S\n",
    "# EfficientNet_model = EfficientNetV2S(\n",
    "#     weights='imagenet',  # Initializes the model with weights pre-trained on ImageNet (crucial for transfer learning)\n",
    "#     ### strong starting point, allows to learn faster and often perform better, especially with limited data\n",
    "#     ### Alternatives:\n",
    "#     ### weights=None: Starts with random initialization. Useful if you're not doing transfer learning and want to train from scratch\n",
    "#     ### weights='path/to/weights.h5': Loads weights from a specific file. Useful if you have custom pre-trained weights or want to resume training from a checkpoint.\n",
    "#     include_top=False,  # Removes the classification layer (designed for 1000 classes)\n",
    "#     input_shape=input_shape, #Input Shape adjusted for EfficientNetV2S (RGB images of size 384x384)\n",
    "#     pooling='avg'  # Use average pooling after the convolutional layers to reduce dimensionality before passing to the fully connected layers\n",
    "#     ### prevents overfitting by reducing the number of parameters in the model\n",
    "#     ### creates a more robust representation of the input data\n",
    "#     ### Alternatives:\n",
    "#     ### pooling='max': Uses max pooling instead of average pooling. This can be useful if you want to retain the most prominent features from the feature maps.\n",
    "#     ### pooling=None: No pooling is applied. This means the output will be the raw feature maps from the last convolutional layer. This increase the computational cost\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# # Freeze the weights of the pre-trained EfficientNet model\n",
    "# ### TRANSFER LEARNING(especially when you have limited data):\n",
    "# ### weights in these layers will not be updated during training\n",
    "# ### It allows you to leverage the knowledge learned from ImageNet without risking overfitting to your smaller dataset\n",
    "# ### ---------------------------------------------------------------------------\n",
    "# ###  You might choose to unfreeze some or all of these layers later (FINE-TUNING) for better performance once the custom head is trained\n",
    "# EfficientNet_model.trainable = False #Freezing base model. We might want to unfreeze it later on after training the top layers\n",
    "\n",
    "\n",
    "# # Create a new model on top\n",
    "# inputs = keras.Input(shape=input_shape) #define the input layer (tuple:H,W,C) of your new model\n",
    "\n",
    "\n",
    "# ### passing the input tensor through the pre-trained EfficientNet\n",
    "# ### -------------------------------------------------------------------\n",
    "# ### training=False ensures that the Batch Normalization layers within EfficientNet behave in inference mode.??????????? Batch Normalization calculates statistics differently during training and inference\n",
    "# ### If training=True (even with the model frozen), the Batch Normalization layers would recalculate and update their internal statistics based on your smaller training dataset, potentially hurting performance\n",
    "# x = EfficientNet_model(inputs, training=False) #Important to set training to False to avoid updating weights when extracting features\n",
    "\n",
    "\n",
    "# ### This adds a dropout layer after the EfficientNet\n",
    "# ### Dropout is a regularization technique that randomly sets a fraction of the input units to 0 during training. This helps prevent overfitting by reducing the model's reliance on any single neuron\n",
    "# x = keras.layers.Dropout(0.2)(x) #Regularization (Dropout)\n",
    "\n",
    "\n",
    "# # We removed the first dense layer since average pooling creates a good enough output to only require one more fully-connected layer\n",
    "# ### Create the classification head of your model --> dense (fully connected) layer with n_classes output units (one for each species you want to classify)\n",
    "# ### ----------------------------------------------------------------------------------------------------------------------------------\n",
    "# ### Softmax activation function ensures that the outputs are probabilities that sum to 1\n",
    "# outputs = keras.layers.Dense(n_classes, activation=\"softmax\")(x)\n",
    "\n",
    "\n",
    "\n",
    "# # Creates the Keras model, specifying the inputs and outputs tensors\n",
    "# model = keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d1a639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetV2S\n",
    "\n",
    "\n",
    "class RareSpeciesEfficientNet(Model):\n",
    "    def __init__(self, n_classes=202, freeze_base=True):  # Add freeze_base argument\n",
    "        \n",
    "        super().__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.freeze_base = freeze_base\n",
    "\n",
    "        self.rescale_layer = Rescaling(scale=1.0 / 255.0, name=\"Rescale_Layer\")\n",
    "\n",
    "        self.base_model = EfficientNetV2S(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=input_shape,\n",
    "            pooling='avg'  # Important for feature extraction\n",
    "        )\n",
    "\n",
    "        self.base_model.trainable = not freeze_base #Freeze or unfreeze based on constructor argument\n",
    "\n",
    "\n",
    "        self.dropout1 = Dropout(0.2)\n",
    "        self.dense1 = Dense(128, activation='relu')\n",
    "        self.bn_dense1 = BatchNormalization()\n",
    "        self.dropout2 = Dropout(0.5)\n",
    "        self.dense_output = Dense(n_classes, activation='softmax')\n",
    "\n",
    "\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.rescale_layer(inputs)\n",
    "        x = self.base_model(x, training=False) \n",
    "        x = self.dropout1(x, training=training)  # Regularization after EfficientNet\n",
    "\n",
    "        x = self.dense1(x)\n",
    "        x = self.bn_dense1(x, training=training)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        outputs = self.dense_output(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d2d901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "model = RareSpeciesEfficientNet(n_classes=n_classes, freeze_base=True)  # Start with frozen base\n",
    "inputs = Input(shape=input_shape)    \n",
    "_ = model.call(inputs) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5ea20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----FEATURE EXTRACTION-----#\n",
    "optimizer = Adam(learning_rate=0.001, weight_decay=0.01, name=\"Optimizer\")\n",
    "\n",
    "loss = CategoricalCrossentropy(name=\"Loss\")\n",
    "\n",
    "metrics = [CategoricalAccuracy(name=\"accuracy\"),\n",
    "           Precision(name=\"precision\"), \n",
    "           Recall(name=\"recall\"),\n",
    "           F1Score(average=\"macro\", name=\"f1_score\"),\n",
    "           AUC(name=\"auc\")]\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3414f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "\n",
    "model_name = f\"RareSpeciesEfficientNet_FeatureExtraction_{datetime.datetime.now().strftime('%Y%m%d')}\" \n",
    "callbacks = [\n",
    "    ModelCheckpoint(f\"./ModelCallbacks/checkpoint_{model_name}.keras\", monitor=\"val_loss\", save_best_only=True, verbose=0),\n",
    "    CSVLogger(f\"./ModelCallbacks/metrics_{model_name}.csv\"),\n",
    "    LearningRateScheduler(lambda epoch, lr: lr * 0.95),\n",
    "    EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5979e860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_datagen, batch_size = batch_size, epochs=10, validation_data=val_datagen, callbacks=callbacks, verbose=1)\n",
    "train_time = round(time.time() - start_time, 2)\n",
    "\n",
    "print(f\"\\nTraining completed in \\033[1m{train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\\033[0m).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc4c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----FINE-TUNING-----#\n",
    "\n",
    "model.base_model.trainable = True # Unfreeze the EfficientNet base\n",
    "model.summary(show_trainable=True)  # Show that layers are now trainable\n",
    "\n",
    "# Compile model\n",
    "optimizer_fine_tune = tf.keras.optimizers.Adam(1e-5)  # Lower learning rate for fine-tuning\n",
    "model.compile(optimizer=optimizer_fine_tune, loss=loss, metrics=metrics) # Recompile with new optimizer\n",
    "\n",
    "\n",
    "\n",
    "model_name = f\"RareSpeciesEfficientNet_FineTuning_{datetime.datetime.now().strftime('%Y%m%d')}\"  # Update model name\n",
    "callbacks_finetune = [ # New callbacks for fine-tuning (potentially different patience, etc.)\n",
    "    ModelCheckpoint(f\"./ModelCallbacks/checkpoint_{model_name}.keras\", monitor=\"val_loss\", save_best_only=True, verbose=0),\n",
    "    CSVLogger(f\"./ModelCallbacks/metrics_{model_name}.csv\"),\n",
    "    EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True) # Possibly lower patience for fine-tuning\n",
    "]\n",
    "\n",
    "\n",
    "history_fine_tuning = model.fit(\n",
    "    train_datagen, batch_size=batch_size, epochs=5,\n",
    "    validation_data=val_datagen, callbacks=callbacks_finetune, verbose=1\n",
    ") # Fine-tune the whole model\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ba13c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e321bb15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9c053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for saving the model and logs\n",
    "model_name = f\"RareSpeciesEfficientNet_{datetime.datetime.now().strftime('%Y%m%d')}\"                                                                             # Model name\n",
    "print(f\"\\n\\033[1mModel name:\\033[0m {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693df776",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load pre-trained EfficientNetV2S\n",
    "EfficientNet_model = EfficientNetV2S(\n",
    "    weights='imagenet',  # Initializes the model with weights pre-trained on ImageNet (crucial for transfer learning)\n",
    "    include_top=False,  # Do not include the ImageNet classifier at the top (it was made for 1000 classes)\n",
    "    input_shape=input_shape, #Input Shape adjusted for EfficientNetV2S\n",
    "    pooling='avg'  # Use average pooling to reduce dimensionality\n",
    ")\n",
    "\n",
    "# Freeze the base model's layers\n",
    "EfficientNet_model.trainable = False #Freezing base model. We might want to unfreeze it later on after training the top layers\n",
    "\n",
    "# Create a new model on top\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "x = EfficientNet_model(inputs, training=False) #Important to set training to False to avoid updating weights when extracting features\n",
    "\n",
    "x = keras.layers.Dropout(0.2)(x) #Regularization (Dropout)\n",
    "# We removed the first dense layer since average pooling creates a good enough output to only require one more fully-connected layer\n",
    "outputs = keras.layers.Dense(n_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391168a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the model architecture\n",
    "# Source: https://www.kaggle.com/code/devsubhash/visualize-deep-learning-models-using-visualkeras\n",
    "visualkeras.layered_view(model,\n",
    "                         legend=True,\n",
    "                         show_dimension=True,\n",
    "                         scale_xy=1,                                        # Adjust the scale of the image\n",
    "                        #  scale_z=1,\n",
    "                         # to_file='./BaselineModel_Architecture.png',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200e3c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.001, weight_decay=0.001, name=\"Optimizer\") #Decreased weight decay for better performance with transfer learning\n",
    "loss = CategoricalCrossentropy(name=\"Loss\")       \n",
    "metrics = [CategoricalAccuracy(name=\"accuracy\"), Precision(name=\"precision\"), Recall(name=\"recall\"),\n",
    "           F1Score(average=\"macro\", name=\"f1_score\"), AUC(name=\"auc\")]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795aec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for saving the model and logs\n",
    "model_name = f\"EfficientNetV2S_{datetime.datetime.now().strftime('%Y%m%d')}\"                                                                             # Model name\n",
    "print(f\"\\n\\033[1mModel name:\\033[0m {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052f914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "model_name = f\"EfficientNetV2S_{datetime.datetime.now().strftime('%Y%m%d')}_EfficientNetV2S\"                                       # Model name\n",
    "callbacks = [\n",
    "    ModelCheckpoint(f\"./ModelCallbacks/checkpoint_{model_name}.keras\", monitor=\"val_loss\", save_best_only=True, verbose=0), \n",
    "    CSVLogger(f\"./ModelCallbacks/metrics_{model_name}.csv\"),\n",
    "    LearningRateScheduler(lambda epoch, lr: lr * 0.95), #Change learning rate for better convergence\n",
    "    EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43da0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_datagen, batch_size = batch_size, epochs=10, validation_data=val_datagen, callbacks=callbacks, verbose=1)\n",
    "train_time = round(time.time() - start_time, 2)\n",
    "\n",
    "print(f\"\\nTraining completed in \\033[1m{train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\\033[0m).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f48a4f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204995d589f8431f",
   "metadata": {},
   "source": [
    "### <a class='anchor' id='3_1'></a> <a class='anchor' id='3_2'></a>  **üß™ Model Selection & üìè Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ffc2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from utilities import plot_metrics\n",
    "\n",
    "os.makedirs(\"./ModelsEvaluation\", exist_ok=True)                                              # Create directory if it doesn't exist\n",
    "plot_metrics(history, file_path=f\"./ModelsEvaluation/2_Training_Validation_Metrics_{datetime.datetime.now().strftime('%Y%m%d')}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632582b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation and test sets\n",
    "train_results = {'accuracy': history.history['accuracy'][-1], 'precision': history.history['precision'][-1], 'recall': history.history['recall'][-1], 'f1_score': history.history['f1_score'][-1], 'auc': history.history['auc'][-1]}\n",
    "val_results = model.evaluate(val_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "test_results = model.evaluate(test_datagen, batch_size=batch_size, return_dict=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea96d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "from utilities import display_side_by_side, create_evaluation_dataframe\n",
    "results_df = create_evaluation_dataframe(\n",
    "    model_name=\"Baseline Model\",\n",
    "    variation=\"Original | Grayscale=F | Contrast=F | Saturation=F | Adam=0.001\",           # Dataset | Grayscale | Contrast | Saturation | Optimizer=Learning Rate\n",
    "    train_metrics=train_results, val_metrics=val_results, test_metrics=test_results, train_time=train_time,\n",
    "    csv_save_path= f\"./ModelsEvaluation/2_BaselineModel_TrainingValidationMetrics_{model_name}.csv\"      # Save the results to a CSV file\n",
    ")\n",
    "display_side_by_side(results_df, super_title=\"Model Evaluation Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b90a90",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e61c8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95a3689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dff3bdf66c1f233",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a5816b",
   "metadata": {},
   "source": [
    "# **üîó Bibliography/References**\n",
    "\n",
    "**[[1]](https://)** AAAAAAAAAA\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
