{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 16:41:07.402814: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-10 16:41:07.411380: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741624867.421361   98474 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741624867.424062   98474 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-10 16:41:07.434292: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Library imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.18.0\n",
      "Is TensorFlow built with CUDA? True\n",
      "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU Device Name: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741624869.540112   98474 gpu_device.cc:2022] Created device /device:GPU:0 with 9558 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"Is TensorFlow built with CUDA?\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"GPU Device Name:\", tf.test.gpu_device_name())\n",
    "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (11983, 7)\n",
      "Dataset columns: Index(['rare_species_id', 'eol_content_id', 'eol_page_id', 'kingdom', 'phylum',\n",
      "       'family', 'file_path'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "\n",
    "dataset = pd.read_csv('rare_species 1/metadata.csv')\n",
    "\n",
    "# Display the first few rows and columns of the dataset\n",
    "\n",
    "print(\"Dataset shape:\", dataset.shape)\n",
    "print(\"Dataset columns:\", dataset.columns)\n",
    "\n",
    "# EOL means Encyclopedia of Life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the features and the target variable\n",
    "\n",
    "X = dataset.iloc[:, 1:5].values  # Select features, excluding 'rare_species_id' and 'file_path'\n",
    "y = dataset.iloc[:, 5].values   # 'family' column as the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eol_content_id unique values: 11983\n",
      "eol_page_id unique values: 400\n",
      "kingdom unique values: 1\n",
      "phylum unique values: 5\n",
      "family unique values: 202\n"
     ]
    }
   ],
   "source": [
    "# Check the unique values of the columns,\n",
    "# seeing which can be one-hot encoded\n",
    "\n",
    "#print(dataset['rare_species_id'].unique())\n",
    "print(\"eol_content_id unique values:\", dataset['eol_content_id'].nunique())\n",
    "print(\"eol_page_id unique values:\", dataset['eol_page_id'].nunique())\n",
    "print(\"kingdom unique values:\", dataset['kingdom'].nunique())\n",
    "print(\"phylum unique values:\", dataset['phylum'].nunique())\n",
    "\n",
    "print(\"family unique values:\", dataset['family'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phylum unique values: ['mollusca' 'chordata' 'arthropoda' 'echinodermata' 'cnidaria']\n"
     ]
    }
   ],
   "source": [
    "# Display 'phylum' unique values\n",
    "print(\"phylum unique values:\", dataset['phylum'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kingdom unique values: ['animalia']\n"
     ]
    }
   ],
   "source": [
    "# Display 'kingdom' unique values\n",
    "print(\"kingdom unique values:\", dataset['kingdom'].unique())\n",
    "\n",
    "# Do we really need the 'kingdom' column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12853737 449393 'animalia' 'mollusca']\n",
      " [20969394 793083 'animalia' 'chordata']\n",
      " [28895411 319982 'animalia' 'chordata']\n",
      " [29658536 45510188 'animalia' 'chordata']\n",
      " [21252576 7250886 'animalia' 'chordata']]\n"
     ]
    }
   ],
   "source": [
    "print(X[:5])  # Display the first 5 rows of X to identify the correct indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 0.0 1.0 12853737 449393 'animalia']\n",
      " [1.0 0.0 0.0 0.0 20969394 793083 'animalia']\n",
      " [1.0 0.0 0.0 0.0 28895411 319982 'animalia']\n",
      " [1.0 0.0 0.0 0.0 29658536 45510188 'animalia']\n",
      " [1.0 0.0 0.0 0.0 21252576 7250886 'animalia']]\n"
     ]
    }
   ],
   "source": [
    "# Transforming categorical data into numerical data\n",
    "ct = ColumnTransformer(\n",
    "    [('one_hot_encoder', OneHotEncoder(drop=\"first\"), [3])],  # Only 'phylum' column\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "# Display the transformed feature set\n",
    "print(X[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
