{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1834cc3d7b582eb2",
      "metadata": {
        "id": "1834cc3d7b582eb2"
      },
      "source": [
        "<div style=\"display: flex; align-items: center; justify-content: center; flex-wrap: wrap;\">\n",
        "    <div style=\"flex: 1; max-width: 400px; display: flex; justify-content: center;\">\n",
        "        <img src=\"https://i.ibb.co/JBPWVYR/Logo-Nova-IMS-Black.png\" style=\"max-width: 50%; height: auto; margin-top: 50px; margin-bottom: 50px;margin-left: 6rem;\">\n",
        "    </div>\n",
        "    <div style=\"flex: 2; text-align: center; margin-top: 20px;margin-left: 8rem;\">\n",
        "        <div style=\"font-size: 28px; font-weight: bold; line-height: 1.2;\">\n",
        "            <span style=\"color: #22c1c3;\">DL Project |</span> <span style=\"color: #08529C;\">Predicting Rare Species from Images using Deep Learning</span>\n",
        "        </div>\n",
        "        <div style=\"font-size: 17px; font-weight: bold; margin-top: 10px;\">\n",
        "            Spring Semester | 2024 - 2025\n",
        "        </div>\n",
        "        <div style=\"font-size: 17px; font-weight: bold;\">\n",
        "            Master in Data Science and Advanced Analytics\n",
        "        </div>\n",
        "        <div style=\"margin-top: 20px;\">\n",
        "            <div>André Silvestre, 20240502</div>\n",
        "            <div>Diogo Duarte, 20240525</div>\n",
        "            <div>Filipa Pereira, 20240509</div>\n",
        "            <div>Maria Cruz, 20230760</div>\n",
        "            <div>Umeima Mahomed, 20240543</div>\n",
        "        </div>\n",
        "        <div style=\"margin-top: 20px; font-weight: bold;\">\n",
        "            Group 37\n",
        "        </div>\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "827c9197",
      "metadata": {
        "id": "827c9197"
      },
      "source": [
        "<div style=\"background: linear-gradient(to right, #22c1c3, #27b1dd, #2d9cfd, #090979);\n",
        "            padding: 1px; color: white; border-radius: 500px; text-align: center;\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f603cf1cb0fd531",
      "metadata": {
        "id": "7f603cf1cb0fd531"
      },
      "source": [
        "## **📚 Libraries Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "E2Awz5RdfEk8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2Awz5RdfEk8",
        "outputId": "ec595009-fa82-470b-e111-d75f4da6fd3b"
      },
      "outputs": [],
      "source": [
        "# !pip install visualkeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9c91174e",
      "metadata": {
        "id": "9c91174e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-11 12:17:33.229800: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744370253.248429   10457 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744370253.253607   10457 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1744370253.269875   10457 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1744370253.269912   10457 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1744370253.269914   10457 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1744370253.269916   10457 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-04-11 12:17:33.275045: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "# System imports\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "from typing_extensions import Self, Any      # For Python 3.10\n",
        "# from typing import Self, Any               # For Python >3.11\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Data manipulation imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Data visualization imports\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Deep learning imports\n",
        "import tensorflow as tf\n",
        "from keras.ops import add\n",
        "from keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras import Model, Sequential, Input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, EarlyStopping\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Rescaling, Lambda\n",
        "import visualkeras\n",
        "\n",
        "# Evaluation imports\n",
        "from keras.metrics import CategoricalAccuracy, AUC, F1Score, Precision, Recall\n",
        "\n",
        "# Other imports\n",
        "from itertools import product\n",
        "\n",
        "# Set the style of the visualization\n",
        "pd.set_option('future.no_silent_downcasting', True)   # use int instead of float in DataFrame\n",
        "pd.set_option(\"display.max_columns\", None)            # display all columns\n",
        "\n",
        "# Disable warnings (FutureWarning)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(2025)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9f0d56ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f0d56ec",
        "outputId": "ca08852e-48bf-4b6f-d7ca-d23f56cf761e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow Version: 2.19.0\n",
            "Is TensorFlow built with CUDA? True\n",
            "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "GPU Device Name: /device:GPU:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1744370256.124663   10457 gpu_device.cc:2019] Created device /device:GPU:0 with 3586 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "print(\"TensorFlow Version:\", tf.__version__)\n",
        "print(\"Is TensorFlow built with CUDA?\", tf.test.is_built_with_cuda())\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
        "print(\"GPU Device Name:\", tf.test.gpu_device_name())                                # (if error in Google Colab: Make sure your Hardware accelerator is set to GPU.\n",
        "                                                                                    # Runtime > Change runtime type > Hardware Accelerator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b0d96104",
      "metadata": {
        "id": "b0d96104"
      },
      "outputs": [],
      "source": [
        "# Extra: https://www.tensorflow.org/api_docs/python/tf/config/experimental/set_memory_growth\n",
        "# If you’re using a GPU, TensorFlow might pre-allocate GPU memory, leaving less for CPU operations.\n",
        "# Enabling memory growth lets the GPU allocate only what’s needed.\n",
        "if tf.test.is_built_with_cuda():\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b1e0633b",
      "metadata": {
        "id": "b1e0633b"
      },
      "outputs": [],
      "source": [
        "# Import custom module for importing data, visualization, and utilities\n",
        "import utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcb366e4",
      "metadata": {
        "id": "bcb366e4"
      },
      "source": [
        "<div style=\"background: linear-gradient(to right, #22c1c3, #27b1dd, #2d9cfd, #090979);\n",
        "            padding: 1px; color: white; border-radius: 500px; text-align: center;\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a5d91a720daf9a2",
      "metadata": {
        "id": "4a5d91a720daf9a2"
      },
      "source": [
        "## **🧮 Import Databases**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5a69d2c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a69d2c3",
        "outputId": "7d494fd7-2440-4108-ccfb-fe674b41e315"
      },
      "outputs": [],
      "source": [
        "# # Run in Google Collab to download the dataset already splitted\n",
        "# # Source: https://stackoverflow.com/questions/25010369/wget-curl-large-file-from-google-drivez\n",
        "# # Download the file from Google Drive using wget\n",
        "# !wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate \\\n",
        "#   \"https://drive.usercontent.google.com/download?id=11vkRJLP-re8E-8DWaoKeSuG66u64ez0J&export=download\" -O- | \\\n",
        "#   sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p' > /tmp/confirm.txt\n",
        "\n",
        "# # Read the confirmation token from the temporary file\n",
        "# with open('/tmp/confirm.txt', 'r') as f:\n",
        "#     confirm_token = f.read().strip()\n",
        "\n",
        "# # Download the file using the confirmation token and cookies\n",
        "# !wget --load-cookies /tmp/cookies.txt \\\n",
        "#   \"https://drive.usercontent.google.com/download?id=11vkRJLP-re8E-8DWaoKeSuG66u64ez0J&export=download&confirm={confirm_token}\" \\\n",
        "#   -O /content/RareSpecies_Split.zip\n",
        "\n",
        "# # Clean up temporary files\n",
        "# !rm /tmp/cookies.txt /tmp/confirm.txt\n",
        "\n",
        "# # List files in the /content directory to verify the download\n",
        "# !ls -lh /content/\n",
        "\n",
        "# # Unzip the downloaded file\n",
        "# !unzip /content/RareSpecies_Split.zip -d /content/\n",
        "\n",
        "# # List the unzipped files to verify\n",
        "# !ls -lh /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b87da922",
      "metadata": {
        "id": "b87da922"
      },
      "outputs": [],
      "source": [
        "# Define the path to the data\n",
        "train_dir = Path(\"data/RareSpecies_Split/train\")\n",
        "val_dir = Path(\"data/RareSpecies_Split/val\")\n",
        "test_dir = Path(\"data/RareSpecies_Split/test\")\n",
        "\n",
        "# For Google Collab\n",
        "# train_dir = Path(\"/content/RareSpecies_Split/train\")\n",
        "# val_dir = Path(\"/content/RareSpecies_Split/val\")\n",
        "# test_dir = Path(\"/content/RareSpecies_Split/test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5977e7e9",
      "metadata": {
        "id": "5977e7e9"
      },
      "outputs": [],
      "source": [
        "# Image Generators\n",
        "n_classes = 202                                     # Number of classes (we already know this based on previous notebook)\n",
        "image_size = (224, 224)                             # Image size (224x224)\n",
        "img_height, img_width = image_size                  # Image dimensions\n",
        "batch_size = 32                                     # Batch size\n",
        "input_shape = (img_height, img_width, 3)            # Input shape of the model\n",
        "value_range = (0.0, 1.0)                            # Range of pixel values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c6686885",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6686885",
        "outputId": "e6bb4d7c-04ec-4514-b6f2-6e0801fbf9e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 9586 files belonging to 202 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1744370257.322203   10457 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3586 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1198 files belonging to 202 classes.\n",
            "Found 1199 files belonging to 202 classes.\n",
            "\n",
            "Loaded: Train (9600), Val (1216), Test (1216)\n"
          ]
        }
      ],
      "source": [
        "# Get class names from directory\n",
        "class_names = sorted(os.listdir(train_dir))\n",
        "class_indices = {name: i for i, name in enumerate(class_names)}\n",
        "\n",
        "# Import the image dataset from the directory\n",
        "from utilities import load_images_from_directory\n",
        "train_datagen, val_datagen, test_datagen = load_images_from_directory(train_dir, val_dir, test_dir,\n",
        "                                                                      labels='inferred', label_mode='categorical',\n",
        "                                                                      class_names=class_names, color_mode='rgb',\n",
        "                                                                      batch_size=batch_size, image_size=image_size, seed=2025,\n",
        "                                                                      interpolation='bilinear', crop_to_aspect_ratio=False, pad_to_aspect_ratio=False)\n",
        "\n",
        "print(f\"\\nLoaded: Train ({train_datagen.cardinality().numpy() * batch_size}), \"\n",
        "        f\"Val ({val_datagen.cardinality().numpy() * batch_size}), \"\n",
        "        f\"Test ({test_datagen.cardinality().numpy() * batch_size})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "83cbf32e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83cbf32e",
        "outputId": "1dde1e33-9ed5-4101-a45f-6ba65f55c5a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train batch shape: (32, 224, 224, 3) (32, 202)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-11 12:17:39.243418: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val batch shape: (32, 224, 224, 3) (32, 202)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-11 12:17:39.680507: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test batch shape: (32, 224, 224, 3) (32, 202)\n"
          ]
        }
      ],
      "source": [
        "# Check the shape of the data (batch_size, img_width, img_height, 3)\n",
        "for x, y in train_datagen.take(1):\n",
        "    print(\"Train batch shape:\", x.shape, y.shape)\n",
        "for x, y in val_datagen.take(1):\n",
        "    print(\"Val batch shape:\", x.shape, y.shape)\n",
        "for x, y in test_datagen.take(1):\n",
        "    print(\"Test batch shape:\", x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61f158b792ebd291",
      "metadata": {
        "id": "61f158b792ebd291"
      },
      "source": [
        "# <a class='anchor' id='3'></a>\n",
        "<br>\n",
        "<style>\n",
        "@import url('https://fonts.cdnfonts.com/css/avenir-next-lt-pro?styles=29974');\n",
        "</style>\n",
        "\n",
        "<div style=\"background: linear-gradient(to right, #22c1c3, #27b1dd, #2d9cfd, #090979);\n",
        "            padding: 10px; color: white; border-radius: 300px; text-align: center;\">\n",
        "    <center><h1 style=\"margin-left: 140px;margin-top: 10px; margin-bottom: 4px; color: white;\n",
        "                       font-size: 32px; font-family: 'Avenir Next LT Pro', sans-serif;\">\n",
        "        <b>3 | Modeling - Baseline Model</b></h1></center>\n",
        "</div>\n",
        "\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26312ae5b0368022",
      "metadata": {
        "id": "26312ae5b0368022"
      },
      "source": [
        "# **💡 Modeling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "mkWC6m64Tkt6",
      "metadata": {
        "id": "mkWC6m64Tkt6"
      },
      "outputs": [],
      "source": [
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b3556121",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "b3556121",
        "outputId": "3d2e5098-f515-4499-a223-a24b754023ba"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"rare_species_cnn\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"rare_species_cnn\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ Rescale_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ vgg19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,024,384</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ GlobalAvgPool                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Output_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">103,626</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ Rescale_Layer (\u001b[38;5;33mRescaling\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ vgg19 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m20,024,384\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ GlobalAvgPool                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Output_Layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m202\u001b[0m)            │       \u001b[38;5;34m103,626\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,128,010</span> (76.78 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,128,010\u001b[0m (76.78 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">103,626</span> (404.79 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m103,626\u001b[0m (404.79 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,024,384</span> (76.39 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,024,384\u001b[0m (76.39 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from keras.applications import VGG19\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "# Baseline Model\n",
        "class RareSpeciesCNN(Model):\n",
        "    \"\"\"Custom CNN for rare species classification.\n",
        "\n",
        "    Architecture: Simple CNN\n",
        "    Why: Small model to establish baseline, avoiding overfitting on 202 classes.\n",
        "    Alternatives: Deeper CNNs (e.g., ResNet) or transfer learning (e.g., EfficientNet).\n",
        "    Allows selection of preprocessing steps like grayscale, contrast, and saturation adjustment.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_classes=202,\n",
        "                 apply_grayscale=False,\n",
        "                 apply_contrast=False, contrast_factor=1.5,\n",
        "                 apply_saturation=False, saturation_factor=1.5):\n",
        "        \"\"\"Initializes the model.\n",
        "\n",
        "        Args:\n",
        "            n_classes (int): Number of output classes.\n",
        "            apply_grayscale (bool): If True, convert images to grayscale.\n",
        "            apply_contrast (bool): If True, adjust image contrast.\n",
        "            contrast_factor (float): Factor to adjust contrast by (if apply_contrast is True).\n",
        "            apply_saturation (bool): If True, adjust image saturation.\n",
        "            saturation_factor (float): Factor to adjust saturation by (if apply_saturation is True).\n",
        "        \"\"\"\n",
        "        super().__init__() # Call the parent class constructor\n",
        "\n",
        "        # Store preprocessing flags and factors\n",
        "        self.apply_grayscale = apply_grayscale\n",
        "        self.apply_contrast = apply_contrast\n",
        "        self.apply_saturation = apply_saturation\n",
        "\n",
        "        # --- Preprocessing Layers ---\n",
        "        # Rescaling layer (always applied)\n",
        "        self.rescale_layer = Rescaling(scale= 1 / 255.0, name=\"Rescale_Layer\")    # Rescales pixel values to [0, 1]\n",
        "\n",
        "        # Conditionally define Lambda layer for contrast adjustment\n",
        "        if self.apply_contrast:\n",
        "            # Define Lambda layer for contrast adjustment\n",
        "            # Source: https://keras.io/api/layers/core_layers/lambda/\n",
        "            #         https://www.tensorflow.org/api_docs/python/tf/image/adjust_contrast\n",
        "            #         contrast_factor > 1 increases contrast, < 1 decreases contrast\n",
        "            self.contrast_layer = Lambda(\n",
        "                lambda x: tf.image.adjust_contrast(x, contrast_factor=contrast_factor),\n",
        "                name='Adjust_Contrast'\n",
        "            )\n",
        "\n",
        "        # Conditionally define Lambda layer for saturation adjustment\n",
        "        if self.apply_saturation:\n",
        "            # Define Lambda layer for saturation adjustment\n",
        "            # Source: https://www.tensorflow.org/api_docs/python/tf/image/adjust_saturation\n",
        "            #         saturation_factor > 1 increases saturation, < 1 decreases saturation\n",
        "            self.saturation_layer = Lambda(\n",
        "                lambda x: tf.image.adjust_saturation(x, saturation_factor=saturation_factor),\n",
        "                name='Adjust_Saturation'\n",
        "            )\n",
        "\n",
        "        # Conditionally define Lambda layer for grayscale conversion\n",
        "        if self.apply_grayscale:\n",
        "            # Define Lambda layer for grayscale conversion\n",
        "            # Source: https://www.tensorflow.org/api_docs/python/tf/image/rgb_to_grayscale\n",
        "            self.grayscale_layer = Lambda(\n",
        "                lambda x: tf.image.rgb_to_grayscale(x),\n",
        "                name='RGB_to_Grayscale'\n",
        "            )\n",
        "            # IMPORTANT: Add a Conv2D layer immediately after grayscale to ensure\n",
        "            # the number of channels is compatible with subsequent layers\n",
        "            # if they expect 3 channels. Here, we'll keep it 1 channel and adjust conv1.\n",
        "            # Alternatively, convert grayscale back to 3 identical channels:\n",
        "            # self.grayscale_to_rgb_layer = Lambda(\n",
        "            #     lambda x: tf.image.grayscale_to_rgb(x),\n",
        "            #     name='Grayscale_to_RGB'\n",
        "            # )\n",
        "\n",
        "\n",
        "        # # --- Convolutional Layers ---\n",
        "        # # Adjust the first Conv layer's input channels if grayscale is applied and not converted back to RGB\n",
        "        # # If grayscale IS applied, the input to conv1 will have 1 channel.\n",
        "        # # If grayscale IS NOT applied, the input will have 3 channels (after rescaling).\n",
        "        # # We will handle this by checking the shape dynamically or assuming subsequent layers can handle 1 channel if needed.\n",
        "        # # For simplicity here, let's assume conv1 works with either 1 or 3 channels.\n",
        "        # # If grayscale is applied, the input depth is 1, otherwise 3.\n",
        "        # # A more robust way might involve explicitly setting input_shape or checking channels.\n",
        "        # # Let's define conv1 to work even if input is grayscale (1 channel)\n",
        "        # self.conv1 = Conv2D(filters=3*8, kernel_size=(3, 3), activation='relu', name=\"Conv_Layer1\", padding=\"same\")    # 24 filters\n",
        "        # self.pool1 = MaxPooling2D(pool_size=(2, 2), name=\"Max_Pool_Layer1\")                                            # Reduces spatial dimensions by half\n",
        "\n",
        "        # # Subsequent layers\n",
        "        # self.conv2l = Conv2D(filters=3*16, kernel_size=(3, 3), activation='relu', name=\"Conv_Layer2l\", padding=\"same\") # 48 filters\n",
        "        # self.conv2r = Conv2D(filters=3*16, kernel_size=(3, 3), activation='relu', name=\"Conv_Layer2r\", padding=\"same\") # 48 filters (parallel path example)\n",
        "        # # Need to combine conv2l and conv2r, e.g., by concatenation or addition before pooling\n",
        "        # # For simplicity, let's just use one path for now:\n",
        "        # self.conv2 = Conv2D(filters=3*16, kernel_size=(3, 3), activation='relu', name=\"Conv_Layer2\", padding=\"same\") # 48 filters\n",
        "        # self.pool2 = MaxPooling2D(pool_size=(2, 2), name=\"MaxPool_Layer2\")                                            # Further reduces spatial dimensions\n",
        "\n",
        "        # Pre-trained VGG19 model - Using as a feature extractor\n",
        "        # Source: https://keras.io/api/applications/vgg/#vgg19-function\n",
        "        self.vgg19 = VGG19(include_top=False, weights='imagenet')\n",
        "        # Freeze the VGG19 layers to prevent training\n",
        "        for layer in self.vgg19.layers:\n",
        "            layer.trainable = False\n",
        "            \n",
        "        # Use Global Average Pooling instead of Flatten to reduce memory usage\n",
        "        self.global_pool = GlobalAveragePooling2D(name=\"GlobalAvgPool\")\n",
        "        \n",
        "        self.output_layer = Dense(n_classes, activation='softmax', name=\"Output_Layer\")\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        \"\"\"Defines the forward pass of the model.\n",
        "\n",
        "        Args:\n",
        "            inputs: Input tensor (batch of images).\n",
        "            training (bool): Indicates if the model is in training mode (for Dropout).\n",
        "\n",
        "        Returns:\n",
        "            Output tensor (probabilities for each class).\n",
        "        \"\"\"\n",
        "        # Apply mandatory rescaling\n",
        "        x = self.rescale_layer(inputs)\n",
        "\n",
        "        # Apply conditional preprocessing layers\n",
        "        if self.apply_contrast:\n",
        "            x = self.contrast_layer(x)\n",
        "        if self.apply_saturation:\n",
        "            x = self.saturation_layer(x)\n",
        "        if self.apply_grayscale:\n",
        "            x = self.grayscale_layer(x)\n",
        "            # If subsequent layers strictly require 3 channels, uncomment this:\n",
        "            # x = self.grayscale_to_rgb_layer(x)\n",
        "            # Note: If grayscale is applied, conv1 will process a 1-channel input unless converted back.\n",
        "\n",
        "        x = self.vgg19(x)\n",
        "        x = self.global_pool(x)       \n",
        "        outputs = self.output_layer(x)\n",
        "        return outputs\n",
        "\n",
        "# Example Instantiation and Summary\n",
        "model = RareSpeciesCNN(\n",
        "    n_classes=n_classes,\n",
        "    apply_grayscale=False,\n",
        "    apply_contrast=False,\n",
        "    apply_saturation=False\n",
        ")\n",
        "\n",
        "# Build the model by providing an input shape\n",
        "inputs = Input(shape=(img_width, img_height, 3))        # Input shape\n",
        "_ = model.call(inputs)                                  # Call the model to build it\n",
        "model.summary()                                         # Print the model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "dde8dc4b",
      "metadata": {
        "id": "dde8dc4b"
      },
      "outputs": [],
      "source": [
        "# # Visualize the model architecture\n",
        "# # Source: https://www.kaggle.com/code/devsubhash/visualize-deep-learning-models-using-visualkeras\n",
        "# visualkeras.layered_view(model,\n",
        "#                          legend=True,\n",
        "#                          show_dimension=True,\n",
        "#                          scale_xy=1,                                        # Adjust the scale of the image\n",
        "#                         #  scale_z=1,\n",
        "#                          # to_file='./BaselineModel_Architecture.png',\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "391168a3",
      "metadata": {
        "id": "391168a3"
      },
      "outputs": [],
      "source": [
        "# Compile model\n",
        "# optimizer = SGD(learning_rate=0.1, momentum=0.9, name=\"Optimizer\")                                                       # SGD with decay for stability\n",
        "optimizer = Adam(learning_rate=0.001, name=\"Optimizer\")                                                   # Adam for faster convergence\n",
        "# optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, decay=0.0, amsgrad=False, name=\"Optimizer\")  # Adam\n",
        "\n",
        "loss = CategoricalCrossentropy(name=\"Loss\")                            # Suitable for multi-class one-hot labels\n",
        "metrics = [CategoricalAccuracy(name=\"accuracy\"),\n",
        "           Precision(name=\"precision\"),\n",
        "           Recall(name=\"recall\"),\n",
        "           F1Score(average=\"macro\", name=\"f1_score\"),\n",
        "           AUC(name=\"auc\")]\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5ed55ae9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ed55ae9",
        "outputId": "a500749d-d893-4ccf-bd41-034ef35c152b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1mModel name:\u001b[0m RareSpeciesCNN_20250411\n"
          ]
        }
      ],
      "source": [
        "# Create a directory for saving the model and logs\n",
        "model_name = f\"RareSpeciesCNN_{datetime.datetime.now().strftime('%Y%m%d')}\"                                                                             # Model name\n",
        "print(f\"\\n\\033[1mModel name:\\033[0m {model_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "870a01da",
      "metadata": {
        "id": "870a01da"
      },
      "outputs": [],
      "source": [
        "# Callbacks\n",
        "model_name = f\"RareSpeciesCNN_{datetime.datetime.now().strftime('%Y%m%d')}\"\n",
        "os.makedirs(\"./ModelCallbacks\", exist_ok=True)      # Create directory if it doesn't exist                                                                      # Model name\n",
        "callbacks = [\n",
        "    ModelCheckpoint(f\"./ModelCallbacks/checkpoint_{model_name}.keras\", monitor=\"val_loss\", save_best_only=True, verbose=0),       # Save best model\n",
        "    CSVLogger(f\"./ModelCallbacks/metrics_{model_name}.csv\"),                                                                      # Log training metrics\n",
        "    LearningRateScheduler(lambda epoch, lr: lr * 0.95),                                                                           # Exponential decay for learning rate\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)                                           # Stop training when the validation loss stops improving\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19f48a4f",
      "metadata": {
        "id": "19f48a4f"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "668d0768",
      "metadata": {
        "id": "668d0768"
      },
      "source": [
        "### **Original Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65ddcc5f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65ddcc5f",
        "outputId": "a05a3a24-e9d7-47c1-f4ba-61a8f9900f43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1mBatch size:\u001b[0m 32\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "print(f\"\\n\\033[1mBatch size:\\033[0m {batch_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09b6dda9",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "09b6dda9",
        "outputId": "257bb8bc-9c87-43bb-84aa-09c4ffb5ecdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1744370263.073893   10573 service.cc:152] XLA service 0x77eeb4005c40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1744370263.073938   10573 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
            "2025-04-11 12:17:43.565867: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1744370264.315481   10573 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
            "2025-04-11 12:17:46.037528: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_771', 380 bytes spill stores, 380 bytes spill loads\n",
            "\n",
            "2025-04-11 12:17:46.455673: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1217', 12 bytes spill stores, 12 bytes spill loads\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m  1/300\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12:04\u001b[0m 14s/step - accuracy: 0.0000e+00 - auc: 0.4097 - f1_score: 0.0000e+00 - loss: 5.8171 - precision: 0.0000e+00 - recall: 0.0000e+00"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1744370276.074765   10573 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m  7/300\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 107ms/step - accuracy: 0.0000e+00 - auc: 0.4824 - f1_score: 0.0000e+00 - loss: 5.6063 - precision: 0.0000e+00 - recall: 0.0000e+00"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-11 12:17:56.620156: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 162656685 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 26/300\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 107ms/step - accuracy: 0.0075 - auc: 0.5250 - f1_score: 4.4036e-04 - loss: 5.4770 - precision: 0.0000e+00 - recall: 0.0000e+00"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-11 12:17:58.742286: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 150962688 exceeds 10% of free system memory.\n",
            "2025-04-11 12:17:58.858175: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 150962688 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 81/300\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 115ms/step - accuracy: 0.0243 - auc: 0.5868 - f1_score: 0.0015 - loss: 5.3038 - precision: 0.0000e+00 - recall: 0.0000e+00"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-11 12:18:05.272162: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 150962688 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 85/300\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 115ms/step - accuracy: 0.0251 - auc: 0.5895 - f1_score: 0.0016 - loss: 5.2954 - precision: 0.0000e+00 - recall: 0.0000e+00"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-11 12:18:05.739647: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 150962688 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m299/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.0455 - auc: 0.6486 - f1_score: 0.0041 - loss: 5.0940 - precision: 0.0000e+00 - recall: 0.0000e+00"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-11 12:18:37.617441: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_771', 468 bytes spill stores, 468 bytes spill loads\n",
            "\n",
            "2025-04-11 12:18:37.955854: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1217', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.0456 - auc: 0.6487 - f1_score: 0.0041 - loss: 5.0934 - precision: 0.0000e+00 - recall: 0.0000e+00"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-11 12:18:56.278315: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_319', 300 bytes spill stores, 300 bytes spill loads\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 226ms/step - accuracy: 0.0457 - auc: 0.6489 - f1_score: 0.0041 - loss: 5.0928 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0902 - val_auc: 0.7410 - val_f1_score: 0.0112 - val_loss: 4.6934 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 9.5000e-04\n",
            "Epoch 2/25\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 210ms/step - accuracy: 0.1050 - auc: 0.7644 - f1_score: 0.0147 - loss: 4.5958 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.1194 - val_auc: 0.7840 - val_f1_score: 0.0212 - val_loss: 4.4611 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 9.0250e-04\n",
            "Epoch 3/25\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 243ms/step - accuracy: 0.1362 - auc: 0.8099 - f1_score: 0.0290 - loss: 4.3386 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.1444 - val_auc: 0.8099 - val_f1_score: 0.0347 - val_loss: 4.2920 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 8.5737e-04\n",
            "Epoch 4/25\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 249ms/step - accuracy: 0.1553 - auc: 0.8437 - f1_score: 0.0395 - loss: 4.1474 - precision: 0.4836 - recall: 3.7674e-04 - val_accuracy: 0.1536 - val_auc: 0.8257 - val_f1_score: 0.0399 - val_loss: 4.1681 - val_precision: 1.0000 - val_recall: 0.0025 - learning_rate: 8.1451e-04\n",
            "Epoch 5/25\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 258ms/step - accuracy: 0.1730 - auc: 0.8656 - f1_score: 0.0555 - loss: 3.9904 - precision: 0.7765 - recall: 0.0012 - val_accuracy: 0.1661 - val_auc: 0.8399 - val_f1_score: 0.0503 - val_loss: 4.0681 - val_precision: 1.0000 - val_recall: 0.0033 - learning_rate: 7.7378e-04\n",
            "Epoch 6/25\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 257ms/step - accuracy: 0.1931 - auc: 0.8802 - f1_score: 0.0762 - loss: 3.8595 - precision: 0.9558 - recall: 0.0045 - val_accuracy: 0.1770 - val_auc: 0.8493 - val_f1_score: 0.0618 - val_loss: 3.9852 - val_precision: 1.0000 - val_recall: 0.0083 - learning_rate: 7.3509e-04\n",
            "Epoch 7/25\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 260ms/step - accuracy: 0.2064 - auc: 0.8905 - f1_score: 0.0940 - loss: 3.7578 - precision: 0.9635 - recall: 0.0096 - val_accuracy: 0.1853 - val_auc: 0.8545 - val_f1_score: 0.0709 - val_loss: 3.9200 - val_precision: 0.9474 - val_recall: 0.0150 - learning_rate: 6.9834e-04\n",
            "Epoch 8/25\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 269ms/step - accuracy: 0.2211 - auc: 0.8998 - f1_score: 0.1144 - loss: 3.6695 - precision: 0.9580 - recall: 0.0155 - val_accuracy: 0.1920 - val_auc: 0.8588 - val_f1_score: 0.0816 - val_loss: 3.8609 - val_precision: 0.9630 - val_recall: 0.0217 - learning_rate: 6.6342e-04\n",
            "Epoch 9/25\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 272ms/step - accuracy: 0.2390 - auc: 0.9056 - f1_score: 0.1363 - loss: 3.5883 - precision: 0.9738 - recall: 0.0207 - val_accuracy: 0.1995 - val_auc: 0.8643 - val_f1_score: 0.0908 - val_loss: 3.8096 - val_precision: 0.9062 - val_recall: 0.0242 - learning_rate: 6.3025e-04\n",
            "Epoch 10/25\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 280ms/step - accuracy: 0.2535 - auc: 0.9112 - f1_score: 0.1570 - loss: 3.5172 - precision: 0.9503 - recall: 0.0241 - val_accuracy: 0.2120 - val_auc: 0.8682 - val_f1_score: 0.1060 - val_loss: 3.7660 - val_precision: 0.8824 - val_recall: 0.0250 - learning_rate: 5.9874e-04\n",
            "Epoch 11/25\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - accuracy: 0.2657 - auc: 0.9169 - f1_score: 0.1719 - loss: 3.4542 - precision: 0.9522 - recall: 0.0278"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-11 12:32:52.233596: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 33554432 bytes after encountering the first element of size 33554432 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 479ms/step - accuracy: 0.2657 - auc: 0.9169 - f1_score: 0.1719 - loss: 3.4542 - precision: 0.9522 - recall: 0.0278 - val_accuracy: 0.2129 - val_auc: 0.8723 - val_f1_score: 0.1061 - val_loss: 3.7267 - val_precision: 0.8889 - val_recall: 0.0267 - learning_rate: 5.6880e-04\n",
            "Epoch 12/25\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 263ms/step - accuracy: 0.2748 - auc: 0.9197 - f1_score: 0.1842 - loss: 3.4064 - precision: 0.9362 - recall: 0.0306 - val_accuracy: 0.2212 - val_auc: 0.8752 - val_f1_score: 0.1188 - val_loss: 3.6919 - val_precision: 0.8974 - val_recall: 0.0292 - learning_rate: 5.4036e-04\n",
            "Epoch 13/25\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 288ms/step - accuracy: 0.2837 - auc: 0.9231 - f1_score: 0.1957 - loss: 3.3575 - precision: 0.9495 - recall: 0.0352 - val_accuracy: 0.2337 - val_auc: 0.8778 - val_f1_score: 0.1284 - val_loss: 3.6592 - val_precision: 0.9000 - val_recall: 0.0301 - learning_rate: 5.1334e-04\n",
            "Epoch 14/25\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.2925 - auc: 0.9273 - f1_score: 0.2062 - loss: 3.3042 - precision: 0.9423 - recall: 0.0387"
          ]
        }
      ],
      "source": [
        "# Train model\n",
        "start_time = time.time()\n",
        "history = model.fit(train_datagen, batch_size = batch_size, epochs=25, validation_data=val_datagen, callbacks=callbacks, verbose=1)\n",
        "train_time = round(time.time() - start_time, 2)\n",
        "\n",
        "print(f\"\\nTraining completed in \\033[1m{train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\\033[0m).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "204995d589f8431f",
      "metadata": {
        "id": "204995d589f8431f"
      },
      "source": [
        "#### **🧪 Model Selection & 📏 Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24ffc2e9",
      "metadata": {
        "id": "24ffc2e9"
      },
      "outputs": [],
      "source": [
        "# Evaluate model\n",
        "from utilities import plot_metrics\n",
        "\n",
        "plot_metrics(history,\n",
        "            #  file_path=f\"./ModelsEvaluation/2_Training_Validation_Metrics_{datetime.datetime.now().strftime('%Y%m%d')}.png\"\n",
        "             )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbae5954",
      "metadata": {
        "id": "fbae5954"
      },
      "outputs": [],
      "source": [
        "# Evaluate on validation and test sets\n",
        "train_results = {'accuracy': history.history['accuracy'][-1], 'precision': history.history['precision'][-1], 'recall': history.history['recall'][-1], 'f1_score': history.history['f1_score'][-1], 'auc': history.history['auc'][-1]}\n",
        "val_results = model.evaluate(val_datagen, batch_size=batch_size, return_dict=True, verbose=0)\n",
        "test_results = model.evaluate(test_datagen, batch_size=batch_size, return_dict=True, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eb1867d",
      "metadata": {
        "id": "3eb1867d"
      },
      "outputs": [],
      "source": [
        "# Display results\n",
        "from utilities import display_side_by_side, create_evaluation_dataframe\n",
        "\n",
        "results_df = create_evaluation_dataframe(\n",
        "    model_name=\"Baseline Model\",\n",
        "    variation=\"Default\",\n",
        "    train_metrics=train_results,\n",
        "    val_metrics=val_results,\n",
        "    test_metrics=test_results,\n",
        "    train_time=train_time\n",
        ")\n",
        "\n",
        "display_side_by_side(results_df, super_title=\"Model Evaluation Results\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d77537d",
      "metadata": {
        "id": "3d77537d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3ea3f13",
      "metadata": {
        "id": "a3ea3f13"
      },
      "source": [
        "## **📊 Best Model - Predictions Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "252e6113",
      "metadata": {
        "id": "252e6113"
      },
      "outputs": [],
      "source": [
        "from utilities import plot_confusion_matrix\n",
        "\n",
        "# Plot confusion matrix for test set\n",
        "plot_confusion_matrix(\n",
        "    y_true=test_datagen.classes,\n",
        "    y_pred=model.predict(test_datagen, batch_size=batch_size),\n",
        "    title=\"Confusion Matrix | Best Baseline Model\",\n",
        "    # file_path=\"./ModelsEvaluation/3_Test_Confusion_Matrix.png\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5e2e827",
      "metadata": {
        "id": "c5e2e827"
      },
      "outputs": [],
      "source": [
        "# Plot 5 right and 5 wrong predictions\n",
        "from utilities import plot_predictions\n",
        "plot_predictions(\n",
        "    model=model,\n",
        "    data=test_datagen,\n",
        "    n_samples=5,\n",
        "    file_path=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b849b2d",
      "metadata": {
        "id": "5b849b2d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ddc8664",
      "metadata": {
        "id": "2ddc8664"
      },
      "outputs": [],
      "source": [
        "# # Save to CSV\n",
        "# results_df.set_index('Models', inplace=True)\n",
        "# results_df.to_csv(\"ModelsEvaluation/BaselineModelEvaluation_1_29.03.2025.csv\", index=False)                ### Change the name of the file to save it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RoG_M5jtf8X6",
      "metadata": {
        "id": "RoG_M5jtf8X6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "84b90a90",
      "metadata": {
        "id": "84b90a90"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ILdCeh0Mf864",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "ILdCeh0Mf864",
        "outputId": "ef9051cc-3875-4ebe-9b4c-2692ef0f994c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"improved_rare_species_cnn_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"improved_rare_species_cnn_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ Rescale (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Contrast (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Saturation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ vgg19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,024,384</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ GlobalAvgPool                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ BatchNorm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Predictions (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">103,626</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ Rescale (\u001b[38;5;33mRescaling\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Contrast (\u001b[38;5;33mLambda\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Saturation (\u001b[38;5;33mLambda\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ vgg19 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m20,024,384\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ GlobalAvgPool                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ BatchNorm (\u001b[38;5;33mBatchNormalization\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Predictions (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m202\u001b[0m)            │       \u001b[38;5;34m103,626\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,130,058</span> (76.79 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,130,058\u001b[0m (76.79 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,903,690</span> (45.41 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,903,690\u001b[0m (45.41 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,226,368</span> (31.38 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m8,226,368\u001b[0m (31.38 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.layers import (GlobalAveragePooling2D, BatchNormalization,\n",
        "                                     Dense, Dropout, Lambda, Rescaling)\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import (ModelCheckpoint, CSVLogger, EarlyStopping,\n",
        "                                        LearningRateScheduler)\n",
        "\n",
        "# Improved model class definition\n",
        "class ImprovedRareSpeciesCNN(Model):\n",
        "    \"\"\"\n",
        "    Improved Rare Species CNN using VGG19 as the backbone.\n",
        "\n",
        "    This model includes:\n",
        "      - Rescaling and optional preprocessing (contrast, saturation, grayscale adjustments).\n",
        "      - Data augmentation (applied only during training).\n",
        "      - A pre-trained VGG19 backbone with the option to fine-tune later layers.\n",
        "      - Global Average Pooling to reduce the number of parameters.\n",
        "      - Batch Normalization and Dropout for regularization.\n",
        "      - A final Dense layer for classification (using softmax activation).\n",
        "\n",
        "    Args:\n",
        "        n_classes (int): Number of output classes.\n",
        "        apply_grayscale (bool): Convert images to grayscale if True.\n",
        "        apply_contrast (bool): Adjust image contrast if True.\n",
        "        contrast_factor (float): Factor for contrast adjustment.\n",
        "        apply_saturation (bool): Adjust image saturation if True.\n",
        "        saturation_factor (float): Factor for saturation adjustment.\n",
        "        fine_tune_at (int or None): If specified, unfreezes layers from this index onward in VGG19.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_classes=202,\n",
        "                 apply_grayscale=False,\n",
        "                 apply_contrast=False, contrast_factor=1.5,\n",
        "                 apply_saturation=False, saturation_factor=1.5,\n",
        "                 fine_tune_at=None):\n",
        "        super().__init__()\n",
        "\n",
        "        # Mandatory rescaling layer: scales pixel values to [0, 1]\n",
        "        self.rescale_layer = Rescaling(1/255.0, name=\"Rescale\")\n",
        "\n",
        "        # Optional preprocessing layers\n",
        "        self.contrast_layer = (Lambda(lambda x: tf.image.adjust_contrast(x, contrast_factor=contrast_factor),\n",
        "                                      name=\"Contrast\")\n",
        "                               if apply_contrast else None)\n",
        "\n",
        "        self.saturation_layer = (Lambda(lambda x: tf.image.adjust_saturation(x, saturation_factor=saturation_factor),\n",
        "                                        name=\"Saturation\")\n",
        "                                 if apply_saturation else None)\n",
        "\n",
        "        self.grayscale_layer = (Lambda(lambda x: tf.image.rgb_to_grayscale(x), name=\"Grayscale\")\n",
        "                                if apply_grayscale else None)\n",
        "        # If grayscale conversion is applied and subsequent layers expect 3 channels,\n",
        "        # you can convert it back to RGB:\n",
        "        self.grayscale_to_rgb_layer = (Lambda(lambda x: tf.image.grayscale_to_rgb(x), name=\"GrayscaleToRGB\")\n",
        "                                       if apply_grayscale else None)\n",
        "\n",
        "        # Pre-trained VGG19 backbone (without the top classification layers)\n",
        "        self.vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "        self.vgg19.trainable = False  # Initially freeze the backbone\n",
        "\n",
        "        # Option to fine-tune: Unfreeze layers from the specified index onward\n",
        "        if fine_tune_at is not None:\n",
        "            self.vgg19.trainable = True\n",
        "            for layer in self.vgg19.layers[:fine_tune_at]:\n",
        "                layer.trainable = False\n",
        "\n",
        "        # Replace Flatten with Global Average Pooling to reduce parameters\n",
        "        self.global_pool = GlobalAveragePooling2D(name=\"GlobalAvgPool\")\n",
        "        self.batch_norm = BatchNormalization(name=\"BatchNorm\")\n",
        "        self.dropout = Dropout(0.5, name=\"Dropout\")\n",
        "        self.output_layer = Dense(n_classes, activation='softmax', name=\"Predictions\")\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        \"\"\"\n",
        "        Forward pass of the model.\n",
        "\n",
        "        Args:\n",
        "            inputs: Input tensor (batch of images).\n",
        "            training (bool): Indicates if the model is in training mode.\n",
        "\n",
        "        Returns:\n",
        "            Output tensor (class probabilities).\n",
        "        \"\"\"\n",
        "        # Rescale input\n",
        "        x = self.rescale_layer(inputs)\n",
        "\n",
        "\n",
        "        # Optional preprocessing: contrast, saturation, grayscale adjustments\n",
        "        if self.contrast_layer is not None:\n",
        "            x = self.contrast_layer(x)\n",
        "        if self.saturation_layer is not None:\n",
        "            x = self.saturation_layer(x)\n",
        "        if self.grayscale_layer is not None:\n",
        "            x = self.grayscale_layer(x)\n",
        "            if self.grayscale_to_rgb_layer is not None:\n",
        "                x = self.grayscale_to_rgb_layer(x)\n",
        "\n",
        "        # Pass through the pre-trained backbone\n",
        "        x = self.vgg19(x, training=training)\n",
        "\n",
        "        # Global pooling, normalization, and dropout\n",
        "        x = self.global_pool(x)\n",
        "        x = self.batch_norm(x, training=training)\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        # Final classification layer\n",
        "        return self.output_layer(x)\n",
        "\n",
        "# Instantiate the improved model\n",
        "model = ImprovedRareSpeciesCNN(n_classes=202,\n",
        "                               apply_grayscale=False,\n",
        "                               apply_contrast=True, contrast_factor=1.2,\n",
        "                               apply_saturation=True, saturation_factor=1.2,\n",
        "                               fine_tune_at=15)  # Unfreeze layers after index 15 for fine-tuning\n",
        "\n",
        "# Build the model by providing an input tensor\n",
        "inputs = Input(shape=(224, 224, 3))\n",
        "_ = model.call(inputs)\n",
        "\n",
        "# Compile the model using SGD with momentum and a categorical crossentropy loss\n",
        "optimizer = SGD(learning_rate=1e-3, momentum=0.9)\n",
        "loss = CategoricalCrossentropy()\n",
        "metrics = ['accuracy', tf.keras.metrics.Precision(name=\"precision\"), tf.keras.metrics.Recall(name=\"recall\")]\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "# Set up callbacks for training\n",
        "model_name = f\"ImprovedRareSpeciesCNN_{datetime.datetime.now().strftime('%Y%m%d')}\"\n",
        "os.makedirs(\"ModelCallbacks\", exist_ok=True)\n",
        "callbacks = [\n",
        "    ModelCheckpoint(f\"ModelCallbacks/checkpoint_{model_name}.keras\", monitor=\"val_loss\", save_best_only=True, verbose=1),\n",
        "    CSVLogger(f\"ModelCallbacks/metrics_{model_name}.csv\"),\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True, verbose=1),\n",
        "    LearningRateScheduler(lambda epoch, lr: lr * 0.95, verbose=1)\n",
        "]\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bDvPrV1fmXU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bDvPrV1fmXU",
        "outputId": "0ff35f24-ad35-4d59-eba1-1eb1f8f3ab45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 48480 files belonging to 202 classes.\n",
            "Found 1198 files belonging to 202 classes.\n",
            "Found 1199 files belonging to 202 classes.\n",
            "\n",
            "Loaded: Train (48480), Val (1216), Test (1216)\n"
          ]
        }
      ],
      "source": [
        "# Import the image dataset from the directory\n",
        "from utilities import load_images_from_directory\n",
        "train_datagen_SMOTE, val_datagen, test_datagen = load_images_from_directory('/content/RareSpecies_Split/train_DataAugmentationSMOTE', val_dir, test_dir,\n",
        "                                                                      labels='inferred', label_mode='categorical',\n",
        "                                                                      class_names=class_names, color_mode='rgb',\n",
        "                                                                      batch_size=batch_size, image_size=image_size, seed=2025,\n",
        "                                                                      interpolation='bilinear', crop_to_aspect_ratio=False, pad_to_aspect_ratio=False)\n",
        "\n",
        "print(f\"\\nLoaded: Train ({train_datagen_SMOTE.cardinality().numpy() * batch_size}), \"\n",
        "        f\"Val ({val_datagen.cardinality().numpy() * batch_size}), \"\n",
        "        f\"Test ({test_datagen.cardinality().numpy() * batch_size})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e61c8d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "0e61c8d7",
        "outputId": "475e4ad0-a9ba-4a68-8f23-76ac67d3b6d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0009500000451225787.\n",
            "Epoch 1/25\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 5.31813, saving model to ModelCallbacks/checkpoint_ImprovedRareSpeciesCNN_20250411.keras\n",
            "1515/1515 - 430s - 284ms/step - accuracy: 7.8383e-04 - loss: 5.3882 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0025 - val_loss: 5.3181 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 9.5000e-04\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0009025000152178108.\n",
            "Epoch 2/25\n",
            "\n",
            "Epoch 2: val_loss did not improve from 5.31813\n",
            "1515/1515 - 424s - 280ms/step - accuracy: 2.8878e-04 - loss: 5.3720 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0025 - val_loss: 5.3188 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 9.0250e-04\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0008573750033974647.\n",
            "Epoch 3/25\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-94240efb1b03>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_datagen_SMOTE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_datagen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrain_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[1;32m    219\u001b[0m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/optional_ops.py\u001b[0m in \u001b[0;36mhas_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       return gen_optional_ops.optional_has_value(\n\u001b[0m\u001b[1;32m    177\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_optional_ops.py\u001b[0m in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    173\u001b[0m         _ctx, \"OptionalHasValue\", name, optional)\n\u001b[1;32m    174\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train\n",
        "start_time = time.time()\n",
        "history = model.fit(train_datagen_SMOTE, batch_size = batch_size, epochs=25, validation_data=val_datagen, callbacks=callbacks, verbose=2)\n",
        "train_time = round(time.time() - start_time, 2)\n",
        "\n",
        "print(f\"\\nTraining completed in \\033[1m{train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\\033[0m).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f95a3689",
      "metadata": {
        "id": "f95a3689"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8973198d",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9dff3bdf66c1f233",
      "metadata": {
        "id": "9dff3bdf66c1f233"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45a5816b",
      "metadata": {
        "id": "45a5816b"
      },
      "source": [
        "# **🔗 Bibliography/References**\n",
        "\n",
        "**[[1]](https://)** AAAAAAAAAA\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf218",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
