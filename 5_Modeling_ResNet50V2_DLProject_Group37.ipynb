{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1834cc3d7b582eb2",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center; justify-content: center; flex-wrap: wrap;\">\n",
    "    <div style=\"flex: 1; max-width: 400px; display: flex; justify-content: center;\">\n",
    "        <img src=\"https://i.ibb.co/JBPWVYR/Logo-Nova-IMS-Black.png\" style=\"max-width: 50%; height: auto; margin-top: 50px; margin-bottom: 50px;margin-left: 6rem;\">\n",
    "    </div>\n",
    "    <div style=\"flex: 2; text-align: center; margin-top: 20px;margin-left: 8rem;\">\n",
    "        <div style=\"font-size: 28px; font-weight: bold; line-height: 1.2;\">\n",
    "            <span style=\"color: #22c1c3;\">DL Project |</span> <span style=\"color: #08529C;\">Predicting Rare Species from Images using Deep Learning</span>\n",
    "        </div>\n",
    "        <div style=\"font-size: 17px; font-weight: bold; margin-top: 10px;\">\n",
    "            Spring Semester | 2024 - 2025\n",
    "        </div>\n",
    "        <div style=\"font-size: 17px; font-weight: bold;\">\n",
    "            Master in Data Science and Advanced Analytics\n",
    "        </div>\n",
    "        <div style=\"margin-top: 20px;\">\n",
    "            <div>Andr√© Silvestre, 20240502</div>\n",
    "            <div>Diogo Duarte, 20240525</div>\n",
    "            <div>Filipa Pereira, 20240509</div>\n",
    "            <div>Maria Cruz, 20230760</div>\n",
    "            <div>Umeima Mahomed, 20240543</div>\n",
    "        </div>\n",
    "        <div style=\"margin-top: 20px; font-weight: bold;\">\n",
    "            Group 37\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827c9197",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right, #22c1c3, #27b1dd, #2d9cfd, #090979); \n",
    "            padding: 1px; color: white; border-radius: 500px; text-align: center;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e047308f",
   "metadata": {},
   "source": [
    "## **üìö Libraries Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212899eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from typing_extensions import Self, Any      # For Python 3.10\n",
    "# from typing import Self, Any               # For Python >3.11\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Data manipulation imports\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Deep learning imports\n",
    "import tensorflow as tf\n",
    "from keras.ops import add\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import Model, Sequential, Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Rescaling, Lambda, BatchNormalization, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras import regularizers                                                                           # For L2 regularization\n",
    "# import visualkeras\n",
    "\n",
    "# Evaluation imports\n",
    "from keras.metrics import CategoricalAccuracy, AUC, F1Score, Precision, Recall\n",
    "\n",
    "# Other imports\n",
    "from itertools import product\n",
    "\n",
    "# Set the style of the visualization\n",
    "pd.set_option('future.no_silent_downcasting', True)   # use int instead of float in DataFrame\n",
    "pd.set_option(\"display.max_columns\", None)            # display all columns\n",
    "\n",
    "# Disable warnings (FutureWarning)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b679a1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a SSL context that does not verify the server‚Äôs certificate - Needed for downloading pretrained models\n",
    "# Source: https://precli.readthedocs.io/0.3.4/rules/python/stdlib/ssl_create_unverified_context.html\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ba1bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"Is TensorFlow built with CUDA?\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"GPU Device Name:\", tf.test.gpu_device_name())                                # (if error in Google Colab: Make sure your Hardware accelerator is set to GPU. \n",
    "                                                                                    # Runtime > Change runtime type > Hardware Accelerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d69f728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get build information from TensorFlow\n",
    "build_info = tf.sysconfig.get_build_info()\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"CUDA version:\", build_info.get(\"cuda_version\", \"Not available\"))\n",
    "print(\"cuDNN version:\", build_info.get(\"cudnn_version\", \"Not available\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ebd61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom module for importing data, visualization, and utilities\n",
    "import utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef892b8f",
   "metadata": {},
   "source": [
    "## **üßÆ Import Databases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1958d1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data\n",
    "train_dir = Path(\"data/RareSpecies_Split/train\")\n",
    "val_dir = Path(\"data/RareSpecies_Split/val\")\n",
    "test_dir = Path(\"data/RareSpecies_Split/test\")\n",
    "\n",
    "# For Google Collab\n",
    "# train_dir = Path(\"/content/RareSpecies_Split/train\")\n",
    "# val_dir = Path(\"/content/RareSpecies_Split/val\")\n",
    "# test_dir = Path(\"/content/RareSpecies_Split/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39adca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Generators \n",
    "n_classes = 202                                     # Number of classes (we already know this based on previous notebook)\n",
    "image_size = (224, 224)                             # Image size (224x224)\n",
    "img_height, img_width = image_size                  # Image dimensions\n",
    "batch_size = 64                                     # Batch size\n",
    "input_shape = (img_height, img_width, 3)            # Input shape of the model\n",
    "value_range = (0.0, 1.0)                            # Range of pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5aa922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names from directory\n",
    "class_names = sorted(os.listdir(train_dir))\n",
    "class_indices = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "# Import the image dataset from the directory\n",
    "from utilities import load_images_from_directory\n",
    "train_datagen, val_datagen, test_datagen = load_images_from_directory(train_dir, val_dir, test_dir,\n",
    "                                                                      labels='inferred', label_mode='categorical',\n",
    "                                                                      class_names=class_names, color_mode='rgb',\n",
    "                                                                      batch_size=batch_size, image_size=image_size, seed=2025, \n",
    "                                                                      interpolation='bilinear', crop_to_aspect_ratio=False, pad_to_aspect_ratio=False)\n",
    "\n",
    "print(f\"\\nLoaded: Train ({train_datagen.cardinality().numpy() * batch_size}), \"\n",
    "        f\"Val ({val_datagen.cardinality().numpy() * batch_size}), \"\n",
    "        f\"Test ({test_datagen.cardinality().numpy() * batch_size})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c18b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the data (batch_size, img_width, img_height, 3)\n",
    "for x, y in train_datagen.take(1):\n",
    "    print(\"Train batch shape:\", x.shape, y.shape)\n",
    "for x, y in val_datagen.take(1):\n",
    "    print(\"Val batch shape:\", x.shape, y.shape)\n",
    "for x, y in test_datagen.take(1):\n",
    "    print(\"Test batch shape:\", x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f158b792ebd291",
   "metadata": {},
   "source": [
    "# <a class='anchor' id='3'></a>\n",
    "<br>\n",
    "<style>\n",
    "@import url('https://fonts.cdnfonts.com/css/avenir-next-lt-pro?styles=29974');\n",
    "</style>\n",
    "\n",
    "<div style=\"background: linear-gradient(to right, #22c1c3, #27b1dd, #2d9cfd, #090979); \n",
    "            padding: 10px; color: white; border-radius: 300px; text-align: center;\">\n",
    "    <center><h1 style=\"margin-left: 140px;margin-top: 10px; margin-bottom: 4px; color: white;\n",
    "                       font-size: 32px; font-family: 'Avenir Next LT Pro', sans-serif;\">\n",
    "        <b>3 | Modeling - ResNet50V2</b></h1></center>\n",
    "</div>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<center><img src=\"https://www.researchgate.net/publication/370917910/figure/fig5/AS:11431281160027107@1684590298290/Architecture-of-the-ResNet50V2-model.ppm\"\n",
    "             style=\"width: 700px\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b21f66",
   "metadata": {},
   "source": [
    "# **üí° Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5f2a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for saving model checkpoints and evaluation logs\n",
    "os.makedirs(\"./ModelCallbacks/5_ResNet152V2Model\", exist_ok=True)      # exist_ok=True | Create directory if it doesn't exist\n",
    "os.makedirs(\"./ModelsEvaluation/5_ResNet152V2Model\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91250f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet152V2\n",
    "\n",
    "class RareSpeciesCNN_ResNet152V2(Model):\n",
    "    \"\"\"Custom CNN for rare species classification using ResNet152V2.\n",
    "    \n",
    "    Architecture: ResNet152V2 \n",
    "    \"\"\"\n",
    "    def __init__(self, n_classes=202,\n",
    "                 apply_grayscale=False,\n",
    "                 apply_contrast=False, contrast_factor=1.5,\n",
    "                 apply_saturation=False, saturation_factor=1.5):\n",
    "        super().__init__()                          # Call the parent class constructor\n",
    "\n",
    "        # Store preprocessing flags and factors\n",
    "        self.apply_grayscale = apply_grayscale\n",
    "        self.apply_contrast = apply_contrast\n",
    "        self.apply_saturation = apply_saturation\n",
    "\n",
    "        # Preprocessing Layers (Same as in the previous notebook)\n",
    "        self.rescale_layer = Rescaling(scale=1 / 255.0, name=\"Rescale_Layer\")\n",
    "        if self.apply_contrast:\n",
    "            self.contrast_layer = Lambda(lambda x: tf.image.adjust_contrast(x, contrast_factor=contrast_factor), name='Adjust_Contrast') \n",
    "        if self.apply_saturation:\n",
    "            self.saturation_layer = Lambda(lambda x: tf.image.adjust_saturation(x, saturation_factor=saturation_factor), name='Adjust_Saturation')\n",
    "        if self.apply_grayscale:\n",
    "            self.grayscale_layer = Lambda(lambda x: tf.image.rgb_to_grayscale(x), name='RGB_to_Grayscale')\n",
    "\n",
    "        # Load ResNet152V2 Pretrained Model\n",
    "        self.resnet152v2 = ResNet152V2(include_top=False,           # Do not include the top classification layer (we will add our own because we have a different number of classes)\n",
    "                                            classes=n_classes,      # Number of classes\n",
    "                                            weights='imagenet')     # Use ImageNet weights\n",
    "        self.resnet152v2.trainable = False                          # Freeze the convolutional layers in the model (transfer learning)\n",
    "        \n",
    "        # --- Classification Head ---\n",
    "        self.global_avg_pool = GlobalAveragePooling2D(name=\"Global_Average_Pooling\")      # Global Average Pooling layer\n",
    "        self.dense1 = Dense(128, name=\"Dense_Layer1\")                                     # Smaller intermediate dense layer\n",
    "        self.dropout = Dropout(0.5, name=\"Dropout_Layer\")                                 # Dropout layer for regularization\n",
    "        self.dense_output = Dense(n_classes, activation='softmax', name=\"Output_Layer\")   # Output layer with softmax activation (for multi-class classification)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # Apply mandatory rescaling\n",
    "        x = self.rescale_layer(inputs)\n",
    "        \n",
    "        # Apply conditional preprocessing layers\n",
    "        if self.apply_contrast:\n",
    "            x = self.contrast_layer(x)\n",
    "        if self.apply_saturation:\n",
    "            x = self.saturation_layer(x)\n",
    "        if self.apply_grayscale:\n",
    "            x = self.grayscale_layer(x)\n",
    "\n",
    "        # Pass through ResNet152V2 model\n",
    "        x = self.resnet152v2(x, training=training)      # Pass through the model (ResNet152V2)\n",
    "\n",
    "        # Classification Head\n",
    "        x = self.global_avg_pool(x)                    # Global Average Pooling\n",
    "        x = self.dense1(x)                             # Dense layer\n",
    "        x = self.dropout(x, training=training)         # Dropout layer\n",
    "        outputs = self.dense_output(x)                 # Output layer\n",
    "        return outputs\n",
    "\n",
    "# Example Instantiation and Summary\n",
    "model = RareSpeciesCNN_ResNet152V2(\n",
    "    n_classes=n_classes,\n",
    "    apply_grayscale=False,\n",
    "    apply_contrast=False,\n",
    "    apply_saturation=False,\n",
    ")\n",
    "\n",
    "# Build the model by providing an input shape\n",
    "inputs = Input(shape=(img_width, img_height, 3))        # Input shape\n",
    "_ = model.call(inputs)                                  # Call the model to build it\n",
    "model.summary()                                         # Print the model summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65549be1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f6da1e",
   "metadata": {},
   "source": [
    "# **ü•á Best Combinations Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae15b991",
   "metadata": {},
   "source": [
    "#### **Original | Grayscale=F | Contrast=F | Saturation=F**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0caefff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain model with m√°x 100 epochs and EarlyStopping\n",
    "# ResNet152V2 Model - Original Dataset | Grayscale=F | Contrast=F | Saturation=F\n",
    "model = RareSpeciesCNN_ResNet152V2(\n",
    "    n_classes=n_classes, \n",
    "    apply_grayscale=False, \n",
    "    apply_contrast=False,                         \n",
    "    apply_saturation=False\n",
    ")\n",
    "# Build the model by providing an input shape\n",
    "inputs = Input(shape=(img_width, img_height, 3))        # Input shape\n",
    "_ = model.call(inputs)                                  # Call the model to build it\n",
    "model.summary()                                         # Print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a94e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.001, weight_decay=0.01, name=\"Optimizer\")                                        # Adam for faster convergence\n",
    "loss = CategoricalCrossentropy(name=\"Loss\")                                                                       # Suitable for multi-class one-hot labels\n",
    "metrics = [CategoricalAccuracy(name=\"accuracy\"), Precision(name=\"precision\"), Recall(name=\"recall\"), F1Score(average=\"macro\", name=\"f1_score\"), AUC(name=\"auc\")]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6f0a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "model_name = f\"RareSpeciesCNN_ResNet152V2_{datetime.datetime.now().strftime('%Y%m%d')}_Original_maxEpochs100\" # Model name\n",
    "callbacks = [ModelCheckpoint(f\"./ModelCallbacks/5_ResNet152V2Model/checkpoint_{model_name}.keras\", monitor=\"val_loss\", save_best_only=True, verbose=0), CSVLogger(f\"./ModelCallbacks/5_ResNet152V2Model/metrics_{model_name}.csv\"), LearningRateScheduler(lambda epoch, lr: lr * 0.95), EarlyStopping(monitor='val_loss', patience=3, verbose=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e77499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_datagen, batch_size = batch_size, epochs=100, validation_data=val_datagen, callbacks=callbacks, verbose=1)\n",
    "train_time = round(time.time() - start_time, 2)\n",
    "print(f\"\\nTraining completed in \\033[1m{train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\\033[0m).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0513496",
   "metadata": {},
   "source": [
    "##### **üß™ Model Selection & üìè Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78841c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from utilities import plot_metrics\n",
    "plot_metrics(history, file_path=f\"./ModelsEvaluation/5_ResNet152V2Model/5_TrainingValidationMetrics_{model_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca893e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation and test sets\n",
    "train_results = {'accuracy': history.history['accuracy'][-1], 'precision': history.history['precision'][-1], 'recall': history.history['recall'][-1], 'f1_score': history.history['f1_score'][-1], 'auc': history.history['auc'][-1]}\n",
    "val_results = model.evaluate(val_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "test_results = model.evaluate(test_datagen, batch_size=batch_size, return_dict=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aeec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "from utilities import display_side_by_side, create_evaluation_dataframe\n",
    "results_df = create_evaluation_dataframe(\n",
    "    model_name=\"ResNet152V2\", variation=\"Original | Grayscale=F | Contrast=F | Saturation=F | Adam=0.001\",   # Dataset | Grayscale | Contrast | Saturation | Optimizer=Learning Rate\n",
    "    train_metrics=train_results, val_metrics=val_results, test_metrics=test_results, train_time=train_time,\n",
    "    csv_save_path= f\"./ModelsEvaluation/5_ResNet152V2Model/5_TrainingValidationMetrics_{model_name}.csv\"\n",
    ")\n",
    "display_side_by_side(results_df, super_title=\"Model Evaluation Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11038d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot n right and n wrong predictions\n",
    "from utilities import plot_predictions\n",
    "plot_predictions(\n",
    "    model=model,\n",
    "    class_names=class_names,\n",
    "    train_dir=train_dir,\n",
    "    test_data=test_datagen,\n",
    "    num_images=10,\n",
    "    file_path=f\"./ModelsEvaluation/5_ResNet152V2Model/5_TestPredictions_{model_name}.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7869d48",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bab5dcf",
   "metadata": {},
   "source": [
    "#### **Original | Grayscale=F | Contrast=T | Saturation=F**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d7f707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain model with m√°x 100 epochs and EarlyStopping\n",
    "# ResNet152V2 Model - Original | Grayscale=F | Contrast=T | Saturation=F | Adam=0.001\n",
    "model = RareSpeciesCNN_ResNet152V2(\n",
    "    n_classes=n_classes, \n",
    "    apply_grayscale=False, \n",
    "    apply_contrast=True,                         \n",
    "    apply_saturation=False\n",
    ")\n",
    "# Build the model by providing an input shape\n",
    "inputs = Input(shape=(img_width, img_height, 3))        # Input shape\n",
    "_ = model.call(inputs)                                  # Call the model to build it\n",
    "model.summary()                                         # Print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a1cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.001, weight_decay=0.01, name=\"Optimizer\")                                        # Adam for faster convergence\n",
    "loss = CategoricalCrossentropy(name=\"Loss\")                                                                       # Suitable for multi-class one-hot labels\n",
    "metrics = [CategoricalAccuracy(name=\"accuracy\"), Precision(name=\"precision\"), Recall(name=\"recall\"), F1Score(average=\"macro\", name=\"f1_score\"), AUC(name=\"auc\")]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea9ce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "model_name = f\"RareSpeciesCNN_ResNet152V2_{datetime.datetime.now().strftime('%Y%m%d')}_OriginalContrast_maxEpochs100\" # Model name\n",
    "callbacks = [ModelCheckpoint(f\"./ModelCallbacks/5_ResNet152V2Model/checkpoint_{model_name}.keras\", monitor=\"val_loss\", save_best_only=True, verbose=0), CSVLogger(f\"./ModelCallbacks/5_ResNet152V2Model/metrics_{model_name}.csv\"), LearningRateScheduler(lambda epoch, lr: lr * 0.95), EarlyStopping(monitor='val_loss', patience=3, verbose=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68208cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_datagen, batch_size = batch_size, epochs=100, validation_data=val_datagen, callbacks=callbacks, verbose=1)\n",
    "train_time = round(time.time() - start_time, 2)\n",
    "print(f\"\\nTraining completed in \\033[1m{train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\\033[0m).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5865964",
   "metadata": {},
   "source": [
    "##### **üß™ Model Selection & üìè Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59b1ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from utilities import plot_metrics\n",
    "plot_metrics(history, file_path=f\"./ModelsEvaluation/5_ResNet152V2Model/5_TrainingValidationMetrics_{model_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f39135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation and test sets\n",
    "train_results = {'accuracy': history.history['accuracy'][-1], 'precision': history.history['precision'][-1], 'recall': history.history['recall'][-1], 'f1_score': history.history['f1_score'][-1], 'auc': history.history['auc'][-1]}\n",
    "val_results = model.evaluate(val_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "test_results = model.evaluate(test_datagen, batch_size=batch_size, return_dict=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03595ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "from utilities import display_side_by_side, create_evaluation_dataframe\n",
    "results_df = create_evaluation_dataframe(\n",
    "    model_name=\"ResNet152V2\", variation=\"Original | Grayscale=F | Contrast=T | Saturation=F | Adam=0.001\",   # Dataset | Grayscale | Contrast | Saturation | Optimizer=Learning Rate\n",
    "    train_metrics=train_results, val_metrics=val_results, test_metrics=test_results, train_time=train_time,\n",
    "    csv_save_path= f\"./ModelsEvaluation/5_ResNet152V2Model/5_TrainingValidationMetrics_{model_name}.csv\"\n",
    ")\n",
    "display_side_by_side(results_df, super_title=\"Model Evaluation Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcbb3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot n right and n wrong predictions\n",
    "from utilities import plot_predictions\n",
    "plot_predictions(\n",
    "    model=model,\n",
    "    class_names=class_names,\n",
    "    train_dir=train_dir,\n",
    "    test_data=test_datagen,\n",
    "    num_images=10,\n",
    "    file_path=f\"./ModelsEvaluation/5_ResNet152V2Model/5_TestPredictions_{model_name}.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbed6cb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6506e948",
   "metadata": {},
   "source": [
    "### **üñåÔ∏è SMOTE (Data Augmentation)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af8ae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SMOTE training data\n",
    "train_DataAugmentationSMOTE_dir = Path(\"data/RareSpecies_Split/train_DataAugmentationSMOTE\")\n",
    "val_dir = Path(\"data/RareSpecies_Split/val\")\n",
    "test_dir = Path(\"data/RareSpecies_Split/test\")\n",
    "\n",
    "# train_DataAugmentationSMOTE_dir = Path(\"/content/RareSpecies_Split/train_DataAugmentationSMOTE\")\n",
    "# val_dir = Path(\"/content/RareSpecies_Split/val\")\n",
    "# test_dir = Path(\"/content/RareSpecies_Split/test\")\n",
    "\n",
    "# Import the image dataset from the directory\n",
    "train_DataAugmentationSMOTE_datagen, val_datagen, test_datagen = load_images_from_directory(train_DataAugmentationSMOTE_dir, val_dir, test_dir,\n",
    "                                                                      labels='inferred', label_mode='categorical',\n",
    "                                                                      class_names=class_names, color_mode='rgb',\n",
    "                                                                      batch_size=batch_size, image_size=image_size, seed=2025, \n",
    "                                                                      interpolation='bilinear', crop_to_aspect_ratio=False, pad_to_aspect_ratio=False)\n",
    "# Check the shape of the data (batch_size, img_width, img_height, 3)\n",
    "for x, y in train_DataAugmentationSMOTE_datagen.take(1):\n",
    "    print(\"Train batch shape:\", x.shape, y.shape)\n",
    "for x, y in val_datagen.take(1):\n",
    "    print(\"Val batch shape:\", x.shape, y.shape)\n",
    "for x, y in test_datagen.take(1):\n",
    "    print(\"Test batch shape:\", x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bf8278",
   "metadata": {},
   "source": [
    "#### **SMOTE | Grayscale=F | Contrast=F | Saturation=F**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70247694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet152V2 Model - SMOTE Data Augmentation | Grayscale=F | Contrast=F | Saturation=F\n",
    "model = RareSpeciesCNN_ResNet152V2(\n",
    "    n_classes=n_classes, \n",
    "    apply_grayscale=False, \n",
    "    apply_contrast=False,                         \n",
    "    apply_saturation=False\n",
    ")\n",
    "\n",
    "# Build the model by providing an input shape\n",
    "inputs = Input(shape=(img_width, img_height, 3))        # Input shape\n",
    "_ = model.call(inputs)                                  # Call the model to build it\n",
    "model.summary()                                         # Print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd697e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.001, weight_decay=0.01, name=\"Optimizer\")\n",
    "loss = CategoricalCrossentropy(name=\"Loss\")\n",
    "metrics = [CategoricalAccuracy(name=\"accuracy\"), Precision(name=\"precision\"), Recall(name=\"recall\"), F1Score(average=\"macro\", name=\"f1_score\"), AUC(name=\"auc\")]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8155461a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "model_name = f\"RareSpeciesCNN_ResNet152V2_{datetime.datetime.now().strftime('%Y%m%d')}_SMOTE_MaxEpochs100\" # Model name\n",
    "callbacks = [ModelCheckpoint(f\"./ModelCallbacks/5_ResNet152V2Model/checkpoint_{model_name}.keras\", monitor=\"val_loss\", save_best_only=True, verbose=0), CSVLogger(f\"./ModelCallbacks/5_ResNet152V2Model/metrics_{model_name}.csv\"), LearningRateScheduler(lambda epoch, lr: lr * 0.95), EarlyStopping(monitor='val_loss', patience=3, verbose=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcdd40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_DataAugmentationSMOTE_datagen, batch_size=batch_size, epochs=100, validation_data=val_datagen, callbacks=callbacks, verbose=1)\n",
    "train_time = round(time.time() - start_time, 2)\n",
    "print(f\"\\nTraining completed in \\033[1m{train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\\033[0m).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733c38cd",
   "metadata": {},
   "source": [
    "##### **üß™ Model Selection & üìè Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920f150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from utilities import plot_metrics\n",
    "plot_metrics(history, file_path=f\"./ModelsEvaluation/5_ResNet152V2Model/5_TrainingValidationMetrics_{model_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c2b1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation and test sets\n",
    "train_results = {'accuracy': history.history['accuracy'][-1], 'precision': history.history['precision'][-1], 'recall': history.history['recall'][-1], 'f1_score': history.history['f1_score'][-1], 'auc': history.history['auc'][-1]}\n",
    "val_results = model.evaluate(val_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "test_results = model.evaluate(test_datagen, batch_size=batch_size, return_dict=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f335bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "from utilities import display_side_by_side, create_evaluation_dataframe\n",
    "results_df = create_evaluation_dataframe(\n",
    "    model_name=\"ResNet152V2\", variation=\"SMOTE | Grayscale=F | Contrast=F | Saturation=F | Adam=0.001\",\n",
    "    train_metrics=train_results, val_metrics=val_results, test_metrics=test_results, train_time=train_time,\n",
    "    csv_save_path= f\"./ModelsEvaluation/5_ResNet152V2Model/5_TrainingValidationMetrics_{model_name}.csv\"\n",
    ")\n",
    "display_side_by_side(results_df, super_title=\"Model Evaluation Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d266c4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot n right and n wrong predictions\n",
    "from utilities import plot_predictions\n",
    "plot_predictions(\n",
    "    model=model,\n",
    "    class_names=class_names,\n",
    "    train_dir=train_dir,\n",
    "    test_data=test_datagen,\n",
    "    num_images=10,\n",
    "    file_path=f\"./ModelsEvaluation/5_ResNet152V2Model/5_TestPredictions_{model_name}.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d6dfad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b2ec0a",
   "metadata": {},
   "source": [
    "#### **SMOTE | Grayscale=F | Contrast=T | Saturation=F**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d803c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet152V2 Model - SMOTE Data Augmentation | Grayscale=F | Contrast=T | Saturation=F\n",
    "model = RareSpeciesCNN_ResNet152V2(\n",
    "    n_classes=n_classes, \n",
    "    apply_grayscale=False, \n",
    "    apply_contrast=True,                         \n",
    "    apply_saturation=False\n",
    ")\n",
    "# Build the model by providing an input shape\n",
    "inputs = Input(shape=(img_width, img_height, 3))        # Input shape\n",
    "_ = model.call(inputs)                                  # Call the model to build it\n",
    "model.summary()                                         # Print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1c4b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.001, weight_decay=0.01, name=\"Optimizer\")\n",
    "loss = CategoricalCrossentropy(name=\"Loss\")\n",
    "metrics = [CategoricalAccuracy(name=\"accuracy\"), Precision(name=\"precision\"), Recall(name=\"recall\"), F1Score(average=\"macro\", name=\"f1_score\"), AUC(name=\"auc\")]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa9af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "model_name = f\"RareSpeciesCNN_ResNet152V2_{datetime.datetime.now().strftime('%Y%m%d')}_SMOTEContrast_MaxEpochs100\" # Model name\n",
    "callbacks = [ModelCheckpoint(f\"./ModelCallbacks/5_ResNet152V2Model/checkpoint_{model_name}.keras\", monitor=\"val_loss\", save_best_only=True, verbose=0), CSVLogger(f\"./ModelCallbacks/5_ResNet152V2Model/metrics_{model_name}.csv\"), LearningRateScheduler(lambda epoch, lr: lr * 0.95), EarlyStopping(monitor='val_loss', patience=3, verbose=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83395e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_DataAugmentationSMOTE_datagen, batch_size=batch_size, epochs=100, validation_data=val_datagen, callbacks=callbacks, verbose=1)\n",
    "train_time = round(time.time() - start_time, 2)\n",
    "print(f\"\\nTraining completed in \\033[1m{train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\\033[0m).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669f1f5d",
   "metadata": {},
   "source": [
    "##### **üß™ Model Selection & üìè Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928309ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from utilities import plot_metrics\n",
    "plot_metrics(history, file_path=f\"./ModelsEvaluation/5_ResNet152V2Model/5_TrainingValidationMetrics_{model_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27569b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation and test sets\n",
    "train_results = {'accuracy': history.history['accuracy'][-1], 'precision': history.history['precision'][-1], 'recall': history.history['recall'][-1], 'f1_score': history.history['f1_score'][-1], 'auc': history.history['auc'][-1]}\n",
    "val_results = model.evaluate(val_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "test_results = model.evaluate(test_datagen, batch_size=batch_size, return_dict=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e2ee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "from utilities import display_side_by_side, create_evaluation_dataframe\n",
    "results_df = create_evaluation_dataframe(\n",
    "    model_name=\"ResNet152V2\", variation=\"SMOTE | Grayscale=F | Contrast=T | Saturation=F | Adam=0.001\",\n",
    "    train_metrics=train_results, val_metrics=val_results, test_metrics=test_results, train_time=train_time,\n",
    "    csv_save_path= f\"./ModelsEvaluation/5_ResNet152V2Model/5_TrainingValidationMetrics_{model_name}.csv\"\n",
    ")\n",
    "display_side_by_side(results_df, super_title=\"Model Evaluation Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1877afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot n right and n wrong predictions\n",
    "from utilities import plot_predictions\n",
    "plot_predictions(\n",
    "    model=model,\n",
    "    class_names=class_names,\n",
    "    train_dir=train_dir,\n",
    "    test_data=test_datagen,\n",
    "    num_images=10,\n",
    "    file_path=f\"./ModelsEvaluation/5_ResNet152V2Model/5_TestPredictions_{model_name}.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c643e21d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5015dd",
   "metadata": {},
   "source": [
    "#### **SMOTE | Grayscale=F | Contrast=F | Saturation=T**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f292d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet152V2 Model - SMOTE Data Augmentation | Grayscale=F | Contrast=F | Saturation=T\n",
    "model = RareSpeciesCNN_ResNet152V2(\n",
    "    n_classes=n_classes, \n",
    "    apply_grayscale=False, \n",
    "    apply_contrast=False,                         \n",
    "    apply_saturation=True\n",
    ")\n",
    "# Build the model by providing an input shape\n",
    "inputs = Input(shape=(img_width, img_height, 3))        # Input shape\n",
    "_ = model.call(inputs)                                  # Call the model to build it\n",
    "model.summary()                                         # Print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674e2748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.001, weight_decay=0.01, name=\"Optimizer\")\n",
    "loss = CategoricalCrossentropy(name=\"Loss\")\n",
    "metrics = [CategoricalAccuracy(name=\"accuracy\"), Precision(name=\"precision\"), Recall(name=\"recall\"), F1Score(average=\"macro\", name=\"f1_score\"), AUC(name=\"auc\")]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8719453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "model_name = f\"RareSpeciesCNN_ResNet152V2_{datetime.datetime.now().strftime('%Y%m%d')}_SMOTESaturation_MaxEpochs100\" # Model name\n",
    "callbacks = [ModelCheckpoint(f\"./ModelCallbacks/5_ResNet152V2Model/checkpoint_{model_name}.keras\", monitor=\"val_loss\", save_best_only=True, verbose=0), CSVLogger(f\"./ModelCallbacks/5_ResNet152V2Model/metrics_{model_name}.csv\"), LearningRateScheduler(lambda epoch, lr: lr * 0.95), EarlyStopping(monitor='val_loss', patience=3, verbose=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169d2605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_DataAugmentationSMOTE_datagen, batch_size=batch_size, epochs=100, validation_data=val_datagen, callbacks=callbacks, verbose=1)\n",
    "train_time = round(time.time() - start_time, 2)\n",
    "print(f\"\\nTraining completed in \\033[1m{train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\\033[0m).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b92596",
   "metadata": {},
   "source": [
    "##### **üß™ Model Selection & üìè Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a29b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from utilities import plot_metrics\n",
    "plot_metrics(history, file_path=f\"./ModelsEvaluation/5_ResNet152V2Model/5_TrainingValidationMetrics_{model_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd2ef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation and test sets\n",
    "train_results = {'accuracy': history.history['accuracy'][-1], 'precision': history.history['precision'][-1], 'recall': history.history['recall'][-1], 'f1_score': history.history['f1_score'][-1], 'auc': history.history['auc'][-1]}\n",
    "val_results = model.evaluate(val_datagen, batch_size=batch_size, return_dict=True, verbose=1)\n",
    "test_results = model.evaluate(test_datagen, batch_size=batch_size, return_dict=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d230fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "from utilities import display_side_by_side, create_evaluation_dataframe\n",
    "results_df = create_evaluation_dataframe(\n",
    "    model_name=\"ResNet152V2\", variation=\"SMOTE | Grayscale=F | Contrast=F | Saturation=T | Adam=0.001\",\n",
    "    train_metrics=train_results, val_metrics=val_results, test_metrics=test_results, train_time=train_time,\n",
    "    csv_save_path= f\"./ModelsEvaluation/5_ResNet152V2Model/5_TrainingValidationMetrics_{model_name}.csv\"\n",
    ")\n",
    "display_side_by_side(results_df, super_title=\"Model Evaluation Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45768120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot n right and n wrong predictions\n",
    "from utilities import plot_predictions\n",
    "plot_predictions(\n",
    "    model=model,\n",
    "    class_names=class_names,\n",
    "    train_dir=train_dir,\n",
    "    test_data=test_datagen,\n",
    "    num_images=10,\n",
    "    file_path=f\"./ModelsEvaluation/5_ResNet152V2Model/5_TestPredictions_{model_name}.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e42da22",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3928807f",
   "metadata": {},
   "source": [
    "#### **üü® Google Collab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27089001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Google Collab Workspace\n",
    "# Source: https://stackoverflow.com/questions/48774285/how-to-download-file-created-in-colaboratory-workspace\n",
    "# !zip -r /content/ModelCallbacks.zip /content/ModelCallbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c961c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !zip -r /content/ModelsEvaluation.zip /content/ModelsEvaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55eadb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# files.download(\"/content/ModelCallbacks.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca57c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files.download(\"/content/ModelsEvaluation.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dff3bdf66c1f233",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a5816b",
   "metadata": {},
   "source": [
    "# **üîó Bibliography/References**\n",
    "\n",
    "**[[1]](https://arxiv.org/pdf/1603.05027)** He, K., Zhang, X., Ren, S., & Sun, J. (2016). Identity Mappings in Deep Residual Networks. https://arxiv.org/pdf/1603.05027"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
