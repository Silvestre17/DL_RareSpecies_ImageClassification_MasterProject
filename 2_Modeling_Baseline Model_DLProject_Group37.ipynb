{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1834cc3d7b582eb2",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center; justify-content: center; flex-wrap: wrap;\">\n",
    "    <div style=\"flex: 1; max-width: 400px; display: flex; justify-content: center;\">\n",
    "        <img src=\"https://i.ibb.co/JBPWVYR/Logo-Nova-IMS-Black.png\" style=\"max-width: 50%; height: auto; margin-top: 50px; margin-bottom: 50px;margin-left: 6rem;\">\n",
    "    </div>\n",
    "    <div style=\"flex: 2; text-align: center; margin-top: 20px;margin-left: 8rem;\">\n",
    "        <div style=\"font-size: 28px; font-weight: bold; line-height: 1.2;\">\n",
    "            <span style=\"color: #22c1c3;\">DL Project |</span> <span style=\"color: #08529C;\">Predicting Rare Species from Images using Deep Learning</span>\n",
    "        </div>\n",
    "        <div style=\"font-size: 17px; font-weight: bold; margin-top: 10px;\">\n",
    "            Spring Semester | 2024 - 2025\n",
    "        </div>\n",
    "        <div style=\"font-size: 17px; font-weight: bold;\">\n",
    "            Master in Data Science and Advanced Analytics\n",
    "        </div>\n",
    "        <div style=\"margin-top: 20px;\">\n",
    "            <div>AndrÃ© Silvestre, 20240502</div>\n",
    "            <div>Diogo Duarte, 20240525</div>\n",
    "            <div>Filipa Pereira, 20240509</div>\n",
    "            <div>Maria Cruz, 20230760</div>\n",
    "            <div>Umeima Mahomed, 20240543</div>\n",
    "        </div>\n",
    "        <div style=\"margin-top: 20px; font-weight: bold;\">\n",
    "            Group 37\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827c9197",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right, #22c1c3, #27b1dd, #2d9cfd, #090979); \n",
    "            padding: 1px; color: white; border-radius: 500px; text-align: center;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f603cf1cb0fd531",
   "metadata": {},
   "source": [
    "## **ğŸ“š Libraries Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c91174e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 20:59:32.400955: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743281972.535326   35748 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743281972.571524   35748 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743281972.854984   35748 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743281972.855082   35748 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743281972.855085   35748 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743281972.855088   35748 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-29 20:59:32.886576: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from typing_extensions import Self, Any      # For Python 3.10\n",
    "# from typing import Self, Any               # For Python >3.11\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Data manipulation imports\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Deep learning imports\n",
    "import tensorflow as tf\n",
    "from keras.ops import add\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import Model, Sequential, Input\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "# Image processing imports (Data Augmentation)\n",
    "from tensorflow.keras.layers import (\n",
    "    Resizing, Rescaling, CenterCrop, AutoContrast, Equalization, MixUp, \n",
    "    RandAugment, RandomBrightness, RandomColorDegeneration, RandomColorJitter, RandomContrast, \n",
    "    RandomCrop, RandomFlip, RandomGrayscale, RandomHue, RandomRotation, RandomSaturation, RandomSharpness, \n",
    "    RandomShear, RandomTranslation, RandomZoom\n",
    ")\n",
    "# Evaluation imports\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.metrics import CategoricalAccuracy, AUC, F1Score, Precision, Recall\n",
    "\n",
    "# Other imports\n",
    "from itertools import product\n",
    "\n",
    "# Image processing imports\n",
    "from matplotlib.image import imread\n",
    "from PIL import Image\n",
    "\n",
    "# Set the style of the visualization\n",
    "pd.set_option('future.no_silent_downcasting', True)   # use int instead of float in DataFrame\n",
    "pd.set_option(\"display.max_columns\", None)            # display all columns\n",
    "\n",
    "# Disable warnings (FutureWarning)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# For better resolution plots\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# Setting seaborn style\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0d56ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.19.0\n",
      "Is TensorFlow built with CUDA? True\n",
      "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU Device Name: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743281977.181177   35748 gpu_device.cc:2019] Created device /device:GPU:0 with 3586 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"Is TensorFlow built with CUDA?\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"GPU Device Name:\", tf.test.gpu_device_name())                                # (if error in Google Colab: Make sure your Hardware accelerator is set to GPU. \n",
    "                                                                                    # Runtime > Change runtime type > Hardware Accelerator)\n",
    "\n",
    "if tf.test.is_built_with_cuda():\n",
    "    tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcb366e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary function to display multiple dataframes side by side\n",
    "# Source: https://python.plainenglish.io/displaying-multiple-dataframes-side-by-side-in-jupyter-lab-notebook-9a4649a4940\n",
    "from IPython.display import display_html\n",
    "from itertools import chain,cycle\n",
    "def display_side_by_side(*args, super_title, titles=cycle([''])):\n",
    "    \"\"\"\n",
    "    :param args: Variable number of DataFrame objects to be displayed side by side.\n",
    "    :param super_title: The main title to be displayed at the top of the combined view.\n",
    "    :param titles: An iterable containing titles for each DataFrame to be displayed. Defaults to an infinite cycle of empty strings.\n",
    "    \n",
    "    :return: None. The function generates and displays HTML content side by side for given DataFrames.\n",
    "    \"\"\"\n",
    "    html_str = ''\n",
    "    html_str += f'<h1 style=\"text-align: left; margin-bottom: -15px;\">{super_title}</h1><br>'\n",
    "    html_str += '<div style=\"display: flex;\">'\n",
    "    for df, title in zip(args, chain(titles, cycle(['</br>']))):\n",
    "        html_str += f'<div style=\"margin-right: 20px;\"><h3 style=\"text-align: center;color:#555555;\">{title}</h3>'\n",
    "        html_str += df.to_html().replace('table', 'table style=\"display:inline; margin-right: 20px;\"')\n",
    "        html_str += '</div>'\n",
    "    html_str += '</div>'\n",
    "    display_html(html_str, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5d91a720daf9a2",
   "metadata": {},
   "source": [
    "## **ğŸ§® Import Databases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a69d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run in Google Collab to download the dataset already splitted\n",
    "# # Source: https://stackoverflow.com/questions/25010369/wget-curl-large-file-from-google-drivez\n",
    "# # Download the file from Google Drive using wget\n",
    "# !wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate \\\n",
    "#   \"https://drive.usercontent.google.com/download?id=1CxoEypMtEp_Uzh9MiCJKWmQ9OBs7iNdY&export=download\" -O- | \\\n",
    "#   sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p' > /tmp/confirm.txt\n",
    "\n",
    "# # Read the confirmation token from the temporary file\n",
    "# with open('/tmp/confirm.txt', 'r') as f:\n",
    "#     confirm_token = f.read().strip()\n",
    "\n",
    "# # Download the file using the confirmation token and cookies\n",
    "# !wget --load-cookies /tmp/cookies.txt \\\n",
    "#   \"https://drive.usercontent.google.com/download?id=1CxoEypMtEp_Uzh9MiCJKWmQ9OBs7iNdY&export=download&confirm={confirm_token}\" \\\n",
    "#   -O /content/RareSpecies_Split.zip\n",
    "\n",
    "# # Clean up temporary files\n",
    "# !rm /tmp/cookies.txt /tmp/confirm.txt\n",
    "\n",
    "# # List files in the /content directory to verify the download\n",
    "# !ls -lh /content/\n",
    "\n",
    "# # Unzip the downloaded file\n",
    "# !unzip /content/RareSpecies_Split.zip -d /content/\n",
    "\n",
    "# # List the unzipped files to verify\n",
    "# !ls -lh /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87da922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data\n",
    "train_dir = Path(\"data/train\")\n",
    "val_dir = Path(\"data/val\")\n",
    "test_dir = Path(\"data/test\")\n",
    "\n",
    "# For Google Collab\n",
    "# train_dir = Path(\"/content/RareSpecies_Split/train\")\n",
    "# val_dir = Path(\"/content/RareSpecies_Split/val\")\n",
    "# test_dir = Path(\"/content/RareSpecies_Split/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5977e7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8388 files belonging to 202 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743281981.786283   35748 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3586 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1797 files belonging to 202 classes.\n",
      "Found 1798 files belonging to 202 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image Generators\n",
    "n_classes = 202                                     # Number of classes (we already know this based on previous notebook)\n",
    "image_size = (224, 224)                             # Size of the images\n",
    "img_width, img_height = 224, 224               \n",
    "batch_size = 16                                     # Batch size\n",
    "input_shape = (img_width, img_height, 3)            # Input shape of the model\n",
    "value_range = (0.0, 1.0)                            # Range of pixel values\n",
    "\n",
    "# Data generators with built-in rescaling (no augmentation yet)\n",
    "\n",
    "# Training data generator\n",
    "train_datagen = image_dataset_from_directory(\n",
    "    train_dir,                                      # Path to the directory\n",
    "    labels='inferred',                              # Type of labels to generate (inferred = from the directory structure)\n",
    "    label_mode='categorical',                       # Type of labels to generate (categorical = 'float32' tensor of shape (batch_size, num_classes), representing a one-hot encoding of the class index.)\n",
    "    color_mode='rgb',                               # Color mode to read images\n",
    "    batch_size=batch_size,                          # Size of the batches of data\n",
    "    image_size=(img_width, img_height),             # Size of the images to read\n",
    "    shuffle=True,                                   # Whether to shuffle the data\n",
    "    seed=2025,                                      # Random seed for shuffling and transformations\n",
    "    interpolation='bilinear',                       # Interpolation method to resample the image\n",
    ")\n",
    "\n",
    "# Validation data generator\n",
    "val_datagen = image_dataset_from_directory(val_dir, labels='inferred', label_mode='categorical', color_mode='rgb', batch_size=batch_size,\n",
    "                                           image_size=(img_width, img_height), shuffle=True, seed=2025, interpolation='bilinear')\n",
    "\n",
    "# Test data generator\n",
    "test_datagen = image_dataset_from_directory(test_dir, labels='inferred', label_mode='categorical', color_mode='rgb', batch_size=batch_size,\n",
    "                                            image_size=(img_width, img_height), shuffle=True, seed=2025, interpolation='bilinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f158b792ebd291",
   "metadata": {},
   "source": [
    "# <a class='anchor' id='3'></a>\n",
    "<br>\n",
    "<style>\n",
    "@import url('https://fonts.cdnfonts.com/css/avenir-next-lt-pro?styles=29974');\n",
    "</style>\n",
    "\n",
    "<div style=\"background: linear-gradient(to right, #22c1c3, #27b1dd, #2d9cfd, #090979); \n",
    "            padding: 10px; color: white; border-radius: 300px; text-align: center;\">\n",
    "    <center><h1 style=\"margin-left: 140px;margin-top: 10px; margin-bottom: 4px; color: white;\n",
    "                       font-size: 32px; font-family: 'Avenir Next LT Pro', sans-serif;\">\n",
    "        <b>3 | Modeling - Baseline Model</b></h1></center>\n",
    "</div>\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f65000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample one image filepath from the training set\n",
    "list(train_datagen.file_paths)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9092e002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_experiment(image_path='data/train/chordata_dactyloidae/29482917_453292_eol-full-size-copy.jpg'):\n",
    "    \"\"\"Tests all Keras preprocessing and augmentation layers on a sample image with max effect (factor=1).\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the sample image.\n",
    "    \n",
    "    Returns:\n",
    "        None: Displays multiple 2xN grids of transformed images.\n",
    "    \n",
    "    Notes:\n",
    "        - Loads image, resizes to 224x224, rescales to [0, 1].\n",
    "        - Applies all available Keras image preprocessing/augmentation layers.\n",
    "        - Uses training=True for random layers to ensure application.\n",
    "        - Splits into multiple 2-row grids for readability.\n",
    "    \"\"\"\n",
    "    # Load and preprocess the image\n",
    "    try:\n",
    "        original_img = Image.open(image_path).convert('RGB')  # Ensure RGB format\n",
    "        img = original_img.resize((224, 224))  # Resize to 224x224\n",
    "        img_array = np.array(img).astype(\"float32\") / 255.0  # Rescale to [0, 1]\n",
    "        img_array = tf.expand_dims(img_array, 0)  # Add batch dimension\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image: {e}\")\n",
    "        return\n",
    "\n",
    "    # Define all preprocessing and augmentation layers with max effect\n",
    "    transformations = [\n",
    "        (\"Original\", lambda x: x[0]),                                           # Unchanged image\n",
    "        (\"Resized\", Resizing(224, 224)),                                        # Resizes to specified dimensions (redundant here but shown)\n",
    "        (\"Rescaled\", Rescaling(1./255)),                                        # Scales pixels to [0, 1] (redundant here)\n",
    "        (\"CenterCrop\", CenterCrop(200, 200)),                                   # Crops center to 200x200\n",
    "        (\"AutoContrast\", AutoContrast()),                                       # Maximizes contrast across the image\n",
    "        (\"Equalization\", Equalization()),                                       # Equalizes histogram for contrast enhancement\n",
    "        (\"MixUp\", MixUp(alpha=1.0)),                                            # Blends images (simplified for single image)\n",
    "        (\"RandAugment\", RandAugment(value_range=(0, 1))),                       # Randomly applies augmentations at max magnitude\n",
    "        (\"Brightness\", RandomBrightness(1.0)),                                  # Adjusts brightness by max factor\n",
    "        (\"ColorDegeneration\", RandomColorDegeneration(factor=1.0)),             # Degenerates color to grayscale-like\n",
    "        (\"ColorJitter\", RandomColorJitter(brightness_factor=1.0, \n",
    "                                          contrast_factor=1.0, \n",
    "                                          saturation_factor=1.0)),              # Max jitters brightness, contrast, saturation\n",
    "        (\"Contrast\", RandomContrast(1.0)),                                      # Max contrast adjustment\n",
    "        (\"Crop\", RandomCrop(200, 200)),                                         # Randomly crops to 200x200\n",
    "        (\"Flip\", RandomFlip(\"horizontal_and_vertical\")),                        # Flips both horizontally and vertically\n",
    "        (\"Grayscale\", RandomGrayscale(factor=1.0)),                             # Converts to grayscale with 100% probability\n",
    "        (\"Hue\", RandomHue(factor=0.5)),                                         # Shifts hue by max factor (0.5 is max valid range)\n",
    "        (\"Rotation\", RandomRotation(1.0)),                                      # Rotates by up to 360 degrees (factor=1)\n",
    "        (\"Saturation\", RandomSaturation(1.0)),                                  # Adjusts saturation by max factor\n",
    "        (\"Sharpness\", RandomSharpness(1.0)),                                    # Enhances sharpness by max factor\n",
    "        (\"Shear\", RandomShear(0.5)),                                            # Shears by max factor\n",
    "        (\"Translation\", RandomTranslation(0.5, 0.5)),                           # Shifts by max horizontal/vertical factors\n",
    "        (\"Zoom\", RandomZoom(0.5)),                                              # Zooms by max factor\n",
    "    ]\n",
    "\n",
    "    # Apply transformations and store results\n",
    "    transformed_imgs = []\n",
    "    for name, layer in transformations:\n",
    "        try:\n",
    "            if name == \"Original\":\n",
    "                result = layer(img_array)\n",
    "            else:\n",
    "                result = layer(img_array, training=True)  # Force application\n",
    "            transformed_imgs.append((name, tf.squeeze(result).numpy()))\n",
    "        except Exception as e:\n",
    "            print(f\"Error applying {name}: {e}\")\n",
    "            transformed_imgs.append((name, img_array[0]))  # Fallback to original\n",
    "\n",
    "    # Plot in multiple 4-row grids\n",
    "    n_transforms = len(transformed_imgs)\n",
    "    n_cols = (n_transforms + 1) // 4                 # Number of columns for 2 rows\n",
    "    n_rows = (n_transforms + n_cols - 1) // n_cols   # Number of 2xN grids needed\n",
    "\n",
    "    fig, ax = plt.subplots(n_rows, n_cols, figsize=(n_cols * 2, 8))    \n",
    "    for i, (title, img_data) in enumerate(transformed_imgs):\n",
    "        row, col = divmod(i, n_cols)\n",
    "        ax[row, col].imshow(np.clip(img_data, 0, 1))  # Ensure valid pixel range\n",
    "        ax[row, col].set_title(title, fontsize=10, fontweight='bold')\n",
    "        ax[row, col].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(n_transforms, n_rows * n_cols):\n",
    "        row, col = divmod(i, n_cols)\n",
    "        ax[row, col].axis('off')\n",
    "        \n",
    "    # Adjust layout and display\n",
    "    sns.despine(top=True, right=True)\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f\"Preprocessing and Augmentation Effects\", fontsize=16, fontweight='bold', y=1.05)\n",
    "    plt.show()\n",
    "\n",
    "# Run the experiment with two example images\n",
    "print(\"\\nPreprocessing Experiment (Image 1):\")\n",
    "preprocess_experiment()\n",
    "print(\"\\nPreprocessing Experiment (Image 2):\")\n",
    "preprocess_experiment(image_path='data/train/chordata_anatidae/14020527_45513542_eol-full-size-copy.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26312ae5b0368022",
   "metadata": {},
   "source": [
    "# **ğŸ’¡ Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3556121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"rare_species_cnn\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"rare_species_cnn\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ Rescale_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)       â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ RandAugment_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandAugment</span>) â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Conv_Layer1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)   â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">672</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Max_Pool_Layer1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)   â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Conv_Layer2l (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,416</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Conv_Layer2r (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,416</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ MaxPool_Layer2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Flatten_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">145200</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">145200</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Dense_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span>)            â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">29,330,602</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ Rescale_Layer (\u001b[38;5;33mRescaling\u001b[0m)       â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ RandAugment_Layer (\u001b[38;5;33mRandAugment\u001b[0m) â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Conv_Layer1 (\u001b[38;5;33mConv2D\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m24\u001b[0m)   â”‚           \u001b[38;5;34m672\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Max_Pool_Layer1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m24\u001b[0m)   â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Conv_Layer2l (\u001b[38;5;33mConv2D\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m48\u001b[0m)   â”‚        \u001b[38;5;34m10,416\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Conv_Layer2r (\u001b[38;5;33mConv2D\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m48\u001b[0m)   â”‚        \u001b[38;5;34m10,416\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ MaxPool_Layer2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m48\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Flatten_Layer (\u001b[38;5;33mFlatten\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m145200\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m145200\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Dense_Layer (\u001b[38;5;33mDense\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m202\u001b[0m)            â”‚    \u001b[38;5;34m29,330,602\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,352,106</span> (111.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,352,106\u001b[0m (111.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,352,106</span> (111.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,352,106\u001b[0m (111.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Baseline Model\n",
    "class RareSpeciesCNN(Model):\n",
    "    \"\"\"Custom CNN for rare species classification.\n",
    "    \n",
    "    Architecture: Simple CNN with two conv blocks, max pooling, and a dense layer.\n",
    "    Why: Small model to establish baseline, avoiding overfitting on 202 classes.\n",
    "    Alternatives: Deeper CNNs (e.g., ResNet) or transfer learning (e.g., EfficientNet).\n",
    "    \"\"\"\n",
    "    def __init__(self: Self) -> None:\n",
    "        \"\"\"Initializes the model.\"\"\"\n",
    "        \n",
    "        # Call the parent class constructor\n",
    "        super().__init__()\n",
    "        \n",
    "        # Rescaling layer\n",
    "        self.rescale_layer = Rescaling(scale= 1 / 255.0, name=\"Rescale_Layer\")    # Rescales pixel values to [0, 1]\n",
    "        \n",
    "        # Augmentation layer\n",
    "        self.augmentation = RandAugment(value_range=(0, 1), name=\"RandAugment_Layer\")  # Applies random augmentations to the input images\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = Conv2D(filters=3*8, kernel_size=(3, 3), activation='relu', name=\"Conv_Layer1\")                  # 24 filters for feature extraction\n",
    "        self.pool1 = MaxPooling2D(pool_size=(2, 2), name=\"Max_Pool_Layer1\")                                          # Reduces spatial dimensions\n",
    "        self.conv2l = Conv2D(filters=3*16, kernel_size=(3, 3), activation='relu', name=\"Conv_Layer2l\", padding=\"same\") # 48 filters for deeper feature extraction\n",
    "        self.conv2r = Conv2D(filters=3*16, kernel_size=(3, 3), activation='relu', name=\"Conv_Layer2r\", padding=\"same\") # 48 filters for deeper feature extraction\n",
    "        self.pool2 = MaxPooling2D(pool_size=(2, 2), name=\"MaxPool_Layer2\")                                          # Further reduces spatial dimensions\n",
    "        \n",
    "        # Classification head\n",
    "        self.flatten = Flatten(name=\"Flatten_Layer\")                                  # Flattens the output for the dense layer\n",
    "        self.dropout = Dropout(0.3)                                                   # Prevents overfitting\n",
    "        self.dense = Dense(n_classes, activation='softmax', name=\"Dense_Layer\")       # Outputs probabilities for 202 classes\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        \"\"\"Defines the forward pass.\"\"\"\n",
    "        x = self.augmentation(inputs) if training else inputs\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x_l = self.conv2l(x)\n",
    "        x_r = self.conv2r(x)\n",
    "        x = add(x_l, x_r)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.dense(x)\n",
    "\n",
    "# Instantiate the model\n",
    "model = RareSpeciesCNN()\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "_ = model.call(inputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "391168a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "optimizer = SGD(learning_rate=0.01, name=\"Optimizer\")                  # SGD with decay for stability\n",
    "loss = CategoricalCrossentropy(name=\"Loss\")                            # Suitable for multi-class one-hot labels\n",
    "metrics = [CategoricalAccuracy(name=\"accuracy\"), \n",
    "           Precision(name=\"precision\"),\n",
    "           Recall(name=\"recall\"), \n",
    "           F1Score(average=\"macro\", name=\"f1_score\"),\n",
    "           AUC(name=\"auc\")]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "870a01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"checkpoint.keras\", monitor=\"val_loss\", save_best_only=True, verbose=0),        # Save best model\n",
    "    CSVLogger(\"metrics.csv\"),                                                                       # Log training metrics\n",
    "    LearningRateScheduler(lambda epoch, lr: lr * 0.95)                                              # Exponential decay for learning rate\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a190b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743281997.483693   35900 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-03-29 20:59:59.630216: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 199665810 exceeds 10% of free system memory.\n",
      "2025-03-29 21:00:08.672605: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 346800000 exceeds 10% of free system memory.\n",
      "2025-03-29 21:00:18.651256: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 162656685 exceeds 10% of free system memory.\n",
      "2025-03-29 21:00:19.403619: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 186820236 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_datagen, batch_size = batch_size, epochs=1, validation_data=val_datagen, callbacks=callbacks, verbose=2)\n",
    "train_time = round(time.time() - start_time, 2)\n",
    "\n",
    "print(f\"Training completed in \\033[1m{train_time} seconds ({str(datetime.timedelta(seconds=train_time))} h)\\033[0m).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f48a4f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204995d589f8431f",
   "metadata": {},
   "source": [
    "### <a class='anchor' id='3_1'></a> <a class='anchor' id='3_2'></a>  **ğŸ§ª Model Selection & ğŸ“ Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ffc2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot metrics\n",
    "def plot_metrics(history):\n",
    "    \"\"\"Plots training and validation loss, accuracy, and F1 score.\"\"\"\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(18, 4))\n",
    "    metrics = [('loss', 'Loss'), ('accuracy', 'Accuracy'), ('f1_score', 'F1 Score')]\n",
    "    for i, (metric, title) in enumerate(metrics):\n",
    "        ax[i].plot(history.history[metric], label='Train', color='#22c1c3')\n",
    "        ax[i].plot(history.history[f'val_{metric}'], label='Validation', color='#090979')\n",
    "        ax[i].set_title(title, fontsize=14, fontweight='bold')\n",
    "        ax[i].set_xlabel('Epoch', fontsize=12)\n",
    "        ax[i].set_ylabel(title, fontsize=12)\n",
    "        ax[i].legend()\n",
    "        sns.despine(top=True, right=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nTraining Metrics Plot:\")\n",
    "plot_metrics(history)\n",
    "\n",
    "# Evaluate on test set\n",
    "train_results = model.evaluate(train_datagen, batch_size=batch_size, return_dict=True, verbose=0)\n",
    "val_results = model.evaluate(val_datagen, batch_size=batch_size, return_dict=True, verbose=0)\n",
    "test_results = model.evaluate(test_datagen, batch_size=batch_size, return_dict=True, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632582b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect results in DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    \"Models\": [\"Baseline Model\"],\n",
    "    \"Time of Execution\": [train_time],\n",
    "    \"Training Set Accuracy\": [train_results['accuracy']],\n",
    "    \"Training Set Precision\": [train_results['precision']],\n",
    "    \"Training Set Recall\": [train_results['recall']],\n",
    "    \"Training Set F1 Score\": [train_results['f1_score']],\n",
    "    \"Training Set AUROC\": [train_results['auc']],\n",
    "    \"Validation Set Accuracy\": [val_results['accuracy']],\n",
    "    \"Validation Set Precision\": [val_results['precision']],\n",
    "    \"Validation Set Recall\": [val_results['recall']],\n",
    "    \"Validation Set F1 Score\": [val_results['f1_score']],\n",
    "    \"Validation Set AUROC\": [val_results['auc']],\n",
    "    \"Test Set Accuracy\": [test_results['accuracy']],\n",
    "    \"Test Set Precision\": [test_results['precision']],\n",
    "    \"Test Set Recall\": [test_results['recall']],\n",
    "    \"Test Set F1 Score\": [test_results['f1_score']],\n",
    "    \"Test Set AUROC\": [test_results['auc']]\n",
    "})\n",
    "\n",
    "train_df = results_df[['Models', 'Time of Execution', 'Training Set Accuracy', \n",
    "                       'Training Set Precision', 'Training Set Recall', 'Training Set F1 Score', 'Training Set AUROC']]\n",
    "val_df = results_df[['Models', 'Validation Set Accuracy', 'Validation Set Precision', 'Validation Set Recall', \n",
    "                     'Validation Set F1 Score', 'Validation Set AUROC']]\n",
    "test_df = results_df[['Models', 'Test Set Accuracy', 'Test Set Precision', 'Test Set Recall', \n",
    "                      'Test Set F1 Score', 'Test Set AUROC']]\n",
    "\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "display_side_by_side([train_df, val_df, test_df], [\"Training Set\", \"Validation Set\", \"Test Set\"], \n",
    "                     \"Classification Models | Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddc8664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "results_df.to_csv(\"ModelsEvaluation/BaselineModelEvaluation_1_29.03.2025.csv\", index=False)                ### Change the name of the file to save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d9d90f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e2e827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b849b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84b90a90",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e61c8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95a3689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dff3bdf66c1f233",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a5816b",
   "metadata": {},
   "source": [
    "# **ğŸ”— Bibliography/References**\n",
    "\n",
    "**[[1]](https://)** AAAAAAAAAA\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf218",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
